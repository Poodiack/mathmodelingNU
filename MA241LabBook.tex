%********************************************%
%*       Generated from PreTeXt source      *%
%*       on 2026-01-16T08:43:06-05:00       *%
%*   A recent stable commit (2020-08-09):   *%
%* 98f21740783f166a773df4dc83cab5293ab63a4a *%
%*                                          *%
%*         https://pretextbook.org          *%
%*                                          *%
%********************************************%
%% We elect to always write snapshot output into <job>.dep file
\RequirePackage{snapshot}
\documentclass[oneside,10pt,]{book}
%% Custom Preamble Entries, early (use latex.preamble.early)
%% Default LaTeX packages
%%   1.  always employed (or nearly so) for some purpose, or
%%   2.  a stylewriter may assume their presence
\usepackage{geometry}
%% Some aspects of the preamble are conditional,
%% the LaTeX engine is one such determinant
\usepackage{ifthen}
%% etoolbox has a variety of modern conveniences
\usepackage{etoolbox}
\usepackage{ifxetex,ifluatex}
%% Raster graphics inclusion
\usepackage{graphicx}
%% Color support, xcolor package
%% Always loaded, for: add/delete text, author tools
%% Here, since tcolorbox loads tikz, and tikz loads xcolor
\PassOptionsToPackage{usenames,dvipsnames,svgnames,table}{xcolor}
\usepackage{xcolor}
%% begin: defined colors, via xcolor package, for styling
%% end: defined colors, via xcolor package, for styling
%% Colored boxes, and much more, though mostly styling
%% skins library provides "enhanced" skin, employing tikzpicture
%% boxes may be configured as "breakable" or "unbreakable"
%% "raster" controls grids of boxes, aka side-by-side
\usepackage{tcolorbox}
\tcbuselibrary{skins}
\tcbuselibrary{breakable}
\tcbuselibrary{raster}
%% We load some "stock" tcolorbox styles that we use a lot
%% Placement here is provisional, there will be some color work also
%% First, black on white, no border, transparent, but no assumption about titles
\tcbset{ bwminimalstyle/.style={size=minimal, boxrule=-0.3pt, frame empty,
colback=white, colbacktitle=white, coltitle=black, opacityfill=0.0} }
%% Second, bold title, run-in to text/paragraph/heading
%% Space afterwards will be controlled by environment,
%% independent of constructions of the tcb title
%% Places \blocktitlefont onto many block titles
\tcbset{ runintitlestyle/.style={fonttitle=\blocktitlefont\upshape\bfseries, attach title to upper} }
%% Spacing prior to each exercise, anywhere
\tcbset{ exercisespacingstyle/.style={before skip={1.5ex plus 0.5ex}} }
%% Spacing prior to each block
\tcbset{ blockspacingstyle/.style={before skip={2.0ex plus 0.5ex}} }
%% xparse allows the construction of more robust commands,
%% this is a necessity for isolating styling and behavior
%% The tcolorbox library of the same name loads the base library
\tcbuselibrary{xparse}
%% Hyperref should be here, but likes to be loaded late
%%
%% Inline math delimiters, \(, \), need to be robust
%% 2016-01-31:  latexrelease.sty  supersedes  fixltx2e.sty
%% If  latexrelease.sty  exists, bugfix is in kernel
%% If not, bugfix is in  fixltx2e.sty
%% See:  https://tug.org/TUGboat/tb36-3/tb114ltnews22.pdf
%% and read "Fewer fragile commands" in distribution's  latexchanges.pdf
\IfFileExists{latexrelease.sty}{}{\usepackage{fixltx2e}}
%% shorter subnumbers in some side-by-side require manipulations
\usepackage{xstring}
%% Footnote counters and part/chapter counters are manipulated
%% April 2018:  chngcntr  commands now integrated into the kernel,
%% but circa 2018/2019 the package would still try to redefine them,
%% so we need to do the work of loading conditionally for old kernels.
%% From version 1.1a,  chngcntr  should detect defintions made by LaTeX kernel.
\ifdefined\counterwithin
\else
    \usepackage{chngcntr}
\fi
%% Text height identically 9 inches, text width varies on point size
%% See Bringhurst 2.1.1 on measure for recommendations
%% 75 characters per line (count spaces, punctuation) is target
%% which is the upper limit of Bringhurst's recommendations
\geometry{letterpaper,total={340pt,9.0in}}
%% Custom Page Layout Adjustments (use latex.geometry)
%% This LaTeX file may be compiled with pdflatex, xelatex, or lualatex executables
%% LuaTeX is not explicitly supported, but we do accept additions from knowledgeable users
%% The conditional below provides  pdflatex  specific configuration last
%% begin: engine-specific capabilities
\ifthenelse{\boolean{xetex} \or \boolean{luatex}}{%
%% begin: xelatex and lualatex-specific default configuration
\ifxetex\usepackage{xltxtra}\fi
%% realscripts is the only part of xltxtra relevant to lualatex 
\ifluatex\usepackage{realscripts}\fi
%% end:   xelatex and lualatex-specific default configuration
}{
%% begin: pdflatex-specific default configuration
%% We assume a PreTeXt XML source file may have Unicode characters
%% and so we ask LaTeX to parse a UTF-8 encoded file
%% This may work well for accented characters in Western language,
%% but not with Greek, Asian languages, etc.
%% When this is not good enough, switch to the  xelatex  engine
%% where Unicode is better supported (encouraged, even)
\usepackage[utf8]{inputenc}
%% end: pdflatex-specific default configuration
}
%% end:   engine-specific capabilities
%%
%% Fonts.  Conditional on LaTex engine employed.
%% Default Text Font: The Latin Modern fonts are
%% "enhanced versions of the [original TeX] Computer Modern fonts."
%% We use them as the default text font for PreTeXt output.
%% Default Monospace font: Inconsolata (aka zi4)
%% Sponsored by TUG: http://levien.com/type/myfonts/inconsolata.html
%% Loaded for documents with intentional objects requiring monospace
%% See package documentation for excellent instructions
%% fontspec will work universally if we use filename to locate OTF files
%% Loads the "upquote" package as needed, so we don't have to
%% Upright quotes might come from the  textcomp  package, which we also use
%% We employ the shapely \ell to match Google Font version
%% pdflatex: "varl" package option produces shapely \ell
%% pdflatex: "var0" package option produces plain zero (not used)
%% pdflatex: "varqu" package option produces best upright quotes
%% xelatex,lualatex: add OTF StylisticSet 1 for shapely \ell
%% xelatex,lualatex: add OTF StylisticSet 2 for plain zero (not used)
%% xelatex,lualatex: add OTF StylisticSet 3 for upright quotes
%%
%% Automatic Font Control
%% Portions of a document, are, or may, be affected by defined commands
%% These are perhaps more flexible when using  xelatex  rather than  pdflatex
%% The following definitions are meant to be re-defined in a style, using \renewcommand
%% They are scoped when employed (in a TeX group), and so should not be defined with an argument
\newcommand{\divisionfont}{\relax}
\newcommand{\blocktitlefont}{\relax}
\newcommand{\contentsfont}{\relax}
\newcommand{\pagefont}{\relax}
\newcommand{\tabularfont}{\relax}
\newcommand{\xreffont}{\relax}
\newcommand{\titlepagefont}{\relax}
%%
\ifthenelse{\boolean{xetex} \or \boolean{luatex}}{%
%% begin: font setup and configuration for use with xelatex
%% Generally, xelatex is necessary for non-Western fonts
%% fontspec package provides extensive control of system fonts,
%% meaning *.otf (OpenType), and apparently *.ttf (TrueType)
%% that live *outside* your TeX/MF tree, and are controlled by your *system*
%% (it is possible that a TeX distribution will place fonts in a system location)
%%
%% The fontspec package is the best vehicle for using different fonts in  xelatex
%% So we load it always, no matter what a publisher or style might want
%%
\usepackage{fontspec}
%%
%% begin: xelatex main font ("font-xelatex-main" template)
%% Latin Modern Roman is the default font for xelatex and so is loaded with a TU encoding
%% *in the format* so we can't touch it, only perhaps adjust it later
%% in one of two ways (then known by NFSS names such as "lmr")
%% (1) via NFSS with font family names such as "lmr" and "lmss"
%% (2) via fontspec with commands like \setmainfont{Latin Modern Roman}
%% The latter requires the font to be known at the system-level by its font name,
%% but will give access to OTF font features through optional arguments
%% https://tex.stackexchange.com/questions/470008/
%% where-and-how-does-fontspec-sty-specify-the-default-font-latin-modern-roman
%% http://tex.stackexchange.com/questions/115321
%% /how-to-optimize-latin-modern-font-with-xelatex
%%
%% end:   xelatex main font ("font-xelatex-main" template)
%% begin: xelatex mono font ("font-xelatex-mono" template)
%% (conditional on non-trivial uses being present in source)
\IfFontExistsTF{Inconsolatazi4-Regular.otf}{}{\GenericError{}{The font "Inconsolatazi4-Regular.otf" requested by PreTeXt output is not available.  Either a file cannot be located in default locations via a filename, or a font is not known by its name as part of your system.}{Consult the PreTeXt Guide for help with LaTeX fonts.}{}}
\IfFontExistsTF{Inconsolatazi4-Bold.otf}{}{\GenericError{}{The font "Inconsolatazi4-Bold.otf" requested by PreTeXt output is not available.  Either a file cannot be located in default locations via a filename, or a font is not known by its name as part of your system.}{Consult the PreTeXt Guide for help with LaTeX fonts.}{}}
\usepackage{zi4}
\setmonofont[BoldFont=Inconsolatazi4-Bold.otf,StylisticSet={1,3}]{Inconsolatazi4-Regular.otf}
%% end:   xelatex mono font ("font-xelatex-mono" template)
%% begin: xelatex font adjustments ("font-xelatex-style" template)
%% end:   xelatex font adjustments ("font-xelatex-style" template)
%%
%% Extensive support for other languages
\usepackage{polyglossia}
%% Set main/default language based on pretext/@xml:lang value
%% document language code is "en-US", US English
%% usmax variant has extra hypenation
\setmainlanguage[variant=usmax]{english}
%% Enable secondary languages based on discovery of @xml:lang values
%% Enable fonts/scripts based on discovery of @xml:lang values
%% Western languages should be ably covered by Latin Modern Roman
%% end:   font setup and configuration for use with xelatex
}{%
%% begin: font setup and configuration for use with pdflatex
%% begin: pdflatex main font ("font-pdflatex-main" template)
\usepackage{lmodern}
\usepackage[T1]{fontenc}
%% end:   pdflatex main font ("font-pdflatex-main" template)
%% begin: pdflatex mono font ("font-pdflatex-mono" template)
%% (conditional on non-trivial uses being present in source)
\usepackage[varqu,varl]{inconsolata}
%% end:   pdflatex mono font ("font-pdflatex-mono" template)
%% begin: pdflatex font adjustments ("font-pdflatex-style" template)
%% end:   pdflatex font adjustments ("font-pdflatex-style" template)
%% end:   font setup and configuration for use with pdflatex
}
%% Micromanage spacing, etc.  The named "microtype-options"
%% template may be employed to fine-tune package behavior
\usepackage{microtype}
%% Symbols, align environment, commutative diagrams, bracket-matrix
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amssymb}
%% allow page breaks within display mathematics anywhere
%% level 4 is maximally permissive
%% this is exactly the opposite of AMSmath package philosophy
%% there are per-display, and per-equation options to control this
%% split, aligned, gathered, and alignedat are not affected
\allowdisplaybreaks[4]
%% allow more columns to a matrix
%% can make this even bigger by overriding with  latex.preamble.late  processing option
\setcounter{MaxMatrixCols}{30}
%%
%%
%% Division Titles, and Page Headers/Footers
%% titlesec package, loading "titleps" package cooperatively
%% See code comments about the necessity and purpose of "explicit" option.
%% The "newparttoc" option causes a consistent entry for parts in the ToC 
%% file, but it is only effective if there is a \titleformat for \part.
%% "pagestyles" loads the  titleps  package cooperatively.
\usepackage[explicit, newparttoc, pagestyles]{titlesec}
%% The companion titletoc package for the ToC.
\usepackage{titletoc}
%% Fixes a bug with transition from chapters to appendices in a "book"
%% See generating XSL code for more details about necessity
\newtitlemark{\chaptertitlename}
%% begin: customizations of page styles via the modal "titleps-style" template
%% Designed to use commands from the LaTeX "titleps" package
%% Plain pages should have the same font for page numbers
\renewpagestyle{plain}{%
\setfoot{}{\pagefont\thepage}{}%
}%
%% Single pages as in default LaTeX
\renewpagestyle{headings}{%
\sethead{\pagefont\slshape\MakeUppercase{\ifthechapter{\chaptertitlename\space\thechapter.\space}{}\chaptertitle}}{}{\pagefont\thepage}%
}%
\pagestyle{headings}
%% end: customizations of page styles via the modal "titleps-style" template
%%
%% Create globally-available macros to be provided for style writers
%% These are redefined for each occurence of each division
\newcommand{\divisionnameptx}{\relax}%
\newcommand{\titleptx}{\relax}%
\newcommand{\subtitleptx}{\relax}%
\newcommand{\shortitleptx}{\relax}%
\newcommand{\authorsptx}{\relax}%
\newcommand{\epigraphptx}{\relax}%
%% Create environments for possible occurences of each division
%% Environment for a PTX "part" at the level of a LaTeX "part"
\NewDocumentEnvironment{partptx}{mmmmmm}
{%
\renewcommand{\divisionnameptx}{Part}%
\renewcommand{\titleptx}{#1}%
\renewcommand{\subtitleptx}{#2}%
\renewcommand{\shortitleptx}{#3}%
\renewcommand{\authorsptx}{#4}%
\renewcommand{\epigraphptx}{#5}%
\part[{#3}]{#1}%
\label{#6}%
}{}%
%% Environment for a PTX "chapter" at the level of a LaTeX "chapter"
\NewDocumentEnvironment{chapterptx}{mmmmmm}
{%
\renewcommand{\divisionnameptx}{Chapter}%
\renewcommand{\titleptx}{#1}%
\renewcommand{\subtitleptx}{#2}%
\renewcommand{\shortitleptx}{#3}%
\renewcommand{\authorsptx}{#4}%
\renewcommand{\epigraphptx}{#5}%
\chapter[{#3}]{#1}%
\label{#6}%
}{}%
%% Environment for a PTX "section" at the level of a LaTeX "section"
\NewDocumentEnvironment{sectionptx}{mmmmmm}
{%
\renewcommand{\divisionnameptx}{Section}%
\renewcommand{\titleptx}{#1}%
\renewcommand{\subtitleptx}{#2}%
\renewcommand{\shortitleptx}{#3}%
\renewcommand{\authorsptx}{#4}%
\renewcommand{\epigraphptx}{#5}%
\section[{#3}]{#1}%
\label{#6}%
}{}%
%% Environment for a PTX "subsection" at the level of a LaTeX "subsection"
\NewDocumentEnvironment{subsectionptx}{mmmmmm}
{%
\renewcommand{\divisionnameptx}{Subsection}%
\renewcommand{\titleptx}{#1}%
\renewcommand{\subtitleptx}{#2}%
\renewcommand{\shortitleptx}{#3}%
\renewcommand{\authorsptx}{#4}%
\renewcommand{\epigraphptx}{#5}%
\subsection[{#3}]{#1}%
\label{#6}%
}{}%
%% Environment for a PTX "exercises" at the level of a LaTeX "subsection"
\NewDocumentEnvironment{exercises-subsection}{mmmmmm}
{%
\renewcommand{\divisionnameptx}{Exercises}%
\renewcommand{\titleptx}{#1}%
\renewcommand{\subtitleptx}{#2}%
\renewcommand{\shortitleptx}{#3}%
\renewcommand{\authorsptx}{#4}%
\renewcommand{\epigraphptx}{#5}%
\subsection[{#3}]{#1}%
\label{#6}%
}{}%
%% Environment for a PTX "exercises" at the level of a LaTeX "subsection"
\NewDocumentEnvironment{exercises-subsection-numberless}{mmmmmm}
{%
\renewcommand{\divisionnameptx}{Exercises}%
\renewcommand{\titleptx}{#1}%
\renewcommand{\subtitleptx}{#2}%
\renewcommand{\shortitleptx}{#3}%
\renewcommand{\authorsptx}{#4}%
\renewcommand{\epigraphptx}{#5}%
\subsection*{#1}%
\addcontentsline{toc}{subsection}{#3}
\label{#6}%
}{}%
%% Environment for a PTX "subsubsection" at the level of a LaTeX "subsubsection"
\NewDocumentEnvironment{subsubsectionptx}{mmmmmm}
{%
\renewcommand{\divisionnameptx}{Subsubsection}%
\renewcommand{\titleptx}{#1}%
\renewcommand{\subtitleptx}{#2}%
\renewcommand{\shortitleptx}{#3}%
\renewcommand{\authorsptx}{#4}%
\renewcommand{\epigraphptx}{#5}%
\subsubsection[{#3}]{#1}%
\label{#6}%
}{}%
%%
%% Styles for six traditional LaTeX divisions
\titleformat{\part}[display]
{\divisionfont\Huge\bfseries\centering}{\divisionnameptx\space\thepart}{30pt}{\Huge#1}
[{\Large\centering\authorsptx}]
\titleformat{\chapter}[display]
{\divisionfont\huge\bfseries}{\divisionnameptx\space\thechapter}{20pt}{\Huge#1}
[{\Large\authorsptx}]
\titleformat{name=\chapter,numberless}[display]
{\divisionfont\huge\bfseries}{}{0pt}{#1}
[{\Large\authorsptx}]
\titlespacing*{\chapter}{0pt}{50pt}{40pt}
\titleformat{\section}[hang]
{\divisionfont\Large\bfseries}{\thesection}{1ex}{#1}
[{\large\authorsptx}]
\titleformat{name=\section,numberless}[block]
{\divisionfont\Large\bfseries}{}{0pt}{#1}
[{\large\authorsptx}]
\titlespacing*{\section}{0pt}{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}
\titleformat{\subsection}[hang]
{\divisionfont\large\bfseries}{\thesubsection}{1ex}{#1}
[{\normalsize\authorsptx}]
\titleformat{name=\subsection,numberless}[block]
{\divisionfont\large\bfseries}{}{0pt}{#1}
[{\normalsize\authorsptx}]
\titlespacing*{\subsection}{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\titleformat{\subsubsection}[hang]
{\divisionfont\normalsize\bfseries}{\thesubsubsection}{1em}{#1}
[{\small\authorsptx}]
\titleformat{name=\subsubsection,numberless}[block]
{\divisionfont\normalsize\bfseries}{}{0pt}{#1}
[{\normalsize\authorsptx}]
\titlespacing*{\subsubsection}{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\titleformat{\paragraph}[hang]
{\divisionfont\normalsize\bfseries}{\theparagraph}{1em}{#1}
[{\small\authorsptx}]
\titleformat{name=\paragraph,numberless}[block]
{\divisionfont\normalsize\bfseries}{}{0pt}{#1}
[{\normalsize\authorsptx}]
\titlespacing*{\paragraph}{0pt}{3.25ex plus 1ex minus .2ex}{1.5em}
%%
%% Styles for five traditional LaTeX divisions
\titlecontents{part}%
[0pt]{\contentsmargin{0em}\addvspace{1pc}\contentsfont\bfseries}%
{\Large\thecontentslabel\enspace}{\Large}%
{}%
[\addvspace{.5pc}]%
\titlecontents{chapter}%
[0pt]{\contentsmargin{0em}\addvspace{1pc}\contentsfont\bfseries}%
{\large\thecontentslabel\enspace}{\large}%
{\hfill\bfseries\thecontentspage}%
[\addvspace{.5pc}]%
\dottedcontents{section}[3.8em]{\contentsfont}{2.3em}{1pc}%
\dottedcontents{subsection}[6.1em]{\contentsfont}{3.2em}{1pc}%
\dottedcontents{subsubsection}[9.3em]{\contentsfont}{4.3em}{1pc}%
%%
%% Begin: Semantic Macros
%% To preserve meaning in a LaTeX file
%%
%% \mono macro for content of "c", "cd", "tag", etc elements
%% Also used automatically in other constructions
%% Simply an alias for \texttt
%% Always defined, even if there is no need, or if a specific tt font is not loaded
\newcommand{\mono}[1]{\texttt{#1}}
%%
%% Following semantic macros are only defined here if their
%% use is required only in this specific document
%%
%% Used for inline definitions of terms
\newcommand{\terminology}[1]{\textbf{#1}}
%% End: Semantic Macros
%% Divisional exercises (and worksheet) as LaTeX environments
%% Third argument is option for extra workspace in worksheets
%% Hanging indent occupies a 5ex width slot prior to left margin
%% Experimentally this seems just barely sufficient for a bold "888."
%% Division exercises, not in exercise group
\tcbset{ divisionexercisestyle/.style={bwminimalstyle, runintitlestyle, exercisespacingstyle, left=5ex, breakable, parbox=false } }
\newtcolorbox{divisionexercise}[4]{divisionexercisestyle, before title={\hspace{-5ex}\makebox[5ex][l]{#1.}}, title={\notblank{#2}{#2\space}{}}, phantom={\hypertarget{#4}{}}, after={\notblank{#3}{\newline\rule{\workspacestrutwidth}{#3}\newline}{}}}
%% Localize LaTeX supplied names (possibly none)
\renewcommand*{\partname}{Part}
\renewcommand*{\chaptername}{Chapter}
%% Equation Numbering
%% Controlled by  numbering.equations.level  processing parameter
%% No adjustment here implies document-wide numbering
\numberwithin{equation}{section}
%% "tcolorbox" environment for a single image, occupying entire \linewidth
%% arguments are left-margin, width, right-margin, as multiples of
%% \linewidth, and are guaranteed to be positive and sum to 1.0
\tcbset{ imagestyle/.style={bwminimalstyle} }
\NewTColorBox{image}{mmm}{imagestyle,left skip=#1\linewidth,width=#2\linewidth}
%% For improved tables
\usepackage{array}
%% Some extra height on each row is desirable, especially with horizontal rules
%% Increment determined experimentally
\setlength{\extrarowheight}{0.2ex}
%% Define variable thickness horizontal rules, full and partial
%% Thicknesses are 0.03, 0.05, 0.08 in the  booktabs  package
\newcommand{\hrulethin}  {\noalign{\hrule height 0.04em}}
\newcommand{\hrulemedium}{\noalign{\hrule height 0.07em}}
\newcommand{\hrulethick} {\noalign{\hrule height 0.11em}}
%% We preserve a copy of the \setlength package before other
%% packages (extpfeil) get a chance to load packages that redefine it
\let\oldsetlength\setlength
\newlength{\Oldarrayrulewidth}
\newcommand{\crulethin}[1]%
{\noalign{\global\oldsetlength{\Oldarrayrulewidth}{\arrayrulewidth}}%
\noalign{\global\oldsetlength{\arrayrulewidth}{0.04em}}\cline{#1}%
\noalign{\global\oldsetlength{\arrayrulewidth}{\Oldarrayrulewidth}}}%
\newcommand{\crulemedium}[1]%
{\noalign{\global\oldsetlength{\Oldarrayrulewidth}{\arrayrulewidth}}%
\noalign{\global\oldsetlength{\arrayrulewidth}{0.07em}}\cline{#1}%
\noalign{\global\oldsetlength{\arrayrulewidth}{\Oldarrayrulewidth}}}
\newcommand{\crulethick}[1]%
{\noalign{\global\oldsetlength{\Oldarrayrulewidth}{\arrayrulewidth}}%
\noalign{\global\oldsetlength{\arrayrulewidth}{0.11em}}\cline{#1}%
\noalign{\global\oldsetlength{\arrayrulewidth}{\Oldarrayrulewidth}}}
%% Single letter column specifiers defined via array package
\newcolumntype{A}{!{\vrule width 0.04em}}
\newcolumntype{B}{!{\vrule width 0.07em}}
\newcolumntype{C}{!{\vrule width 0.11em}}
%% tcolorbox to place tabular outside of a sidebyside
\tcbset{ tabularboxstyle/.style={bwminimalstyle,} }
\newtcolorbox{tabularbox}[3]{tabularboxstyle, left skip=#1\linewidth, width=#2\linewidth,}
%% Program listing support: for listings, programs, consoles, and Sage code
\ifthenelse{\boolean{xetex} \or \boolean{luatex}}%
  {\tcbuselibrary{listings}}%
  {\tcbuselibrary{listingsutf8}}%
%% We define the listings font style to be the default "ttfamily"
%% To fix hyphens/dashes rendered in PDF as fancy minus signs by listing
%% http://tex.stackexchange.com/questions/33185/listings-package-changes-hyphens-to-minus-signs
\makeatletter
\lst@CCPutMacro\lst@ProcessOther {"2D}{\lst@ttfamily{-{}}{-{}}}
\@empty\z@\@empty
\makeatother
%% We define a null language, free of any formatting or style
%% for use when a language is not supported, or pseudo-code, or consoles
%% Not necessary for Sage code, so in limited cases included unnecessarily
\lstdefinelanguage{none}{identifierstyle=,commentstyle=,stringstyle=,keywordstyle=}
\ifthenelse{\boolean{xetex}}{}{%
%% begin: pdflatex-specific listings configuration
%% translate U+0080 - U+00F0 to their textmode LaTeX equivalents
%% Data originally from https://www.w3.org/Math/characters/unicode.xml, 2016-07-23
%% Lines marked in XSL with "$" were converted from mathmode to textmode
\lstset{extendedchars=true}
\lstset{literate={ }{{~}}{1}{¡}{{\textexclamdown }}{1}{¢}{{\textcent }}{1}{£}{{\textsterling }}{1}{¤}{{\textcurrency }}{1}{¥}{{\textyen }}{1}{¦}{{\textbrokenbar }}{1}{§}{{\textsection }}{1}{¨}{{\textasciidieresis }}{1}{©}{{\textcopyright }}{1}{ª}{{\textordfeminine }}{1}{«}{{\guillemotleft }}{1}{¬}{{\textlnot }}{1}{­}{{\-}}{1}{®}{{\textregistered }}{1}{¯}{{\textasciimacron }}{1}{°}{{\textdegree }}{1}{±}{{\textpm }}{1}{²}{{\texttwosuperior }}{1}{³}{{\textthreesuperior }}{1}{´}{{\textasciiacute }}{1}{µ}{{\textmu }}{1}{¶}{{\textparagraph }}{1}{·}{{\textperiodcentered }}{1}{¸}{{\c{}}}{1}{¹}{{\textonesuperior }}{1}{º}{{\textordmasculine }}{1}{»}{{\guillemotright }}{1}{¼}{{\textonequarter }}{1}{½}{{\textonehalf }}{1}{¾}{{\textthreequarters }}{1}{¿}{{\textquestiondown }}{1}{À}{{\`{A}}}{1}{Á}{{\'{A}}}{1}{Â}{{\^{A}}}{1}{Ã}{{\~{A}}}{1}{Ä}{{\"{A}}}{1}{Å}{{\AA }}{1}{Æ}{{\AE }}{1}{Ç}{{\c{C}}}{1}{È}{{\`{E}}}{1}{É}{{\'{E}}}{1}{Ê}{{\^{E}}}{1}{Ë}{{\"{E}}}{1}{Ì}{{\`{I}}}{1}{Í}{{\'{I}}}{1}{Î}{{\^{I}}}{1}{Ï}{{\"{I}}}{1}{Ð}{{\DH }}{1}{Ñ}{{\~{N}}}{1}{Ò}{{\`{O}}}{1}{Ó}{{\'{O}}}{1}{Ô}{{\^{O}}}{1}{Õ}{{\~{O}}}{1}{Ö}{{\"{O}}}{1}{×}{{\texttimes }}{1}{Ø}{{\O }}{1}{Ù}{{\`{U}}}{1}{Ú}{{\'{U}}}{1}{Û}{{\^{U}}}{1}{Ü}{{\"{U}}}{1}{Ý}{{\'{Y}}}{1}{Þ}{{\TH }}{1}{ß}{{\ss }}{1}{à}{{\`{a}}}{1}{á}{{\'{a}}}{1}{â}{{\^{a}}}{1}{ã}{{\~{a}}}{1}{ä}{{\"{a}}}{1}{å}{{\aa }}{1}{æ}{{\ae }}{1}{ç}{{\c{c}}}{1}{è}{{\`{e}}}{1}{é}{{\'{e}}}{1}{ê}{{\^{e}}}{1}{ë}{{\"{e}}}{1}{ì}{{\`{\i}}}{1}{í}{{\'{\i}}}{1}{î}{{\^{\i}}}{1}{ï}{{\"{\i}}}{1}{ð}{{\dh }}{1}{ñ}{{\~{n}}}{1}{ò}{{\`{o}}}{1}{ó}{{\'{o}}}{1}{ô}{{\^{o}}}{1}{õ}{{\~{o}}}{1}{ö}{{\"{o}}}{1}{÷}{{\textdiv }}{1}{ø}{{\o }}{1}{ù}{{\`{u}}}{1}{ú}{{\'{u}}}{1}{û}{{\^{u}}}{1}{ü}{{\"{u}}}{1}{ý}{{\'{y}}}{1}{þ}{{\th }}{1}{ÿ}{{\"{y}}}{1}}
%% end: pdflatex-specific listings configuration
}
%% End of generic listing adjustments
%% Program listings via new tcblisting environment
%% First a universal color scheme for parts of any language
%% Colors match a subset of Google prettify "Default" style
%% Full colors for "electronic" version
%% http://code.google.com/p/google-code-prettify/source/browse/trunk/src/prettify.css
\definecolor{identifiers}{rgb}{0.375,0,0.375}
\definecolor{comments}{rgb}{0.5,0,0}
\definecolor{strings}{rgb}{0,0.5,0}
\definecolor{keywords}{rgb}{0,0,0.5}
%% Options passed to the listings package via tcolorbox
\lstdefinestyle{programcodestyle}{identifierstyle=\color{identifiers},commentstyle=\color{comments},stringstyle=\color{strings},keywordstyle=\color{keywords}, breaklines=true, breakatwhitespace=true, columns=fixed, extendedchars=true, aboveskip=0pt, belowskip=0pt}
\tcbset{ programboxstyle/.style={left=3ex, right=0pt, top=0ex, bottom=0ex, middle=0pt, toptitle=0pt, bottomtitle=0pt, boxsep=0pt, 
listing only, fontupper=\small\ttfamily,
colback=white, sharp corners, boxrule=-0.3pt, leftrule=0.5pt, toprule at break=-0.3pt, bottomrule at break=-0.3pt,
breakable, parbox=false,
} }
\newtcblisting{program}[4]{programboxstyle, left skip=#2\linewidth, width=#3\linewidth, listing options={language=#1, style=programcodestyle}}
%% The listings package as tcolorbox for Sage code
%% We do as much styling as possible with tcolorbox, not listings
%% Sage's blue is 50%, we go way lighter (blue!05 would also work)
%% Note that we defuse listings' default "aboveskip" and "belowskip"
\definecolor{sageblue}{rgb}{0.95,0.95,1}
\tcbset{ sagestyle/.style={left=0pt, right=0pt, top=0ex, bottom=0ex, middle=0pt, toptitle=0pt, bottomtitle=0pt,
boxsep=4pt, listing only, fontupper=\small\ttfamily,
breakable, parbox=false, 
listing options={language=Python,breaklines=true,breakatwhitespace=true, extendedchars=true, aboveskip=0pt, belowskip=0pt}} }
\newtcblisting{sageinput}{sagestyle, colback=sageblue, sharp corners, boxrule=0.5pt, toprule at break=-0.3pt, bottomrule at break=-0.3pt, }
\newtcblisting{sageoutput}{sagestyle, colback=white, colframe=white, frame empty, before skip=0pt, after skip=0pt, }
%% Fancy Verbatim for consoles, preformatted, code display, literate programming
\usepackage{fancyvrb}
%% code display (cd), by analogy with math display (md)
%% savebox, lrbox, etc to achieve centering
\newsavebox{\codedisplaybox}
\newenvironment{codedisplay}
{\VerbatimEnvironment\begin{center}\begin{lrbox}{\codedisplaybox}\begin{BVerbatim}}
{\end{BVerbatim}\end{lrbox}\usebox{\codedisplaybox}\end{center}}
%% More flexible list management, esp. for references
%% But also for specifying labels (i.e. custom order) on nested lists
\usepackage{enumitem}
%% hyperref driver does not need to be specified, it will be detected
%% Footnote marks in tcolorbox have broken linking under
%% hyperref, so it is necessary to turn off all linking
%% It *must* be given as a package option, not with \hypersetup
\usepackage[hyperfootnotes=false]{hyperref}
%% configure hyperref's  \url  to match listings' inline verbatim
\renewcommand\UrlFont{\small\ttfamily}
%% Hyperlinking active in electronic PDFs, all links solid and blue
\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,filecolor=blue,urlcolor=blue}
\hypersetup{pdftitle={MA241 Manual}}
%% If you manually remove hyperref, leave in this next command
%% This will allow LaTeX compilation, employing this no-op command
\providecommand\phantomsection{}
%% Division Numbering: Chapters, Sections, Subsections, etc
%% Division numbers may be turned off at some level ("depth")
%% A section *always* has depth 1, contrary to us counting from the document root
%% The latex default is 3.  If a larger number is present here, then
%% removing this command may make some cross-references ambiguous
%% The precursor variable $numbering-maxlevel is checked for consistency in the common XSL file
\setcounter{secnumdepth}{3}
%%
%% AMS "proof" environment is no longer used, but we leave previously
%% implemented \qedhere in place, should the LaTeX be recycled
\newcommand{\qedhere}{\relax}
%%
%% A faux tcolorbox whose only purpose is to provide common numbering
%% facilities for most blocks (possibly not projects, 2D displays)
%% Controlled by  numbering.theorems.level  processing parameter
\newtcolorbox[auto counter, number within=section]{block}{}
%%
%% This document is set to number PROJECT-LIKE on a separate numbering scheme
%% So, a faux tcolorbox whose only purpose is to provide this numbering
%% Controlled by  numbering.projects.level  processing parameter
\newtcolorbox[auto counter, number within=section]{project-distinct}{}
%% A faux tcolorbox whose only purpose is to provide common numbering
%% facilities for 2D displays which are subnumbered as part of a "sidebyside"
\makeatletter
\newtcolorbox[auto counter, number within=tcb@cnt@block, number freestyle={\noexpand\thetcb@cnt@block(\noexpand\alph{\tcbcounter})}]{subdisplay}{}
\makeatother
%%
%% tcolorbox, with styles, for THEOREM-LIKE
%%
%% theorem: fairly simple numbered block/structure
\tcbset{ theoremstyle/.style={bwminimalstyle, runintitlestyle, blockspacingstyle, after title={\space}, } }
\newtcolorbox[use counter from=block]{theorem}[3]{title={{Theorem~\thetcbcounter\notblank{#1#2}{\space}{}\notblank{#1}{\space#1}{}\notblank{#2}{\space(#2)}{}}}, phantomlabel={#3}, breakable, parbox=false, after={\par}, fontupper=\itshape, theoremstyle, }
%%
%% tcolorbox, with styles, for DEFINITION-LIKE
%%
%% definition: fairly simple numbered block/structure
\tcbset{ definitionstyle/.style={bwminimalstyle, runintitlestyle, blockspacingstyle, after title={\space}, after upper={\space\space\hspace*{\stretch{1}}\(\lozenge\)}, } }
\newtcolorbox[use counter from=block]{definition}[2]{title={{Definition~\thetcbcounter\notblank{#1}{\space\space#1}{}}}, phantomlabel={#2}, breakable, parbox=false, after={\par}, definitionstyle, }
%%
%% tcolorbox, with styles, for EXAMPLE-LIKE
%%
%% example: fairly simple numbered block/structure
\tcbset{ examplestyle/.style={bwminimalstyle, runintitlestyle, blockspacingstyle, after title={\space}, after upper={\space\space\hspace*{\stretch{1}}\(\square\)}, } }
\newtcolorbox[use counter from=block]{example}[2]{title={{Example~\thetcbcounter\notblank{#1}{\space\space#1}{}}}, phantomlabel={#2}, breakable, parbox=false, after={\par}, examplestyle, }
%%
%% tcolorbox, with styles, for inline exercises
%%
%% inlineexercise: fairly simple numbered block/structure
\tcbset{ inlineexercisestyle/.style={bwminimalstyle, runintitlestyle, blockspacingstyle, after title={\space}, } }
\newtcolorbox[use counter from=block]{inlineexercise}[2]{title={{Checkpoint~\thetcbcounter\notblank{#1}{\space\space#1}{}}}, phantomlabel={#2}, breakable, parbox=false, after={\par}, inlineexercisestyle, }
%%
%% tcolorbox, with styles, for FIGURE-LIKE
%%
%% figureptx: 2-D display structure
\tcbset{ figureptxstyle/.style={bwminimalstyle, middle=1ex, blockspacingstyle, fontlower=\blocktitlefont} }
\newtcolorbox[use counter from=block]{figureptx}[3]{lower separated=false, before lower={{\textbf{Figure~\thetcbcounter}\space#1}}, phantomlabel={#2}, unbreakable, parbox=false, figureptxstyle, }
%% tableptx: 2-D display structure
\tcbset{ tableptxstyle/.style={bwminimalstyle, middle=1ex, blockspacingstyle, coltitle=black, bottomtitle=2ex, titlerule=-0.3pt, fonttitle=\blocktitlefont} }
\newtcolorbox[use counter from=block]{tableptx}[3]{title={{\textbf{Table~\thetcbcounter}\space#1}}, phantomlabel={#2}, unbreakable, parbox=false, tableptxstyle, }
%%
%% xparse environments for introductions and conclusions of divisions
%%
%% introduction: in a structured division
\NewDocumentEnvironment{introduction}{m}
{\notblank{#1}{\noindent\textbf{#1}\space}{}}{\par\medskip}
%%
%% tcolorbox, with styles, for miscellaneous environments
%%
%% proof: title is a replacement
\tcbset{ proofstyle/.style={bwminimalstyle, fonttitle=\blocktitlefont\itshape, attach title to upper, after title={\space}, after upper={\space\space\hspace*{\stretch{1}}\(\blacksquare\)},
} }
\newtcolorbox{proof}[2]{title={\notblank{#1}{#1}{Proof.}}, phantom={\hypertarget{#2}{}}, breakable, parbox=false, after={\par}, proofstyle }
%% Graphics Preamble Entries
%% If tikz has been loaded, replace ampersand with \amp macro
%% tcolorbox styles for sidebyside layout
\tcbset{ sbsstyle/.style={raster before skip=2.0ex, raster equal height=rows, raster force size=false} }
\tcbset{ sbspanelstyle/.style={bwminimalstyle, fonttitle=\blocktitlefont} }
%% Enviroments for side-by-side and components
%% Necessary to use \NewTColorBox for boxes of the panels
%% "newfloat" environment to squash page-breaks within a single sidebyside
%% "xparse" environment for entire sidebyside
\NewDocumentEnvironment{sidebyside}{mmmm}
  {\begin{tcbraster}
    [sbsstyle,raster columns=#1,
    raster left skip=#2\linewidth,raster right skip=#3\linewidth,raster column skip=#4\linewidth]}
  {\end{tcbraster}}
%% "tcolorbox" environment for a panel of sidebyside
\NewTColorBox{sbspanel}{mO{top}}{sbspanelstyle,width=#1\linewidth,valign=#2}
%% extpfeil package for certain extensible arrows,
%% as also provided by MathJax extension of the same name
%% NB: this package loads mtools, which loads calc, which redefines
%%     \setlength, so it can be removed if it seems to be in the 
%%     way and your math does not use:
%%     
%%     \xtwoheadrightarrow, \xtwoheadleftarrow, \xmapsto, \xlongequal, \xtofrom
%%     
%%     we have had to be extra careful with variable thickness
%%     lines in tables, and so also load this package late
\usepackage{extpfeil}
%% Custom Preamble Entries, late (use latex.preamble.late)
%% Begin: Author-provided packages
%% (From  docinfo/latex-preamble/package  elements)
%% End: Author-provided packages
%% Begin: Author-provided macros
%% (From  docinfo/macros  element)
%% Plus three from MBX for XML characters

\newcommand{\lt}{<}
\newcommand{\gt}{>}
\newcommand{\amp}{&}
%% End: Author-provided macros
\begin{document}
\frontmatter
%% begin: half-title
\thispagestyle{empty}
{\titlepagefont\centering
\vspace*{0.28\textheight}
{\Huge MA241 Manual}\\[2\baselineskip]
{\LARGE Mathematical Computation and Modeling}\\
}
\clearpage
%% end:   half-title
%% begin: title page
%% Inspired by Peter Wilson's "titleDB" in "titlepages" CTAN package
\thispagestyle{empty}
{\titlepagefont\centering
\vspace*{0.14\textheight}
%% Target for xref to top-level element is ToC
\addtocontents{toc}{\protect\hypertarget{x:book:MA241LabBook}{}}
{\Huge MA241 Manual}\\[\baselineskip]
{\LARGE Mathematical Computation and Modeling}\\[3\baselineskip]
{\Large Robert D. Poodiack}\\[0.5\baselineskip]
{\Large Norwich University}\\[3\baselineskip]
{\Large January 16, 2026}\\}
\clearpage
%% end:   title page
%% begin: copyright-page
\thispagestyle{empty}
\vspace*{\stretch{2}}
\vspace*{\stretch{1}}
\null\clearpage
%% end:   copyright-page
%% begin: table of contents
%% Adjust Table of Contents
\setcounter{tocdepth}{0}
\renewcommand*\contentsname{Contents}
\tableofcontents
%% end:   table of contents
\mainmatter
%
%
\typeout{************************************************}
\typeout{Part I SageMath and Python Basics}
\typeout{************************************************}
%
\begin{partptx}{SageMath and Python Basics}{}{SageMath and Python Basics}{}{}{x:part:part-basics}
 %
%
\typeout{************************************************}
\typeout{Chapter 1 Acquiring access to SageMath}
\typeout{************************************************}
%
\begin{chapterptx}{Acquiring access to SageMath}{}{Acquiring access to SageMath}{}{}{x:chapter:download}
\begin{introduction}{}%
SageMath, a computer algebra system built on the Python programming language, is the software we'll use in this course.  In this chapter, we get you started by showing you how to download SageMath to your computer or how to access SageMath without downloading it.\end{introduction}%
%
%
\typeout{************************************************}
\typeout{Section 1.1 Downloading SageMath}
\typeout{************************************************}
%
\begin{sectionptx}{Downloading SageMath}{}{Downloading SageMath}{}{}{x:section:section-downloading-Sage}
\begin{introduction}{}%
SageMath is an open-source and free competitor to expensive computer algebra systems like Mathematica, Maple, and MATLAB.  It is generally easier to use than a graphing calculator and much more powerful, combining ways to display your results to others with stunning graphics.%
\par
Working with SageMath can be done by downloading the software to your own laptop, or by using CoCalc, an online installation that can be used in any browser.  There are advantages and disadvantages to each implementation, but both experiences are equivalent -{}-{} you get the same version of Sage and can use the same commands in either method.%
\par
What follows below are starter instructions for downloading SageMath to your Mac or a Windows PC.  (There is an app for the iPad and the iPhone, but these simply call the SageMathCell server to do quick calculations.  At this writing, there is not a full implementation of SageMath for the iPad or iPhone. On the iPad, you will need to use CoCalc.)%
\par
In any browser, navigate to \href{http://www.sagemath.org}{http:\slash{}\slash{}www.sagemath.org}.%
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{images/sagemathpage.pdf}
\end{image}%
There are six buttons in the center of the screen.  Click on the downward arrow button in the upper right-hand corner. (It'll say "Install 10.7" -{}-{} or whatever the current version is.)%
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{./images/sageinstallation.pdf}
\end{image}%
NOTE: If you have installed SageMath on MacOS, you should move the icon to start SageMath to the Applications folder. If you have installed SageMath on a Windows machine, you should absolutely create a shortcut for SageMath that lets you start the Jupyter or JupyterLab server in one click.%
\end{introduction}%
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 1.2 Using Sage without downloading}
\typeout{************************************************}
%
\begin{sectionptx}{Using Sage without downloading}{}{Using Sage without downloading}{}{}{x:section:section-cocalc}
As an alternative, you can work with Sage through a cloud-based installation called CoCalc, available through \href{http://www.cocalc.com}{http:\slash{}\slash{}www.cocalc.com}. Your instructor will have likely established accounts for your entire class, and you will have received an invitation to join via email. The pro for using CoCalc is that you don't have to go through an installation process.  The con is that CoCalc purposely runs free accounts on a slow server, and it will almost always be slowest on the night before your homework's due date.%
\end{sectionptx}
\end{chapterptx}
 %
%
\typeout{************************************************}
\typeout{Chapter 2 Getting Started with SageMath}
\typeout{************************************************}
%
\begin{chapterptx}{Getting Started with SageMath}{}{Getting Started with SageMath}{}{}{x:chapter:gettingstarted}
\begin{introduction}{}%
Now that you have access to SageMath, either by downloading it to your own computer or by accessing it in CoCalc, we'll start with some basic commands in Sage to get you on your way.\end{introduction}%
%
%
\typeout{************************************************}
\typeout{Section 2.1 Starting up SageMath}
\typeout{************************************************}
%
\begin{sectionptx}{Starting up SageMath}{}{Starting up SageMath}{}{}{x:section:section-starting-Sage}
If you downloaded SageMath on to your own computer, you should be able to simply double-click on the Sage icon to start (SageMath-X-X in the Applications folder on the Mac, whatever you named your shortcut on Windows machines).%
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{images/sageopenwindow.png}
\end{image}%
 (Make sure on MacOS, you choose the Notebook option.) After a short pause, you should land on your default directory page.  If you click the New pulldown menu in the upper right-hand corner of your screen, choose SageMath X.X for your current version.%
\par
If your instructor has given you access to CoCalc, you should be able to log in to your account and then choose New and Jupyter notebook.%
\par
In any case, you should be in a notebook environment that looks something like this:%
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{images/startupscreen.png}
\end{image}%
From this point forward, you should follow along by typing given examples into your Jupyter notebook. (If you are reading along with the Web-based version of this book, you can hit the Evaluate button after each example.)%
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 2.2 Working with Jupyter notebooks}
\typeout{************************************************}
%
\begin{sectionptx}{Working with Jupyter notebooks}{}{Working with Jupyter notebooks}{}{}{x:section:jupyter-notebooks}
\begin{introduction}{}%
While SageMath can be used within a terminal environment, using SageMath in a Jupyter notebook leads to much more robust and readable sessions. In a Jupyter notebook, we can enter explanatory text to go with the SageMath code using HTML commands to format. In this section, we will give some examples of coding that will allow us make our notebooks look exactly as we want them to look.%
\end{introduction}%
%
%
\typeout{************************************************}
\typeout{Subsection 2.2.1 Getting started with Jupyter}
\typeout{************************************************}
%
\begin{subsectionptx}{Getting started with Jupyter}{}{Getting started with Jupyter}{}{}{g:subsection:id1}
When you open a new notebook in either SageMath or CoCalc, you'll have one of two similar but not identical experiences.%
\par
%
\begin{itemize}[label=\textbullet]
\item{}In SageMath, you'll go up to the right-hand corner of your screen to the New button and choose SageMath 10.8 (or whatever version you have). A blank notebook with an indicator that you're using SageMath as the kernel should open.%
\item{}In CoCalc, you can click on the arrow to the right of the New button and choose ``Jupyter notebook (.ipynb)''. You'll be asked to name the file. After you do so, you should see the screen in \hyperref[x:figure:opening-screens]{Figure~{\xreffont\ref{x:figure:opening-screens}}}.%
\end{itemize}
%
\begin{figureptx}{A blank notebook in SageMath (left) and in CoCalc (right).}{x:figure:opening-screens}{}%
\begin{sidebyside}{2}{0}{0}{0.1}%
\begin{sbspanel}{0.45}[center]%
\includegraphics[width=\linewidth]{./images/sagemathopen.png}
\end{sbspanel}%
\begin{sbspanel}{0.45}[center]%
\includegraphics[width=\linewidth]{./images/cocalcopen.png}
\end{sbspanel}%
\end{sidebyside}%
\tcblower
\end{figureptx}%
You may have to go to the Kernel menu in CoCalc to select the most recent version of SageMath as the kernel.%
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 2.2.2 Adding plain text in Jupyter notebooks}
\typeout{************************************************}
%
\begin{subsectionptx}{Adding plain text in Jupyter notebooks}{}{Adding plain text in Jupyter notebooks}{}{}{g:subsection:id2}
We assume that you have a blank Jupyter notebook open either in CoCalc or in SageMath itself.%
\par
We will introduce SageMath code in the next section. For now, we will look at ways of entering and formatting plain text in our notebook. This is useful for adding titles, section headings, and longer comments on your code.%
\par
Content in Jupyter notebooks is inserted via \emph{cells}. In both SageMath and CoCalc, new cells are by default \emph{Code} cells, the kind of cell where we would enter SageMath commands. To enter plain text, we need to have a \emph{Markdown} cell.%
\par
In SageMath, we can click on the pulldown menu right and choose ``Markdown'' as the type of cell. (See \hyperref[x:figure:markdownsage]{Figure~{\xreffont\ref{x:figure:markdownsage}}}.) In CoCalc, we can either add a new cell by choosing to add a Text cell, then choosing Markdown. (see \hyperref[x:figure:markdowncocalc]{Figure~{\xreffont\ref{x:figure:markdowncocalc}}}) or clicking on the three dots at the right end of the cell and choosing Change Cell to Markdown. (See \hyperref[x:figure:markdowncocalc3]{Figure~{\xreffont\ref{x:figure:markdowncocalc3}}}.)%
\begin{figureptx}{Changing the cell type to Markdown in SageMath}{x:figure:markdownsage}{}%
\begin{image}{0.1}{0.8}{0.1}%
\includegraphics[width=\linewidth]{./images/markdown.png}
\end{image}%
\tcblower
\end{figureptx}%
\begin{figureptx}{Adding a new Markdown cell in CoCalc}{x:figure:markdowncocalc}{}%
\begin{sidebyside}{2}{0}{0}{0.1}%
\begin{sbspanel}{0.45}[center]%
\includegraphics[width=\linewidth]{./images/markdowncocalc.png}
\end{sbspanel}%
\begin{sbspanel}{0.45}[center]%
\includegraphics[width=\linewidth]{./images/markdowncocalc2.png}
\end{sbspanel}%
\end{sidebyside}%
\tcblower
\end{figureptx}%
\begin{figureptx}{Changing a cell to Markdown in CoCalc}{x:figure:markdowncocalc3}{}%
\begin{image}{0}{1}{0}%
\includegraphics[width=\linewidth]{./images/markdowncocalc3.png}
\end{image}%
\tcblower
\end{figureptx}%
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 2.2.3 Formatting plain text}
\typeout{************************************************}
%
\begin{subsectionptx}{Formatting plain text}{}{Formatting plain text}{}{}{g:subsection:id3}
Here, we provide several examples of ways to enter and format plain text in Jupyter notebooks. Jupyter notebooks use HTML tags and commands to format text. We only need a few basic commands to make our notebooks look spiffy. Once our Markdown commands are entered, we hit \mono{SHIFT}-\mono{ENTER} to render the text.%
\begin{example}{Entering plain text.}{g:example:id4}%
Plain text in Jupyter notebooks must begin with a \mono{<p>} tag (for \emph{paragraph}) and end with a \mono{</p>} tag. Each new paragraph must begin with \mono{<p>} and end with \mono{</p>}.%
\begin{program}{HTML}{0}{1}{0}
<p>This is a piece of plain text (not code).</p>
\end{program}
\begin{image}{0}{1}{0}%
\includegraphics[width=\linewidth]{./images/output1.png}
\end{image}%
%
\end{example}
\begin{example}{Entering bold or italic text.}{g:example:id5}%
\begin{program}{HTML}{0}{1}{0}
<p>This is a piece of <b>bold</b> text and this is a piece 
of <i>italic</i> text.</p>
\end{program}
\begin{image}{0}{1}{0}%
\includegraphics[width=\linewidth]{./images/output2.png}
\end{image}%
%
\end{example}
\begin{example}{Entering large text.}{g:example:id6}%
Here, we ask SageMath to render our text two sizes bigger than usual.%
\begin{program}{HTML}{0}{1}{0}
<font size=+2>
 		<p>This is a piece of large text.</p>
</font>
\end{program}
\begin{image}{0}{1}{0}%
\includegraphics[width=\linewidth]{./images/output3.png}
\end{image}%
%
\end{example}
\begin{example}{Entering large text with color.}{g:example:id7}%
\begin{program}{HTML}{0}{1}{0}
<font color='red' size=+1>
 		<p>This is a piece of large (though not <br />
 		as large as the previous example) red text.</p>
</font>
\end{program}
\begin{image}{0}{1}{0}%
\includegraphics[width=\linewidth]{./images/output4.png}
\end{image}%
%
\par
The \mono{<br />} command inserts a line break in the text.%
\end{example}
\begin{example}{Adding a big header.}{g:example:id8}%
\begin{program}{HTML}{0}{1}{0}
# Big header
\end{program}
\begin{image}{0}{1}{0}%
\includegraphics[width=\linewidth]{./images/output5.png}
\end{image}%
%
\par
Equivalently, we could enclose the header text in the HTML style commands \mono{<h1>} and \mono{</h1>}.%
\end{example}
\begin{example}{Adding a medium header.}{g:example:id9}%
\begin{program}{HTML}{0}{1}{0}
## Medium header
\end{program}
\begin{image}{0}{1}{0}%
\includegraphics[width=\linewidth]{./images/output6.png}
\end{image}%
%
\par
Equivalently, we could enclose the header text in the HTML style commands \mono{<h2>} and \mono{</h2>}. We can get smaller section headers still by putting in another hashtag or two before the text (or using \mono{h3} or \mono{h4} styles).%
\end{example}
\end{subsectionptx}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 2.3 An introduction to SageMath}
\typeout{************************************************}
%
\begin{sectionptx}{An introduction to SageMath}{}{An introduction to SageMath}{}{}{x:section:sage-intro}
\begin{introduction}{}%
We will introduce the SageMath computer algebra system and walk you through some commands.%
\end{introduction}%
In SageMath, we enter commands and then get them to execute via an "Evaluate" button (if one is present) or by hitting SHIFT-RETURN while the cursor is within the command. For example if we want to factor the integer 1438880, we would give the following command:%
\begin{sageinput}
factor(1438880) #Hit SHIFT-RETURN while your cursor is within this cell.
\end{sageinput}
We can understand that output easily. In some cases, we may want the result to look more like we would see in a math textbook. In that case, we can wrap our command in a \mono{pretty\_print} command.%
\begin{sageinput}
pretty_print(factor(1438880))
\end{sageinput}
One of the handiest features built into SageMath is tab completion of commands. Suppose you want to compute \(56!\) but don't remember the exact command to do this. You suspect that the command will have factorial somewhere in its name. To see if that guess is correct, just type the letters \mono{fac} then hit the TAB key. (This works only in SageMath itself, not in the online textbook.)%
\begin{sageinput}
fac  #Put the cursor at the end of the command and hit TAB
\end{sageinput}
A pop-up menu tells you that the only two commands that begin with fac are \mono{factor} and \mono{factorial}.%
\begin{sageinput}
factorial(56)
\end{sageinput}
\begin{sageoutput}
710998587804863451854045647463724949736497978881168458687447040000000000000
\end{sageoutput}
SageMath is an \emph{object-oriented} language (it's built on Python), meaning that things like numbers are considered as \emph{objects}, which have methods associated with them. For example, suppose we set \(a=56\) , and you were wondering what commands SageMath offers for working with integers like 56. In this case, \(a\) is our object and we can find all the methods associated with integers by typing \mono{a.} followed by the TAB key.%
\begin{sageinput}
a = 56 # Hit SHIFT-ENTER
\end{sageinput}
\begin{sageinput}
a. # In a Jupyter notebook, put the cursor after the period and hit TAB.
\end{sageinput}
You can choose a method from the (long) pulldown menu that results. Methods require parentheses at their end, so even after choosing a method, you need to tack on parentheses. So we can factor \(a\) just by entering:%
\begin{sageinput}
a.factor()
\end{sageinput}
\begin{sageoutput}
2^3 * 7
\end{sageoutput}
Some SageMath commands have aliases that look more like function notation. For instance, we can also factor \(a\) by typing:%
\begin{sageinput}
factor(a)
\end{sageinput}
\begin{sageoutput}
2^3 * 7
\end{sageoutput}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 2.4 SageMath as a calculator}
\typeout{************************************************}
%
\begin{sectionptx}{SageMath as a calculator}{}{SageMath as a calculator}{}{}{x:section:sage-calculator}
The basic arithmetic operators are \mono{+}, \mono{-}, \mono{*}, and \mono{/}. Sage uses the traditional \mono{\textasciicircum{}} for exponentiation as well as the Python \mono{**}.%
\begin{sageinput}
print(1+1)
print(103-101)
print(7*9)
print(7337/11)
print(11/4)
print(2^5)
\end{sageinput}
Normally, if we have many commands in one cell, SageMath will only print the output from the last command. We have to use the \mono{print} command for Sage to display all the outputs. (Note also that recent versions of Sage are built atop Python 3. Thus we must use the parentheses with the \mono{print} command.)%
\par
Sage adheres to the PEMDAS order of operations. When dividing two integers, Sage will return a fractional answer unless we write one of the integers using a decimal.%
\begin{sageinput}
print(11/4)
print(11/4.0)
\end{sageinput}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 2.5 Solving equations and inequalities}
\typeout{************************************************}
%
\begin{sectionptx}{Solving equations and inequalities}{}{Solving equations and inequalities}{}{}{x:section:sage-solve}
In Sage, equations and inequalities are defined using the operators \mono{==} (equal to), \mono{!=} (not equal to), \mono{<} (less than), \mono{<=} (less than or equal to), \mono{>} (greater than), and \mono{>=} (greater than or equal to) and will return either True or False.%
\begin{sageinput}
9 == 9
\end{sageinput}
\begin{sageoutput}
True
\end{sageoutput}
\begin{sageinput}
9 == 10
\end{sageinput}
\begin{sageoutput}
False
\end{sageoutput}
To solve an equation or inequality, we use the aptly named \mono{solve()} command. In Sage, \(x\) is automatically considered to be a variable. (We will see how to handle other letters shortly.)%
\begin{sageinput}
solve(3*x-2==5,x)
\end{sageinput}
\begin{sageoutput}
[x == (7/3)]
\end{sageoutput}
(Note that you always need the \mono{*} operator on multiplication. No shortening to \mono{3x}.)%
\begin{sageinput}
solve(2*x-5==1,x)
\end{sageinput}
\begin{sageoutput}
[x == 3]
\end{sageoutput}
\begin{sageinput}
solve(2*x-5>=17,x)
\end{sageinput}
\begin{sageoutput}
[[x >= 11]]
\end{sageoutput}
\begin{sageinput}
solve(x^2+x==6,x)
\end{sageinput}
\begin{sageoutput}
[x == -3, x == 2]
\end{sageoutput}
\begin{sageinput}
pretty_print(solve(e^x == -1,x))
\end{sageinput}
If Sage can't solve your equation exactly -{}-{} you'll know if Sage simply throws your equation or inequality back at you untouched -{}-{} we can use the \mono{find\_root} command to get a numerical approximation for the solution. (This command uses Newton's method, among other possible methods.)%
\begin{sageinput}
solve(sin(x)==cos(x),x)
\end{sageinput}
\begin{sageoutput}
[sin(x) == cos(x)]
\end{sageoutput}
\begin{sageinput}
find_root(sin(x)==cos(x),0,pi/2)
\end{sageinput}
\begin{sageoutput}
0.7853981633974484
\end{sageoutput}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 2.6 Standard constants and functions}
\typeout{************************************************}
%
\begin{sectionptx}{Standard constants and functions}{}{Standard constants and functions}{}{}{x:section:sage-constants-functions}
Notice from the last couple of examples that the constants \(e\), \(i\), and \(\pi\) are known to Sage. We can get those constants by typing \mono{e}, \mono{I}, or \mono{pi}, respectively. Typing those will get you exact answers in terms of those constants. If a decimal answer is required, we can use the \mono{n} command to get a numerical approximation.%
\begin{sageinput}
print(e)
print(e.n())
print(e.n(digits=100))
\end{sageinput}
\begin{sageoutput}
e
2.71828182845905
2.718281828459045235360287471352662497757247093699959574966967627724076630353547594571382178525166427
\end{sageoutput}
We also have the typical functions: \mono{sin()} and \mono{cos()}, but also \mono{sqrt()}, and \mono{exp()} and all the usual trigonometric and inverse trigonometric functions. One oddity: both \mono{ln()} and \mono{log()} refer to the logarithm to the base \(e\). To get a logarithm to the base \(b\), use the command \mono{log(x,b)}.%
\begin{sageinput}
print(sin(pi/6))
print(cos(pi/4))
print(cos(pi/10))
print(cos(pi/10).n())
print(arctan(1))
print(ln(e))
print(log(e))
print(log(100))
print(log(100.0))
print(log(100,10))
\end{sageinput}
\begin{sageoutput}
1/2
1/2*sqrt(2)
1/4*sqrt(2*sqrt(5) + 10)
0.951056516295154
1/4*pi
1
1
2*log(10)
4.60517018598809
2
\end{sageoutput}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 2.7 Declaring Variables}
\typeout{************************************************}
%
\begin{sectionptx}{Declaring Variables}{}{Declaring Variables}{}{}{x:section:sage-declaring-variables}
Sage automatically declares the symbol \(x\) to be a variable each time it starts. To use other letters (or words), we have to declare them to be variables using the \mono{var()} command. So if we wish to solve a system of linear equations or inequalities in \(x\) and \(y\), say, we would type something like the following:%
\begin{sageinput}
var('x y')
solve([3*x - y == 2, -2*x -y == 1 ], x,y)
\end{sageinput}
\begin{sageoutput}
[[x == (1/5), y == (-7/5)]]
\end{sageoutput}
\begin{sageinput}
solve([2*x - y == -1 , 2*x - y == 2],x,y)
\end{sageinput}
\begin{sageoutput}
[]
\end{sageoutput}
\begin{sageinput}
solve([x-y >=2, x+y <=3], x,y)
\end{sageinput}
\begin{sageoutput}
[[x == (5/2), y == (1/2)], [x == -y + 3, y < (1/2)], [x == y + 2, y < (1/2)], [y + 2 < x, x < -y + 3, y < (1/2)]]
\end{sageoutput}
(In the second case, that system has no solution. In the third, the list of solutions gives the intersection point, then two rays, then the region between the two rays.)%
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 2.8 Calculus}
\typeout{************************************************}
%
\begin{sectionptx}{Calculus}{}{Calculus}{}{}{x:section:sage-calculus}
Sage has many commands for the study of limits, derivatives, and integrals. We can \emph{define} our own functions using syntax like the following:%
\begin{sageinput}
f(x) = x*exp(x)
g(x) = x^2*cos(2*x)
h(x) = (x^2+x-2)/(x-4)
\end{sageinput}
We can evaluate these functions using intuitive notation:%
\begin{sageinput}
f(1)
\end{sageinput}
\begin{sageoutput}
e
\end{sageoutput}
\begin{sageinput}
g(2*pi)
\end{sageinput}
\begin{sageoutput}
4*pi^2
\end{sageoutput}
\begin{sageinput}
h(-1)
\end{sageinput}
\begin{sageoutput}
2/5
\end{sageoutput}
%
%
\typeout{************************************************}
\typeout{Subsection 2.8.1 Limits}
\typeout{************************************************}
%
\begin{subsectionptx}{Limits}{}{Limits}{}{}{g:subsection:id10}
We can compute \(\lim\limits_{x\to 1} f(x)\) by entering the following command:%
\begin{sageinput}
limit(f(x),x=1)
\end{sageinput}
\begin{sageoutput}
e
\end{sageoutput}
We can do the same for \(\lim\limits_{x\to 2} g(x)\):%
\begin{sageinput}
limit(g(x),x=2)
\end{sageinput}
\begin{sageoutput}
4*cos(4)
\end{sageoutput}
The functions \(f(x)\) and \(g(x)\) aren't all that exciting as far as limits are concerned since they are both continuous for all real numbers. But \(h(x)\) has a discontinuity at \(x=4\).%
\begin{sageinput}
limit(h(x),x=4)
\end{sageinput}
\begin{sageoutput}
Infinity
\end{sageoutput}
This isn't quite right as the following graph shows.%
\begin{image}{0.1}{0.8}{0.1}%
\includegraphics[width=\linewidth]{images/sagecalcplot.png}
\end{image}%
Note that the graph of \(h(x)\) has a vertical asymptote at \(x=4\). Thus the overall limit at 4 does not exist. However, we can take the appropriate directional limits as follows:%
\begin{sageinput}
limit(h(x),x=4, dir='right')
\end{sageinput}
\begin{sageoutput}
+Infinity
\end{sageoutput}
\begin{sageinput}
limit(h(x),x=4, dir='left')
\end{sageinput}
\begin{sageoutput}
-Infinity
\end{sageoutput}
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 2.8.2 Derivatives}
\typeout{************************************************}
%
\begin{subsectionptx}{Derivatives}{}{Derivatives}{}{}{g:subsection:id11}
To compute the derivatives of functions, we can use the \mono{diff()} command. (The \mono{derivative()} command works just as well ... but it's longer.)%
\begin{sageinput}
fprime = diff(f,x)
gprime = diff(g,x)
hprime = diff(h,x)
print(fprime(x))
print(gprime(x))
print(hprime(x))
\end{sageinput}
\begin{sageoutput}
x*e^x + e^x
-2*x^2*sin(2*x) + 2*x*cos(2*x)
(2*x + 1)/(x - 4) - (x^2 + x - 2)/(x - 4)^2
\end{sageoutput}
We can now use these functions as any other one.%
\begin{sageinput}
print(fprime(10))
print(gprime(pi/2))
print(hprime(10))
\end{sageinput}
\begin{sageoutput}
11*e^10
-pi
1/2
\end{sageoutput}
For instance, we can now find the critical points of \(f\), \(g\), or \(h\) by using the \mono{solve()} command.%
\begin{sageinput}
solve(fprime(x)==0,x)
\end{sageinput}
\begin{sageoutput}
[x == -1]
\end{sageoutput}
\begin{sageinput}
solve(hprime(x)==0,x)
\end{sageinput}
\begin{sageoutput}
[x == -3*sqrt(2) + 4, x == 3*sqrt(2) + 4]
\end{sageoutput}
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 2.8.3 Integrals}
\typeout{************************************************}
%
\begin{subsectionptx}{Integrals}{}{Integrals}{}{}{g:subsection:id12}
Sage can compute both definite and indefinite integrals for many common functions.%
\begin{sageinput}
print(integral(f(x),x))
print(integral(g(x),x))
print(integral(h(x),x))
print(integral(h(x),x,0,1))
print(integral(h(x),x,0,1).n())
\end{sageinput}
\begin{sageoutput}
(x - 1)*e^x
1/2*x*cos(2*x) + 1/4*(2*x^2 - 1)*sin(2*x)
1/2*x^2 + 5*x + 18*log(x - 4)
18*log(3) - 36*log(2) + 11/2
0.321722695867944
\end{sageoutput}
Sage loses a point for leaving off the \({}+C\) on indefinite integrals.%
\end{subsectionptx}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 2.9 Plotting}
\typeout{************************************************}
%
\begin{sectionptx}{Plotting}{}{Plotting}{}{}{x:section:sage-plotting}
Sage has a basic \mono{plot()} command to produce 2D function graphs. To produce a basic graph of \(f(x)=\sin x\)  from \(x=-\pi/2\) to \(x=\pi/2\), we would type%
\begin{sageinput}
plot(sin(x),(x,-pi/2,pi/2))
\end{sageinput}
This is rather plain by design. We can add options to make things look a little better.%
\begin{sageinput}
plot(sin(x),(x,-pi/2,pi/2),axes_labels=['$x$','$\\sin\\,x$'],color='purple')
\end{sageinput}
We can also change the style of line and its thickness:%
\begin{sageinput}
plot(sin(x),(x,-pi/2,pi/2),linestyle='--',thickness=3)
\end{sageinput}
We can graph two functions together on the same set of axes by adding the plots together:%
\begin{sageinput}
p = plot(sin(x),(x,-pi/2,pi/2),color='black')
q = plot(cos(x),(x,-pi/2,pi/2),color='red')
show(p+q)
\end{sageinput}
We can now use the \mono{find\_root()} command we saw earlier to find the point of intersection of the two graphs and then add this point to the above graph.%
\begin{sageinput}
find_root(sin(x)==cos(x),-pi/2,pi/2)
\end{sageinput}
\begin{sageoutput}
0.7853981633974484
\end{sageoutput}
\begin{sageinput}
P = point([0.7853981633974484,sin(0.7853981633974484)]) # I used copy and paste to get that number there
T = text("(0.79,0.71)",(0.7853981633974484,sin(0.7853981633974484)+0.10))
show(p+q+P+T)
\end{sageinput}
Note that Sage handles many of the details of making graphs look "nice." However, sometimes Sage will need our help.%
\begin{sageinput}
f(x) = (x^3 + x^2 + x)/(x^2 - x -2 )
p = plot(f(x),(x,-5,5))
show(p)
\end{sageinput}
The vertical asymptotes cause Sage to display rather large \(y\)-values, which means that most of the features of the graph are obscured. We can explicitly adjust the vertical and horizontal limits of our plot.%
\begin{sageinput}
show(p,xmin=-2, xmax = 4, ymin = -20, ymax = 20)
\end{sageinput}
\end{sectionptx}
\end{chapterptx}
 %
%
\typeout{************************************************}
\typeout{Chapter 3 Some deeper examples}
\typeout{************************************************}
%
\begin{chapterptx}{Some deeper examples}{}{Some deeper examples}{}{}{x:chapter:sage-more-functions}
\begin{introduction}{}%
We just saw how to define our own functions in SageMath (meaning mathematical functions). The nice part is that we can do this very easily, using the symbols we would normally use when we write down a function on paper. We can also plot functions quickly, and solve equations in SageMath involving functions. In this chapter, we will look at some additional examples of these.\end{introduction}%
%
%
\typeout{************************************************}
\typeout{Section 3.1 Review of mathematical functions}
\typeout{************************************************}
%
\begin{sectionptx}{Review of mathematical functions}{}{Review of mathematical functions}{}{}{x:section:sage-function-review}
If we want to define \(f(x) = x^3-x\), then we type%
\begin{sageinput}
f(x) = x^3 -x # this is a typical function
f(2)
\end{sageinput}
\begin{sageoutput}
6
\end{sageoutput}
where we have defined \(f(x)\) and asked Sage for the value of \(f(2)\). We could instead ask for \(f(3)\), or any other value, just by changing the code in the above cell.%
\par
If we want to define, say, \(g(x)=\sqrt{1-x^2}\), we would type%
\begin{sageinput}
g(x) = sqrt(1-x^2)
g(1/4.)
\end{sageinput}
\begin{sageoutput}
0.968245836551854
\end{sageoutput}
Note that we got a decimal approximation for the answer because we threw in the decimal point at the end. If you want an exact answer, you can re-execute the cell without that decimal point.%
\par
Remember that to evaluate several values, we can use the \mono{print} command. (Without the \mono{print}, Sage would only output the last command.)%
\begin{sageinput}
print(g(-0.1))
print(g(-0.01))
print(g(-0.001))
print(g(-0.0001))
print(g(-0.00001))
print(g(-0.000001))
\end{sageinput}
\begin{sageoutput}
0.994987437106620
0.999949998749938
0.999999499999875
0.999999995000000
0.999999999950000
0.999999999999500
\end{sageoutput}
Since you have taken calculus already, you know that the above is a table to help compute%
\begin{equation*}
\lim_{x\to 0^-} g(x) = 1
\end{equation*}
numerically, or help confirm your algebraic answer.%
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 3.2 Review of plotting functions}
\typeout{************************************************}
%
\begin{sectionptx}{Review of plotting functions}{}{Review of plotting functions}{}{}{x:section:sage-plotting-review}
Now that we have defined \(f(x)\) and \(g(x)\), we can plot them with%
\begin{sageinput}
f(x) = x^3 - x
plot(f, -2, 2)
\end{sageinput}
Likewise ...%
\begin{sageinput}
g(x) = sqrt(1-x^2)
plot(g(x), 0, 1)
\end{sageinput}
The above command is equivalent to \mono{plot(g,0,1)}, and we get the graph on \(0\le x\le 1\). If we leave the interval off the command, Sage aims to give the most likely possible interval.%
\begin{sageinput}
plot(g)
\end{sageinput}
Notice that SageMath remembers what \(f\) and \(g\) are -{}-{} we don't have to redefine those functions in every cell. (This is not true in general for SageMathCell, which is one of the reasons we had to remind Sage of \(f\) and \(g\)'s definitions above.) However, if you quit your work in the notebook and come back to it later, you'll have to re-execute the cells with the definitions of \(f\) and \(g\) before doing any more work with them.%
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 3.3 Miscellaneous stuff on functions}
\typeout{************************************************}
%
\begin{sectionptx}{Miscellaneous stuff on functions}{}{Miscellaneous stuff on functions}{}{}{x:section:sage-misc-functions}
%
%
\typeout{************************************************}
\typeout{Subsection 3.3.1 Composition of functions}
\typeout{************************************************}
%
\begin{subsectionptx}{Composition of functions}{}{Composition of functions}{}{}{g:subsection:id13}
We can compose two functions very easily in SageMath. Consider the two functions:%
\begin{equation*}
f(x) = 3x+5\quad\text{and}\quad g(x)=x^3 + 1.
\end{equation*}
Perhaps we wish to explore \(f(g(x))\). The easy way to do this is to define a third function, \(h(x) = f(g(x))\). Then, we can print this function, and the values of \(h(x)\) whenever we like.%
\begin{sageinput}
f(x) = 3*x + 5
g(x) = x^3 + 1
h(x) = f(g(x))
\end{sageinput}
\begin{sageinput}
print(h(x))
print(h(1))
print(h(2))
print(h(3))
\end{sageinput}
\begin{sageoutput}
3*x^3 + 8
11
32
89
\end{sageoutput}
Recall, though, that generally \(g(f(x)) \ne f(g(x))\).%
\begin{sageinput}
h(x) = g(f(x))
print(h(x))
print(h(1))
print(h(2))
print(h(3))
\end{sageinput}
\begin{sageoutput}
(3*x + 5)^3 + 1
513
1332
2745
\end{sageoutput}
This is completely different output than what we got previously. We can do the calculations to verify:%
%
\begin{align*}
f(g(x)) \amp = 3(g(x)) + 5 \\
\amp = 3(x^3 + 1) + 5 \\
\amp = 3x^3 + 3 + 5 \\
\amp = 3x^3 + 8 \\
\\
g(f(x)) \amp = g(3x+5)\\
\amp = (3x+5)^3 +1 \\
\amp = 27x^3 + 135 x^2 + 225 x + 125 + 1 \\
\amp = 27x^3 + 135 x^2 + 225 x + 126 
\end{align*}
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 3.3.2 Manipulating polynomials}
\typeout{************************************************}
%
\begin{subsectionptx}{Manipulating polynomials}{}{Manipulating polynomials}{}{}{g:subsection:id14}
If we enter the following code%
\begin{sageinput}
a(x) = x^2 - 5*x + 6
b(x) = x^2 - 8*x + 15
a(x) + b(x)
\end{sageinput}
\begin{sageoutput}
2*x^2 - 13*x + 21
\end{sageoutput}
(Don't forget the asterisk for multiplication between the 5 and the \(x\)... and the 8 and the \(x\).) Asking for the difference of the two functions gets us the right answer as well:%
\begin{sageinput}
a(x) - b(x)
\end{sageinput}
\begin{sageoutput}
3*x-9
\end{sageoutput}
On the other hand, a request for the product of the two seems unfinished:%
\begin{sageinput}
a(x) * b(x)
\end{sageinput}
\begin{sageoutput}
(x^2 - 5*x + 6)*(x^2 - 8*x + 15)
\end{sageoutput}
The \mono{expand} method will multiply out that product.%
\begin{sageinput}
g(x) = a(x) * b(x)
g(x).expand()
\end{sageinput}
\begin{sageoutput}
x^4 - 13*x^3 + 61*x^2 - 123*x + 90
\end{sageoutput}
So \(g\) is the function that sends \(x\) to \(x^4 - 13*x^3 + 61*x^2 - 123*x + 90\).%
\par
On the other hand, perhaps we want to factor \(g\) instead:%
\begin{sageinput}
g.factor()
\end{sageinput}
\begin{sageoutput}
x |--> (x - 2)*(x - 3)^2*(x - 5)
\end{sageoutput}
SageMath does allow us to write some methods like \mono{expand} or \mono{factor} in function form instead. For instance, \mono{factor(f)} is equivalent to \mono{f.factor()}. To get rid of the \textasciigrave{}\textasciigrave{}evaluates to'{}'{} piece, we need to specify the "of \(x\)" part of our function.%
\begin{sageinput}
print(factor(g))
factor(g(x))
\end{sageinput}
\begin{sageoutput}
x |--> (x - 2)*(x - 3)^2*(x - 5)
(x - 2)*(x - 3)^2*(x - 5)
\end{sageoutput}
\begin{sageinput}
print(expand(a(b(x))))
factor(a(b(x)))
\end{sageinput}
\begin{sageoutput}
x^4 - 16*x^3 + 89*x^2 - 200*x + 156
(x^2 - 8*x + 13)*(x - 2)*(x - 6)
\end{sageoutput}
\begin{sageinput}
factor(x^4 - 60*x^3 + 1330*x^2 - 12900*x + 46189)
\end{sageinput}
\begin{sageoutput}
(x - 11)*(x - 13)*(x - 17)*(x - 19)
\end{sageoutput}
Recall that we can find factors of numbers as well. If we were searching for roots of the previous polynomial, we would want to factor the constant term in order to look for possible rational roots.%
\begin{sageinput}
factor(46189)
\end{sageinput}
\begin{sageoutput}
11 * 13 * 17 * 19
\end{sageoutput}
\begin{sageinput}
divisors(46189)
\end{sageinput}
\begin{sageoutput}
[1,
 11,
 13,
 17,
 19,
 143,
 187,
 209,
 221,
 247,
 323,
 2431,
 2717,
 3553,
 4199,
 46189]
\end{sageoutput}
Here's a first "program'{}'{} that will demonstrate a couple of the commands from above, and the differences in output:%
\begin{sageinput}
f(x) = a(b(x))
print("Direct:")
print(f(x))
print("Expanded:")
print(expand(f(x)))
print("Factored:")
print(factor(f(x)))
\end{sageinput}
\begin{sageoutput}
Direct:
(x^2 - 8*x + 15)^2 - 5*x^2 + 40*x - 69
Expanded:
x^4 - 16*x^3 + 89*x^2 - 200*x + 156
Factored:
(x^2 - 8*x + 13)*(x - 2)*(x - 6)
\end{sageoutput}
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 3.3.3 Solving problems symbolically}
\typeout{************************************************}
%
\begin{subsectionptx}{Solving problems symbolically}{}{Solving problems symbolically}{}{}{g:subsection:id15}
Computer algebra systems like SageMath can solve problems in two ways: symbolically or numerically. When we solve numerically, we get a decimal approximation (a good one!) of the answer. When we solve symbolically, we get an exact answer, often in terms of radicals, logarithms, or other constants and functions. Computer algebra systems like SageMath can solve problems in two ways: symbolically or numerically. When we solve numerically, we get a decimal approximation (a good one!) of the answer. When we solve symbolically, we get an exact answer, often in terms of radicals, logarithms, or other constants and functions.%
\begin{sageinput}
solve(x^2 + 3*x + 2, x)
\end{sageinput}
\begin{sageoutput}
[x == -2, x == -1]
\end{sageoutput}
Note that this assumes we're looking for the roots of the function we've given. On the other hand, we can give an equation for SageMath to solve:%
\begin{sageinput}
solve(x^2 + 9*x + 15 == 0, x)
\end{sageinput}
\begin{sageoutput}
[x == -1/2*sqrt(21) - 9/2, x == 1/2*sqrt(21) - 9/2]
\end{sageoutput}
By the way, we can use the \mono{pretty\_print} command to get nice-looking output:%
\begin{sageinput}
pretty_print(solve(x^2 + 9*x + 15 == 0, x))
\end{sageinput}
Note the square brackets encompassing the solutions. This is an example of a list in Python.%
\par
One way to distinguish symbolic versus numeric solutions is to compare%
\begin{sageinput}
3+1/(7+1/(15+1/(1+1/(292+1/(1+1/(1+1/6))))))
\end{sageinput}
\begin{sageoutput}
1354394/431117
\end{sageoutput}
\begin{sageinput}
N(3+1/(7+1/(15+1/(1+1/(292+1/(1+1/(1+1/6)))))))
\end{sageinput}
\begin{sageoutput}
3.14159265350241
\end{sageoutput}
That last answer is really close to \(\pi\) (relative error: \(2.78\times 10^{-11}\)).%
\par
There is no restriction to answers from polynomials. On the other hand ...%
\begin{sageinput}
var('theta')
solve(sin(theta) == 1/2, theta)
\end{sageinput}
\begin{sageoutput}
[theta == 1/6*pi]
\end{sageoutput}
... only produces one value because \mono{solve} uses the arcsine function to solve the equation. The (infinitely) other values for which \(\sin\theta = 1/2\) don't get produced. (The answer is \(\theta = \pi/6 + 2\pi\cdot k, 
5\pi/6 + 2\pi\cdot k\), for all integers \(k\).)%
\par
Notice that we had to declare 'theta' as a variable before solving that equation. Remember that whenever we're using a variable symbolically (as opposed to assigning it a value), we have to declare it in advance. For example, if we want to re-derive the quadratic formula, we could type:%
\begin{sageinput}
var('a b c')
pretty_print(solve(a*x^2 + b*x + c ==0, x))
\end{sageinput}
There's a similar formula for cubics:%
\begin{sageinput}
var('a b c d')
pretty_print(solve(a*x^3 + b*x^2 + c*x + d ==0, x))
\end{sageinput}
SageMath can solve systems of equations, where we use the square brackets to let SageMath know we're providing a list of functions, rather than just one. So to solve the system:%
\begin{align*}
9a+3b+c \amp =32\\
4a+2b+c \amp =15\\
a+b+c \amp = 6 
\end{align*}
we type%
\begin{sageinput}
var('a b c')
solve([9*a + 3*b + c == 32, 4*a + 2*b + c == 15, a + b + c == 6], a, b, c)
\end{sageinput}
\begin{sageoutput}
[[a == 4, b == -3, c == 5]]
\end{sageoutput}
In the cases where we will have a lot of possible solutions, it may be good to name the solution list using a variable and then asking for parts of the list:%
\begin{sageinput}
answer = solve( x^6 - 21*x^5 + 175*x^4 - 735*x^3 + 1624*x^2 - 1764*x + 720 == 0, x)
answer
\end{sageinput}
\begin{sageoutput}
[x == 5, x == 6, x == 4, x == 2, x == 3, x == 1]
\end{sageoutput}
Since SageMath is built out of Python, it uses Python's convention of numbering list elements starting from 0 and not from 1.%
\begin{sageinput}
answer[0]
\end{sageinput}
\begin{sageoutput}
x == 5
\end{sageoutput}
\begin{sageinput}
answer[4]
\end{sageinput}
\begin{sageoutput}
x == 3
\end{sageoutput}
\begin{sageinput}
answer[-1] # always gives the last element
\end{sageinput}
\begin{sageoutput}
x == 1
\end{sageoutput}
... and a last reminder that the \mono{solve} command is not restricted to polynomial equations.%
\begin{sageinput}
solve( ln( x^2 ) == 5/3, x )
\end{sageinput}
\begin{sageoutput}
[x == -e^(5/6), x == e^(5/6)]
\end{sageoutput}
As a last piece, there are lots of ways to manipulate function displays.%
\begin{sageinput}
# Logs
f(x) = log(x^2 * sin(x) / sqrt(1 + x))
print("Original function:")
f.show()
print("This form is easier to work with:")
show(f.expand_log())
print("Simplify expanded form:")
show(f.expand_log().simplify_log())
# Rational functions
f(x) = (x + 1) / (x^2 + x)
print("Original function:")
f.show()
print("Simplified:")
show(f.simplify_rational())
\end{sageinput}
\end{subsectionptx}
\end{sectionptx}
\end{chapterptx}
 %
%
\typeout{************************************************}
\typeout{Chapter 4 Basic programming}
\typeout{************************************************}
%
\begin{chapterptx}{Basic programming}{}{Basic programming}{}{}{x:chapter:basic-programming}
\begin{introduction}{}%
SageMath is built on Python, which means we can go beyond the one-line computational commands we've learned so far, to write programs with sequences of instructions.%
\par
What we present here are the most basic programming constructs; those who are fluent in another programming language (such as C++) will find many familiar structures here.%
\end{introduction}%
%
%
\typeout{************************************************}
\typeout{Section 4.1 Basic Sage\slash{}Python syntax}
\typeout{************************************************}
%
\begin{sectionptx}{Basic Sage\slash{}Python syntax}{}{Basic Sage\slash{}Python syntax}{}{}{x:section:basic-syntax}
Instructions are generally processed line by line. The hashtag \mono{\#} is considered by Python to begin a comment, until the end of that line. A semicolon \mono{;} separates several instructions typed on the same line, although if we're looking to see output, we have to use the \mono{print} command on each.%
\begin{sageinput}
print(2*3); print(3*4); print(4*5)  # one comment, three results
\end{sageinput}
\begin{sageoutput}
6
12
20
\end{sageoutput}
In the case where we have a command that's overlong, SageMath will continue type to the right and put a scrollbar in. Another option if we don't wish to scroll is to end a line with a backslash and continue the command on the next line. (The backslash is ignored by SageMath.)%
\begin{sageinput}
123 + \
345
\end{sageinput}
\begin{sageoutput}
468
\end{sageoutput}
%
%
\typeout{************************************************}
\typeout{Subsection 4.1.1 Function calls}
\typeout{************************************************}
%
\begin{subsectionptx}{Function calls}{}{Function calls}{}{}{g:subsection:id16}
To evaluate a function, its arguments should be put inside parentheses -{}-{} for example, \mono{cos(pi)}. If a function has no argument, we include empty parentheses. If we simply type a function without an argument or parentheses, no computation is performed.%
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 4.1.2 More about variables}
\typeout{************************************************}
%
\begin{subsectionptx}{More about variables}{}{More about variables}{}{}{g:subsection:id17}
As seen previously, SageMath denotes the assignment of a value to a variable by the equals sign. The expression to the right of the equals sign is first evaluated, then its value is saved in the variable whose name is on the left. Thus we have%
\begin{sageinput}
y = 3; y = 3*y + 1; y = 3*y + 1; y
\end{sageinput}
\begin{sageoutput}
31
\end{sageoutput}
The \mono{del x} command discards the value assigned to the variable \(x\), and the function call \mono{reset()} recovers the initial Sage state.%
\par
Several variables can be assigned simultaneously, which differs from sequential assignments.%
\begin{sageinput}
a, b = 10, 20 # (a,b) = (10,20) and [10,20] also possible
\end{sageinput}
\begin{sageinput}
a, b = b, a
a, b
\end{sageinput}
\begin{sageoutput}
(20, 10)
\end{sageoutput}
The assignment \mono{a, b = b, a} is equivalent to swapping the values of \(a\) and \(b\) using an auxiliary variable.%
\begin{sageinput}
temp = a; a = b; b = temp # equivalent to a, b = b, a
(a, b)
\end{sageinput}
\begin{sageoutput}
(10, 20)
\end{sageoutput}
We can also assign the same value to several variables simultaneously.%
\begin{sageinput}
a = b = c = 0
(a, b, c)
\end{sageinput}
\begin{sageoutput}
(0, 0, 0)
\end{sageoutput}
The instructions \mono{x += 5} and \mono{n *= 2} are respectively equivalent to \mono{x = x+5} and \mono{n = n*2}.%
\par
The comparison between two objects is performed by the double-equals sign \mono{==}.%
\begin{sageinput}
print(2 + 2 == 2^2)
print(3 * 3 == 3^3)
\end{sageinput}
\begin{sageoutput}
True
False
\end{sageoutput}
\end{subsectionptx}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 4.2 Algorithmics}
\typeout{************************************************}
%
\begin{sectionptx}{Algorithmics}{}{Algorithmics}{}{}{x:section:algorithmics}
In many ways, learning to program in SageMath or Python is very similar to learning the basics of English or another spoken or written language. There are very simple instructions at the base -{}-{} things like assigning a value to a variable, or getting the result of a computation. There are also compound instructions, like loops and conditionals, that are made up of several instructions, which could be simple or compound themselves.%
%
%
\typeout{************************************************}
\typeout{Subsection 4.2.1 Loops}
\typeout{************************************************}
%
\begin{subsectionptx}{Loops}{}{Loops}{}{}{g:subsection:id18}
An \emph{enumeration loop} performs the same computation for all integer values of some index \(k\in\{a,\dots,b\}\). For example:%
\begin{sageinput}
for k in [1..5]:
	print(7*k)
\end{sageinput}
\begin{sageoutput}
7
14
21
28
35
\end{sageoutput}
The colon at the end of the first line tells SageMath that the block of instructions begins on the next line, and evaluates the product \(7k\) for each successive value of \(k\) (1, 2, 3, 4, 5). At each iteration, SageMath outputs the product \(7k\) via the \mono{print} command.%
\par
In this example, the repeated instruction block contains a single instruction, which is indented with respect to the first line. Indenting is extremely important in SageMath and Python, as there are no \mono{begin} ... \mono{end} commands for blocks of instructions. Note that SageMath automatically indented the line after the \mono{for} command.%
\par
The following two pieces of code yield different results due to different indenting:%
\begin{sageinput}
S = 0
for k in [1..3]:
	S = S + k
S = 2*S
S
\end{sageinput}
\begin{sageoutput}
12
\end{sageoutput}
\begin{sageinput}
S = 0
for k in [1..3]:
	S = S + k
	S = 2*S
S
\end{sageinput}
\begin{sageoutput}
22
\end{sageoutput}
In the first block, the instruction \mono{S = 2*S} is executed only once at the end of the loop, while in the second it is executed at every iteration, which explains the different results:%
\begin{equation*}
S = (0+1+2+3)\cdot 2 = 12 \qquad S = ((((0+1)\cdot 2)+2)\cdot 2) + 3)\cdot 2 = 22.
\end{equation*}
(Note that we can stop typing code in as part of a loop simply by hitting backspace at the start of a line.)%
\par
This kind of loop will be useful to compute a given term of a recurrence.  The syntax is very simple and can be used without any problem for thousands, tens of thousands, or hundreds of thousands of iterations.  The main problem is that it constructs the list of all possible values of the loop variable first before executing the instructions in the block.  Some of the options below can make the repetitions go faster.%
\par
\begin{tableptx}{\textbf{}}{g:table:id19}{}%
\centering%
{\tabularfont%
\begin{tabular}{ll}
\multicolumn{2}{l}{\textbf{Iteration functions of the \mono{..range} for \mono{a}, \mono{b}, \mono{c} integers}}\tabularnewline\hrulethick
\mono{for k in [a..b]: ...}&constructs the list of SageMath integers \(a\le k\le b\)\tabularnewline[0pt]
\mono{for k in srange (a, b): ...}&constructs the list of SageMath integers \(a\le k < b\)\tabularnewline[0pt]
\mono{for k in range (a, b): ...}&constructs a list of Python integers (\mono{int})\tabularnewline[0pt]
\mono{for k in xrange (a, b): ...}&enumerates Python integers (\mono{int}) without\tabularnewline[0pt]
&explicitly constructing the corresponding list\tabularnewline[0pt]
\mono{for k in sxrange (a, b): ...}&enumerates SageMath integers without constructing a list\tabularnewline[0pt]
\mono{[a,a+c..b], [a..b, step=c]}&SageMath integers \(a\), \(a+c\), \(a+2c\), \(\dots\) as long as \(a+kc\le b\)\tabularnewline[0pt]
\mono{..range(b)}&equivalent to \mono{.. range (0, b)}\tabularnewline[0pt]
\mono{..range(a, b, c)}&sets the iteration increment to \(c\) instead of 1\tabularnewline\hrulethick
\end{tabular}
}%
\end{tableptx}%
%
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 4.2.2 While loops}
\typeout{************************************************}
%
\begin{subsectionptx}{While loops}{}{While loops}{}{}{g:subsection:id20}
The other kind of loops are \mono{while} loops. The difference here is that, as opposed to enumeration loops, rather than execute a set of instructions a fixed number of times, SageMath will execute the instructions based on a given condition being true.%
\begin{sageinput}
S = 0; k = 0   # The sum S is initialized to 0
while e^k <= 10^6:  # e^13 <= 10^6 < e^14
	S = S + k^2  # accumulates the squares k^2
	k = k + 1
S
\end{sageinput}
\begin{sageoutput}
819
\end{sageoutput}
A connection you may have noticed if you've taken Calculus II (or soon will notice) is the connection between loops and mathematical constructs like sums and sequences. In fact what we just computed was%
\par
%
\begin{equation*}
S = \sum_{\substack{k\in\mathbb{N}\\e^k\le 10^6}} k^2 = \sum_{k=1}^{13} k^2 = 819, 
\qquad e^{13} = 442413\le 10^6 < e^{14} = 1202604
\end{equation*}
%
\par
Notice that there are two instructions inside the loop block: one to accumulate the new square, and the next to move the index \(k\) to the next value.%
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Exercises 4.2.3 Exercises}
\typeout{************************************************}
%
\begin{exercises-subsection}{Exercises}{}{Exercises}{}{}{g:exercises:id21}
\begin{divisionexercise}{1}{}{}{g:exercise:id22}%
Use a \mono{while} loop to solve the following problem: With \(x = 10000\), determine the unique integer \(n\) such that \(2^n\le x < 2^{n+1}\).\end{divisionexercise}%
\begin{divisionexercise}{2}{}{}{g:exercise:id23}%
Compute the sum of the first 1001 positive integers. Print only the final total.\end{divisionexercise}%
\begin{divisionexercise}{3}{}{}{g:exercise:id24}%
Use a loop to investigate \(\lim_{x\to 8} e^{1/(8-x)}\). In other words, find a way to produce values for \(f(x) = e^{1/(8-x)}\) as \(x\to 8\). (Don't forget we're checking a two-sided limit. A plot may be helpful.)\end{divisionexercise}%
\end{exercises-subsection}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 4.3 More Algorithmics}
\typeout{************************************************}
%
\begin{sectionptx}{More Algorithmics}{}{More Algorithmics}{}{}{x:section:more-algorithmics}
When we use loops to repeat instructions, we can have a loop that carries on longer than we wish. For instance, we may be looking for the first instance of an inequality to be true. We find it, but the loop carries on for several more iterations anyway. With \mono{while} loops, we can accidentally write code so that the condition for the loop to terminate never becomes true, and computation goes on and on and on.%
%
%
\typeout{************************************************}
\typeout{Subsection 4.3.1 Aborting a loop execution}
\typeout{************************************************}
%
\begin{subsectionptx}{Aborting a loop execution}{}{Aborting a loop execution}{}{}{g:subsection:id25}
The \mono{for} and \mono{while} loops repeat a given number of times the same instructions. The \mono{break} command inside a loop interrupts it before its end, and the \mono{continue} command goes directly to the next iteration.  Those commands allow to check the terminating condition at every place in the loop.%
\par
The four examples below determine the smallest determine the smallest positive integer \(x\) satisfying \(\log(x+1)\le x/10\).%
\begin{sageinput}
for x in [1.0..100.0]:
	if log(x+1) <= x/10:
		break
x
\end{sageinput}
\begin{sageoutput}
37.0000000000000
\end{sageoutput}
\begin{sageinput}
x = 1.0
while log(x+1) > x/10:
  		x = x + 1
x
\end{sageinput}
\begin{sageoutput}
37.0000000000000
\end{sageoutput}
\begin{sageinput}
while log(x+1) > x/10 and x < 100:
  		x = x + 1
x
\end{sageinput}
\begin{sageoutput}
37.0000000000000
\end{sageoutput}
\begin{sageinput}
x = 1.0
while True:
	if log(x+1) > x/10:
		x = x+1
		continue
	break
x
\end{sageinput}
\begin{sageoutput}
37.0000000000000
\end{sageoutput}
The first of the four examples uses a \mono{for} loop with at most 100 tries which terminates terminates once the first solution is found; the second program looks for the smallest solution and might not terminate if the condition is never fulfilled; the third is equivalent to the first one with a more complex loop condition; finally the fourth has an unnecessarily complex structure, whose unique goal is to exhibit the \mono{continue} command. In all cases the final value \(x\) is 37.0.%
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 4.3.2 Conditionals}
\typeout{************************************************}
%
\begin{subsectionptx}{Conditionals}{}{Conditionals}{}{}{g:subsection:id26}
Notice that we had a new keyword -{}-{} \mono{if} -{}-{} in the first example.  The last two lines are an example of a \emph{conditional}.  This is a test that enables us to execute code based on the result of a boolean (true\slash{}false) condition.  Some possible examples of the syntax are:%
\par
%
\begin{codedisplay}

		if a condition:
			an instruction sequence
		
\end{codedisplay}
%
\begin{codedisplay}

		if a condition:
			an instruction sequence
		else:
			another instruction sequence
		
\end{codedisplay}
%
 As an example, there is the famous Collatz sequence defined by:\par
%
\begin{equation*}
x_0 \in \mathbb{N}\setminus\{0\}, \qquad x_{n+1} = \begin{cases}
x_n/2 & \text{if } x_n \text{ is even} \\
3x_n + 1 & \text{if } x_n \text{ is odd}
\end{cases}
\end{equation*}
%
\par
The Collatz conjecture (which is unsolved) says that for all possible starting values \(x_0\), the sequence will eventually reach a 1, after which it will cycle 4, 2, 1, 4, 2, 1 ... forever.%
\begin{sageinput}
x = 6; n = 0
while x != 1:    # the test x <> 1 is equivalent
    if x%2 == 0: # the operator % yields the remainder
        x = x//2 # //: division quotient
    else:
        x = 3*x + 1
    n = n + 1
    print(n,x)
\end{sageinput}
We check whether \(x_n\) is even by seeing whether the remainder of the division of \(x_n\) by 2 is 0.  The variable \(n\) at the end of the block is the number of iterations. The loop ends as soon as \(x_n = 1\).  So this result says that if \(x_0 = 6\) then \(x_8 = 1\), and \(8 = \min\{p\in \mathbb{N}\mid x_p = 1\}\).%
\par
The \mono{if} instruction also allows nested tests in the \mono{else} branch using the \mono{elif} (short for \emph{else if}) keyword. These two following structures would then be equivalent:%
%
\begin{codedisplay}

if a condition cond1:
	an instruction sequence inst1
else:
	if a condition cond2:
		an instruction sequence inst2
	else:
		if a condition cond3:
			an instruction sequence inst3
		else:
			in all other cases inst4

\end{codedisplay}
%
\begin{codedisplay}

if cond1:
	inst1
elif cond2:
	inst2
elif cond3:
	inst3
else:
	inst4

\end{codedisplay}
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 4.3.3 Procedures and Functions}
\typeout{************************************************}
%
\begin{subsectionptx}{Procedures and Functions}{}{Procedures and Functions}{}{}{g:subsection:id27}
As in other computer languages, we can define our own procedures and functions, using the \mono{def} command whose syntax we detail below. (The difference between a function and a procedure is that a function always returns a result, whereas a procedure does not.) Either can be defined to take as input one or several arguments, or none at all. For instance, we can define the function that takes \(x\) and \(y\) to \(x^2+y^2\) in this way:%
\begin{sageinput}
var('x y')
fct1(x,y) = x^2 + y^2
\end{sageinput}
\begin{sageinput}
var('a')
fct1(a,2*a)
\end{sageinput}
\begin{sageoutput}
5*a^2
\end{sageoutput}
By default, all variables appearing in a function are local variables.  That is, they are created at each call to the function, used as needed within the function, and destroyed at the end of the function, and do not interact with other variables of the same name.  In particular, global variables (variables used outside the function) are not modified.%
\begin{sageinput}
def foo(u):
   	t = u^2
   	return t*(t+1)
\end{sageinput}
\begin{sageinput}
t = 1; u = 2
foo(3), t, u
\end{sageinput}
\begin{sageoutput}
(90, 1, 2)
\end{sageoutput}
It \emph{is} possible to modify a global variable from within a function, using the \mono{global} keyword.%
\begin{sageinput}
a = b = 1
def f():
    global a
    a = b = 2
f(); a, b
\end{sageinput}
\begin{sageoutput}
(2, 1)
\end{sageoutput}
\end{subsectionptx}
\begin{example}{Working with Coins.}{g:example:id28}%
We're going to start with a very easy subroutine, which would be part of the programming of a vending machine or a cash register.  It is going to reply with the dollar value for some number of quarters, dimes, nickels, and pennies, which of course have respective values \textdollar{}0.25, \textdollar{}0.10, \textdollar{}0.05, and \textdollar{}0.01.  This is a simple task, so that we can concentrate on the programming rather than the underlying mathematics.%
\begin{sageinput}
def coinCount( quarters,dimes,nickels,pennies ):
   """
   This subroutine takes in data about a pile of change, with the four parameters being
   the number of quarters, dimes, nickels, and pennies.  Then the total dollar value of
   these is reported.  The quantities are assumed to be natural numbers.  Please do 
   not use complex numbers as inputs, as it will horrify a user to find out that some of 
   their money is imaginary.
   """
   total = quarters*0.25 + dimes*0.10 + nickels*0.05 + pennies*0.01
   print("That's a total of $"), 
   print(total)
\end{sageinput}
The first line, with the \mono{def} command, signals Python and Sage that we're about to define a new subroutine. We follow this immediately with the name of the subroutine, and then a list of the variables needed in that subroutine. Here, we have variables for quarters, dimes, nickels, and pennies. While in algebra, variables tend to be a single letter -{}-{} in programming, we use words so that we don't have to remember what each variable stands for. The colon is very important. It indicates that the next few commands are subordinate to the \mono{def} statement. The indentation shows specifically which statements are subordinate.%
\par
After that, on the second line, we have a formula that computes the total value of the coins. Each coin is multiplied by its value in dollars, and the total is placed in the variable which is unsurprisingly called "total." The third line and the fourth line print the amounts in a nicely formatted human-readable way. (Note that there's a description of the subroutine at the top, set off by triple quotation marks.)%
\par
We can test our subroutine with 5 quarters, 4 dimes, 3 nickels, and 2 pennies.%
\begin{sageinput}
coinCount(5,4,3,2)
\end{sageinput}
\begin{sageoutput}
That's a total of $
1.82000000000000
\end{sageoutput}
It is important to remember that order matters.  Consider the following three calls to this function.%
\begin{sageinput}
coinCount(1, 3, 2, 1)
\end{sageinput}
\begin{sageoutput}
That's a total of $
0.660000000000000
\end{sageoutput}
\begin{sageinput}
coinCount(1, 1, 2, 3)
\end{sageinput}
\begin{sageoutput}
That's a total of $
0.480000000000000
\end{sageoutput}
\begin{sageinput}
coinCount(1, 2, 3, 1)
\end{sageinput}
\begin{sageoutput}
That's a total of $
0.610000000000000
\end{sageoutput}
As you can see, all three calls are asking about different piles of change, and those piles will have different total values. You could imagine that someone using the subroutine on three different days, who has forgotten the ordering, might guess the ordering and input those three lines above. The output produces below illustrates the point: you get a wrong answer if you put the parameters in the wrong order.%
\par
Unlike most computer languages, Python has a solution for those who cannot remember orderings well. Using the following notation, we label each value with the variable that we hope it will be assigned to. We will get the same answer each time.%
\begin{sageinput}
coinCount( dimes=3, nickels=2, pennies=1, quarters=1 )
coinCount( quarters=1, pennies=1, nickels=2, dimes=3 )
coinCount( pennies=1, nickels=2, dimes=3, quarters=1 )
\end{sageinput}
\begin{sageoutput}
That's a total of $
0.660000000000000
That's a total of $
0.660000000000000
That's a total of $
0.660000000000000
\end{sageoutput}
This is a very nice service!  The one thing that Python and Sage will always ding us for are typos or misspellings of variables.%
\begin{sageinput}
coinCount( dimes=3, nickels=2, pennies=1, quaters=1 )
\end{sageinput}
\begin{sageoutput}
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[1], line 1
----> 1 coinCount( dimes=Integer(3), nickels=Integer(2), pennies=Integer(1), quaters=Integer(1) )

TypeError: coinCount() got an unexpected keyword argument 'quaters'
\end{sageoutput}
\end{example}
\begin{inlineexercise}{}{g:exercise:id29}%
Simulate a cash register as follows. Suppose a small foodstand in a subway station sells sodas (\textdollar{}1.50 each), bananas (\textdollar{}0.75 each), sandwiches of various types (all \textdollar{}3.75 each), and bottles of water (\textdollar{}2 each). Write a subroutine that takes five inputs: the number of sodas, bananas, sandwiches and bottles of water, as well as the amount of cash tendered (for example, \textdollar{}20 or \textdollar{}10). Your program should tell the user how much change, in dollars and cents, is therefore due.\end{inlineexercise}%
\begin{inlineexercise}{Designing Aquariums.}{g:exercise:id30}%
Now we're going to write a subroutine that is suitable for a company that builds custom display aquariums for use in dentist's offices and other upscale businesses. Customers come with orders and the cost must be correctly calculated, based on the sizes of the six panels which comprise the rectangular aquarium.%
\par
It turns out that the particular materials that the company is using have the following costs:%
%
\begin{itemize}[label=\textbullet]
\item{}The bottom of the aquarium is metal, and costs 1.3 cents\slash{}sq in.%
\item{}The top of the aquarium is plastic, and costs half a cent\slash{}sq in.%
\item{}The sides of the aquarium are glass, and cost 5 cents\slash{}sq in.%
\end{itemize}
Given a customer preference for the volume of the aquarium, there are many choices of dimensions and they will have substantially different costs. Consider a customer who wants a 12,000 cubic inch aquarium. (Note that 12,000 cubic inches is about 52 gallons so that is not a very large aquarium at all.) We can compute the following prices:%
%
\begin{itemize}[label=\textbullet]
\item{}A choice of \(20\times 30\times 20\) has a cost of \textdollar{}110.80.%
\item{}A choice of \(40\times 30\times 10\) has a cost of \textdollar{}91.60.%
\item{}A choice of \(60\times 20\times 10\) has a cost of \textdollar{}101.60.%
\item{}A choice of \(80\times 15\times 10\) has a cost of \textdollar{}116.60.%
\end{itemize}
Those prices were computed using the \mono{analyzeAquariumDesign} subroutine, which is found below. The commands calling the subroutine are found below the code.%
\begin{sageinput}
top_cost = 0.5
bottom_cost = 1.3
side_cost = 5

def analyzeAquariumDesign( length, width, height):
    """
    Here the dimensions of an aquarium are the inputs. The
    sizes of the six panels that form the rectangular aquarium
    will be printed on the screen, along with their costs. The
    costs are computed in terms of the areas of those panels and 
    the global variables top_cost, bottom_cost, and side_cost.
    Finally, the volume and the total cost are displayed.
    """
    bottom_top_area = length*width
    front_back_area = length*height
    left_right_area = width*height
    
    print ("The left/right panels have an area of", left_right_area,
           "costing $", round(side_cost*left_right_area*0.01,2))
    print ("The front/back panels have an area of", front_back_area,
           "costing $", round(side_cost*front_back_area*0.01,2))
    print ("The top panel has an area of", bottom_top_area,
           "costing $", round(top_cost*bottom_top_area*0.01,2))
    print ("The bottom panel has an area of", bottom_top_area, 
           "costing $", round(bottom_cost*bottom_top_area*0.01,2),"\n")
    
    print ("The total volume is", N( length*width*height,digits=2 ),"\n")
    
    cost = top_cost*bottom_top_area + bottom_cost*bottom_top_area + \
    2*front_back_area*side_cost + 2*left_right_area*side_cost
    
    print ("The total cost is $", round(cost*0.01,ndigits=2),"\n")
\end{sageinput}
\begin{sageinput}
analyzeAquariumDesign( 20, 30, 20 )
analyzeAquariumDesign( 40, 30, 10 )
analyzeAquariumDesign( 60, 20, 10 )
analyzeAquariumDesign( 80, 15, 10 )
\end{sageinput}
\begin{sageoutput}
The left/right panels have an area of 600 costing $ 30.0
The front/back panels have an area of 400 costing $ 20.0
The top panel has an area of 600 costing $ 3.0
The bottom panel has an area of 600 costing $ 7.8 

The total volume is 12000. 

The total cost is $ 110.8 

The left/right panels have an area of 300 costing $ 15.0
The front/back panels have an area of 400 costing $ 20.0
The top panel has an area of 1200 costing $ 6.0
The bottom panel has an area of 1200 costing $ 15.6 

The total volume is 12000. 

The total cost is $ 91.6 

The left/right panels have an area of 200 costing $ 10.0
The front/back panels have an area of 600 costing $ 30.0
The top panel has an area of 1200 costing $ 6.0
The bottom panel has an area of 1200 costing $ 15.6 

The total volume is 12000. 

The total cost is $ 101.6 

The left/right panels have an area of 150 costing $ 7.5
The front/back panels have an area of 800 costing $ 40.0
The top panel has an area of 1200 costing $ 6.0
The bottom panel has an area of 1200 costing $ 15.6 

The total volume is 12000. 

The total cost is $ 116.6
\end{sageoutput}
\end{inlineexercise}%
\end{sectionptx}
\end{chapterptx}
\end{partptx}
%
%
\typeout{************************************************}
\typeout{Part II Mathematical Modeling}
\typeout{************************************************}
%
\begin{partptx}{Mathematical Modeling}{}{Mathematical Modeling}{}{}{x:part:part-modeling-intro}
 %
%
\typeout{************************************************}
\typeout{Chapter 5 Introduction to Mathematical Modeling}
\typeout{************************************************}
%
\begin{chapterptx}{Introduction to Mathematical Modeling}{}{Introduction to Mathematical Modeling}{}{}{x:chapter:intro-to-modeling}
\begin{introduction}{}%
Every student of mathematics has done some “mathematical modeling” in his\slash{}her educational career. These instances of mathematical modeling are typically called “applications” and are used to illustrate how mathematics is implemented in the “real world.”%
\par
In most math classes, the main goal is to learn the theory of some particular mathematical discipline. The applications are used to help achieve this goal by providing a more concrete context in which to study and understand the theory. For instance, in Calculus I, the real goal is to understand the idea of the limit and the derivative. An applied maximization problem is used to motivate the idea of the derivative and to provide practice in calculating and interpreting derivatives.%
\par
In mathematical modeling, the opposite is true. Here we will start with some “real world” problem and use mathematical theory and techniques to better understand the phenomena behind the problem.%
\end{introduction}%
%
%
\typeout{************************************************}
\typeout{Section 5.1 Definitions}
\typeout{************************************************}
%
\begin{sectionptx}{Definitions}{}{Definitions}{}{}{x:section:basic-definitions}
To define the phrase \emph{mathematical modeling}, we will first define the term model. The word model is used frequently in everyday language.We talk about model airplanes, model houses, models on a runway, etc. What does the term model mean in a mathematical sense?%
\par
Lucas (Lucas, William F., The Impact and Benefits of Mathematical Modeling, in \emph{Applied Mathematical Modeling} (D.R Shier and K.T. Wallenius eds.), Chapman and Hall\slash{}CRC, 1999, pg. 5) defines a model as “a simpler realization or idealization of some more complex reality.” The real world is a very complex place. To better understand it, we need to try to simplify it to a reasonable degree, describe the simplification in ways we can understand and work with, and then study the simplification. This is what we call \emph{modeling.}%
\par
A \emph{mathematical model} then can be defined as a model constructed using mathematical terms, symbols, and ideas. Giordano et. al. (Frank R. Giordano, M. D. Weir, and W. P. Fox, \emph{A First Course in Mathematical Modeling}, Third ed., Thomson Brooks\slash{}Cole, 2003, pg. 54) defines a mathematical model as “a mathematical construct designed to study a particular real world system or phenomenon.” Mathematical models can take many different forms. They may involve equations, inequalities, differential equations, matrices, logic, or any other type of “mathematical” idea.%
\par
The key idea is that we use mathematics to describe a portion of the real world. Therefore, a very simple but general definition of the process of mathematical modeling is:%
\begin{definition}{}{g:definition:id31}%
\terminology{Mathematical modeling} is the application of mathematics to real world problems.%
\end{definition}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 5.2 Purpose}
\typeout{************************************************}
%
\begin{sectionptx}{Purpose}{}{Purpose}{}{}{x:section:purpose}
Why do we do mathematical modeling? Since we want to answer a question about real world phenomena, we could just sit back, observe, and take notes. Suppose we put 500 bacteria in a Petri dish. The next day we count 525 in the dish, and the next we count 551.%
\par
Obviously, the number of bacteria is growing. Based on this observation, we might ask these questions:%
%
\begin{itemize}[label=\textbullet]
\item{}How long will it be until there are 600 bacteria in the dish?%
\item{}If we need 900 bacteria for an experiment in 3 days, how many must we put into the dish today?%
\end{itemize}
We could answer each question as follows:%
%
\begin{itemize}[label=\textbullet]
\item{}Wait until we count 600 bacteria in the dish.%
\item{}Put 1 bacterium in a dish, 2 in a second dish, 3 in a third, etc. up to 900, wait 3 days, and determine which dish contains 900 bacteria.%
\end{itemize}
These solutions only require us to make simple observations of this real world phenomenon of bacteria growing in a Petri dish. However, these solutions are obviously impractical for they might require too much time or too many resources (the second solution requires 900 Petri dishes and a total of \(1 + 2 + \cdots + 900 = 405,450\) bacteria).%
\par
A much more practical approach to answering these questions is to construct a function that gives the number of bacteria in the dish in terms of time (i.e. construct a mathematical model of the bacteria growth).%
\par
In other situations, making observations may itself be a complicated ordeal. For instance, suppose we wanted to find the optimal mixture of doctors and nurses (i.e. the number of doctors and number of nurses) to staff a hospital emergency room. The concept of “optimal” may take into account several factors, including:%
%
\begin{itemize}[label=\textbullet]
\item{}Quality of patient care. (Do they get the care they need?)%
\item{}Patient waiting time. (Do they have to wait a long time?)%
\item{}Time spent with patients. (Are the doctors and nurses over-worked, or do they have too much “free time?”)%
\item{}Resources. (Is there enough floor space or are people running into each other?)%
\end{itemize}
One approach to finding an optimal number is to choose some mixture of doctors and nurses (say 3 doctors and 8 nurses), put them to work, and have a team of people record data for a series of weeks or months. Then choose another mixture (say 2 doctors and 7 nurses) and repeat the process. Repeat this until all possible combinations of doctors and nurses have been tried, analyze the data, and pick the optimal mixture.%
\par
This approach has many of the same problems as the bacteria growth problem. It would take too much time and be too expensive. Plus there are additional problems. If there are too few doctors and nurses on staff, patients might unnecessarily die. Plus we may not observe how the different mixtures handle infrequent events such as a bus crash that floods the ER with dozens of patients at once.%
\par
A much more practical solution would be to try to replicate the behavior of the ER on a computer (i.e. create a type of mathematical model called a simulation) where the numbers of doctors and nurses can be easily changed. Each mixture can be simulated for a long period of time under many different situations and at low cost. Plus, nobody dies.%
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 5.3 Process}
\typeout{************************************************}
%
\begin{sectionptx}{Process}{}{Process}{}{}{x:section:process}
We will illustrate the process of mathematical modeling with an example of modeling the number of bacteria in a Petri dish as described in \hyperref[x:section:purpose]{Section~{\xreffont\ref{x:section:purpose}}}.%
\par
%
\begin{description}
\item[{Step 1:}]State the question to be answered.%
\par
In many situations, this step is almost trivial; in others it is the most difficult part of the process. The question should be narrow enough to make the problem manageable, but not too narrow so that the problem is trivial. Initially we may want to focus on a narrow question, and then use the knowledge gained to broaden the question at a later time. The question should also be stated in precise mathematical terms so it can easily be translated into mathematical notation.%
\par
In this example we will answer the question “How long will it be until the number of bacteria in the dish reaches 600?”%
\item[{Step 2:}]Select the modeling approach.%
\par
In this step we determine the form of the model. In some situations this is easy to do; in others we may have several reasonable choices. Making the right choice requires at least some knowledge of all the possibilities. It also depends on the nature of the assumptions being made.%
\par
Often times this step begins with some simple observations. Note that we started with 500 bacteria. After 1 day, it increased by 25, which is 5\% of 500. After a second day it increased by 26, which is approximately 5\% of 525. The growth rate (or change per day) appears to be relatively constant. This suggests a simple relationship between the populations on consecutive days:%
\par
%
\begin{equation*}
\text{Population on one day}=\text{Population on previous day } + 5\%
\end{equation*}
%
\par
This relationship indicates that we may be able to derive a simple equation to model the population.%
\item[{Step 3:}]Define variables and parameters.%
\par
\emph{Variables} are quantities that could change within a problem. \emph{Parameters} are quantities that are constant within a problem, but that could change between problems of the same type. The first part on this step is to determine what variables and parameters are involved. This may be simple and obvious, or very complicated. Often times there are potentially hundreds of quantities involved. To make the model manageable, we need to make assumptions as to which are the most important and which can be ignored. At a later time we could add additional variables and parameters to refine the model.%
\par
In this example, variables include:%
\par
%
\begin{enumerate}
\item{}Time%
\item{}Population%
\item{}Temperature%
\item{}Amount of food present%
\item{}Amount of available space in the dish%
\end{enumerate}
%
\par
These are all values that change as the population grows. Since the initial observation did not give any information on temperature, food, or space, we will ignore these variables and focus on only time and population.%
\par
Possible parameters to consider include:%
\par
%
\begin{enumerate}
\item{}The initial population%
\item{}Growth rate (we will assume this is constant)%
\item{}Size of the dish%
\item{}Initial amount of food%
\end{enumerate}
%
\par
These are all values that are constant once we put the bacteria in the dish and allow them to grow. But if we consider a different dish with a different population of bacteria, they could change. Again, since we don’t know anything about the size of the dish or the amount of food, we will ignore these parameters.%
\par
The second part of this step is to choose symbols to represent the variables and parameters. For this example, let%
\par
%
\begin{equation*}
\begin{aligned}
n & = \text{time in days from the present }(n = 0, 1,\dots) \\
r & = \text{the growth rate (in decimal form)} \\
a_n & = \text{the population at the beginning of day }n \\
a_0 & = \text{the initial population}
\end{aligned}
\end{equation*}
%
\item[{Step 4:}]State the assumptions.%
\par
Making assumptions is an essential aspect of creating a valid and manageable model. Assumptions fall into many different categories. Some are used to simplify the model, such as those used to select the important variables. Some are needed to define relationships between the variables because the precise relationships are not known. Others are needed to determine the values of parameters when the exact values are not known.%
\par
Clearly stating the assumptions is an important part of interpreting and presenting the results. The results of a model are only as valid as the underlying assumptions. If the assumptions are unreasonable, then the conclusion will be unreasonable regardless of the precision of the mathematical analysis.%
\par
In this problem, we have already chosen to ignore temperature, size of the dish, and many other possible variables and parameters. This is a simplification. Furthermore, we will assume that the population growth is constant (\emph{i.e.} the population will increase 5\% each day).%
\item[{Step 5:}]Formulate the model.%
\par
This is where the “mathematics” starts. We have observed that the number of bacteria on day 1 is equal to the number on day 0 plus 5\%. The number on day 2 is equal to the number on day 1 plus 5\%, etc. In mathematical notation using our variables and parameters, we have%
\par
%
\begin{equation*}
\begin{aligned}
a_1 & = a_0 + r\,a_0 = (1+r)a_0 \\
a_2 & = a_1 + r\,a_1 = (1+r)a_1 \\
& \vdots \\
a_{n+1} & = a_n + r\,a_n = (1+r)a_n
\end{aligned}	
\end{equation*}
%
\par
This forms a recursively defined sequence. To form an explicit description of \(a_n\) in terms of \(n\), note that%
\par
%
\begin{equation*}
\begin{aligned}
a_1 & = (1+r)a_0 \\
a_2 & = (1+r)a_1 = (1+r)(1+r)a_0 = (1+r)^2 a_0 \\
a_3 & = (1+r)a_2 = (1+r)(1+r)^2 a_0 = (1+r)^3 a_0 \\
& \vdots \\
a_n & = (1+r)^n a_0
\end{aligned}
\end{equation*}
%
\par
This last equation is our model.%
\item[{Step 6:}]Solve the model and state the solution.%
\par
Here we use the term “solve” loosely. Solving a model may involve solving a single equation, as in this example, it may involve constructing a graph and qualitatively describing its behavior, or it may involve running a simulation several hundred times and summarizing the resulting data. The meaning of the term solve is relative to the type of model.%
\par
In this example, the question is “when will the population be 600?” In terms of our variables, this can be stated as “find \(n\) such that \(a_n = 600\).” This yields the equation%
\par
%
\begin{equation*}
600 = (1+0.05)^n\cdot 500
\end{equation*}
%
\par
Solving this equation using logarithms yields \(n\approx 3.7\). This means that at the beginning of the fourth day we will have over 600 bacteria. This is our solution.%
\par
Often times the results of a model are used to guide decisions. In many practical situations, such as in business or the military, the person doing the modeling is not the final decision maker. The final decision maker is a CEO or officer who is not a mathematician. Therefore, the solution should be stated in as non-technical language as reasonably possible.%
\item[{Step 7:}]Verify the model.%
\par
Verification is necessary to test the reasonableness of our assumptions. Typically we verify a model by comparing it to some real world data. Let’s suppose we let the bacteria grow for a total of 7 days and collect the data in \hyperref[x:table:bacteria-table]{Table~{\xreffont\ref{x:table:bacteria-table}}}. Next to the actual observed populations are the populations predicted by the model.%
\par
We see that on day 4, the actual population is just below 600. Even though the predicted population does not equal the actual population, our solution of 4 days is reasonable.%
\par
Note that on days 5 and 6, the actual and predicted populations differ considerably. The data indicates that the growth rate slows down. This means that our assumption of a constant growth rate is incorrect.%
\par
\begin{tableptx}{\textbf{}}{x:table:bacteria-table}{}%
\centering%
{\tabularfont%
\begin{tabular}{ccc}\hrulethick
\textbf{}&\textbf{Actual}&\textbf{Predicted}\tabularnewline[0pt]
\textbf{Day}&\textbf{Population}&\textbf{Population}\tabularnewline\hrulethin
0&500&500\tabularnewline[0pt]
1&525&525\tabularnewline[0pt]
2&551&551\tabularnewline[0pt]
3&575&579\tabularnewline[0pt]
4&598&608\tabularnewline[0pt]
5&610&638\tabularnewline[0pt]
6&620&670\tabularnewline\hrulethick
\end{tabular}
}%
\end{tableptx}%
%
\par
Our model is accurate up to day 4, but inaccurate for later days. This example illustrates that we must be very cautious about using data from the past to make predictions about the future.%
\item[{Step 8:}]Refine the model.%
\par
Refine means to improve the model in some way. One way to do this is to add variables that we chose to ignore in step 3 to make a more accurate model. Another way is to generalize the model so that it can be used to solve other similar problems. Either one will require us to repeat steps 3 – 7 to some degree.%
\par
We have already noted that the data indicates the growth rate slows down over time. This could be a result of diminishing food supplies or room to grow. These are two variables we chose to ignore.%
\par
One possible refinement is to redo the model incorporating these two variables. This would require additional observations and data to determine how these variables are related to the other variables. Another possible refinement is to use the available data to model a decreasing growth rate. We will illustrate how to do this in the next chapter.%
\par
A simple diagram that illustrates the basic process of mathematical modeling is given in \hyperref[x:figure:model-process]{Figure~{\xreffont\ref{x:figure:model-process}}}. The process begins in the upper left-hand corner with observations (or data). From this we get the basic problem we want to solve. We then make assumptions, construct the model, solve it using appropriate mathematical tools, and obtain a mathematical result. Then we must interpret the mathematical result in light of the assumptions to make our conclusions. We then verify the model using more observations.%
\par
\begin{figureptx}{}{x:figure:model-process}{}%
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{images/modelingprocess.png}
\end{image}%
\tcblower
\end{figureptx}%
%
\par
This figure also illustrates the cyclic nature of mathematical modeling. We rarely stop once we answer the original question. We continually repeat the process, to some extent, to test, refine, and implement the model.%
\par
The right half of this diagram is done in the “math world” and the left half is done in the “real world.” In the math world, we use the absolute certainty of mathematics. The real world contains no such certainties. Making assumptions and interpreting are necessary steps to move between these two worlds.%
\end{description}
%
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 5.4 Assumptions}
\typeout{************************************************}
%
\begin{sectionptx}{Assumptions}{}{Assumptions}{}{}{x:section:assumptions}
\emph{Every} model is based on some set of assumptions. Sometimes those assumptions are rather trivial and obvious, but most times they are significant enough to potentially affect the validity of the model. We will never be able to describe each component of a real world system exactly. Assumptions are needed to fill in these gaps, and whenever possible, the reasonableness of assumptions should be tested. In fact, assumptions are so important that any mention of a model should include the assumptions behind it.%
\par
Here are a few examples of well–known models and some of their underlying assumptions.%
\begin{example}{Range of an Electric Car.}{g:example:id32}%
When considering the purchase of an electric car, the first question most consumers ask is, “what’s the range?” The exact answer depends on many factors including the battery size and condition, driving style, vehicle speed, wind speed and direction, temperature, and elevation change. Any numeric answer to this question must be accompanied with many assumptions about these factors.%
\end{example}
\begin{example}{Carbon-14 Dating.}{g:example:id33}%
Carbon–14 dating methods are used to date organic material, such as a piece of bone, found at archaeological sites. The underlying mathematical model requires knowledge of the proportion of Carbon–14 originally present in the sample. Obviously we cannot measure this precisely, so we assume that this proportion is the same as in a modern bone. This assumption can’t be tested directly, but if a date can be confirmed via independent means, it would be an indication that the assumption is correct.%
\end{example}
\begin{example}{Newtonian Mechanics.}{g:example:id34}%
Newton’s second law says that the force exerted on an object is equal to its rest mass times the acceleration, or \(F = ma\). This was assumed to hold at any velocity. In the 20th century, it was discovered that for speeds approaching the speed of light, this rest mass must be replaced with the relativistic mass, which is larger.%
\end{example}
\begin{example}{Relativity.}{g:example:id35}%
Einstein’s theory of special relativity is really a mathematical model. It is based on several postulates (a type of assumption), one of which is that the speed of light in a vacuum is constant to any observer in an inertial frame of reference. These assumptions cannot be tested in every circumstance imaginable, but the results of Einstein’s theory can be tested. These results have been shown to be correct, so it suggests that the underlying assumptions are also correct.%
\end{example}
%
%
\typeout{************************************************}
\typeout{Exercises 5.4 Exercises}
\typeout{************************************************}
%
\begin{exercises-subsection-numberless}{Exercises}{}{Exercises}{}{}{g:exercises:id36}
\begin{divisionexercise}{1}{}{}{g:exercise:id37}%
Each part below describes a calculated number. Think about how this number was calculated and identify at least one assumption behind the calculation.\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}A consumer magazine reports that a laundry detergent costs \textdollar{}0.31 per load.%
\item{}An exercise bike displays the number of calories burned.%
\item{}A jogging pedometer measures the distance jogged.%
\item{}A dashboard display in a car shows that it can travel 220 miles on the remaining fuel in the tank.%
\item{}A small business owner predicts that his company will spend \textdollar{}500,000 on phone bills next year.%
\item{}A cooking magazine lists one ingredient for a recipe as 1-2 cups of shredded cheddar cheese. It then claims that each serving has 320 calories.%
\end{enumerate}
\end{divisionexercise}%
\begin{divisionexercise}{2}{}{}{g:exercise:id38}%
Identify at least two possible variables and two parameters involved in each of the following models. Clearly identify which is a variable and which is a parameter.\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}A biologist wants to model the population of foxes and rabbits in a forest over a period of time.%
\item{}A consumer wants to model the monthly balance in his credit card.%
\item{}A public health researcher wants to model the amount of alcohol in the bloodstream of a college student during an evening of partying.%
\item{}An ecologist wants to model the amount of pollution in a lake over a period of time.%
\item{}A market researcher wants to model the number of viewers of a TV show over the span of the season.%
\end{enumerate}
\end{divisionexercise}%
\begin{divisionexercise}{3}{}{}{g:exercise:id39}%
To predict the time at which the bacteria population in \hyperref[x:section:process]{Section~{\xreffont\ref{x:section:process}}} reached 600, we solved the equation \(600 = (1 + 0.05)^n \cdot 500\) and concluded that at the beginning of day 4 we will have over 600.\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}Show how this equation was solved for \(n\).%
\item{}A student argues that we should be more precise in our conclusion. She argues that we should say, “on day 3.736850652 there will be exactly 600 bacteria” because this is the value given by her calculator. How would you explain to her that such a level of precision is not appropriate?%
\end{enumerate}
\end{divisionexercise}%
\begin{divisionexercise}{4}{}{}{g:exercise:id40}%
A cashier at a supermarket can checkout, on average, 3 customers a minute (this is called the \emph{service rate}). Customers arrive, on average, 2 a minute (this is called the \emph{arrival rate}). The manager figures that since the service rate is greater than the arrival rate, customers will never have to wait in line. What assumptions is the manager making? Do these assumptions seem reasonable? What does this say about the validity of the conclusion?%
\end{divisionexercise}%
\begin{divisionexercise}{5}{}{}{g:exercise:id41}%
A college student plans to ask 100 different girls for a date. He calculates the number who will say yes with the following reasoning:%
\begin{quote}%
Since every girl can say yes or no, exactly half will say yes. Since half of 100 is 50, exactly 50 girls will say yes.\end{quote}
What, if anything, is faulty with this model? Explain.%
\end{divisionexercise}%
\begin{divisionexercise}{6}{}{}{g:exercise:id42}%
A model for the population of the United States (in millions) for the years 1800-1960 is%
%
\begin{equation*}
P(t) = 0.0063t^2 + 0.0719t + 5.0747
\end{equation*}
where \(t\) is the number of years since 1800. A student predicts that the population in the year 2050 will be \(P(250) \approx 416.8\) million. What assumption is the student making when doing this calculation? Do you think this assumption is reasonable? What does this say about the validity of the prediction?%
\end{divisionexercise}%
\end{exercises-subsection-numberless}
\end{sectionptx}
\end{chapterptx}
 %
%
\typeout{************************************************}
\typeout{Chapter 6 Proportionality and Geometric Similarity}
\typeout{************************************************}
%
\begin{chapterptx}{Proportionality and Geometric Similarity}{}{Proportionality and Geometric Similarity}{}{}{x:chapter:proportionality}
\begin{introduction}{}%
A \emph{model} is ``a simpler realization or idealization of some more complex reality.'' The real world is a very complex place. To better understand it, we need to try to simplify it to a reasonable degree, describe the simplification in ways we can understand and work with, and then study the simplification. This is what we call \emph{modeling.} A \emph{mathematical model} is a model constructed using mathematical terms, symbols, and ideas. Others have described it as "a mathematical construct designed to study a particular real world system or phenomenon."%
\end{introduction}%
%
%
\typeout{************************************************}
\typeout{Section 6.1 Scatter Plots and Lines of Best Fit in SageMath}
\typeout{************************************************}
%
\begin{sectionptx}{Scatter Plots and Lines of Best Fit in SageMath}{}{Scatter Plots and Lines of Best Fit in SageMath}{}{}{x:section:scatterplots}
One of the first steps in modeling is to make simplifying assumptions, and one of the most basic types of assumptions is that one variable is simply a constant multiple of the other. This type of relationship is called \emph{proportionality}.  We say that \(y\) is \emph{proportional} to \(x\) if there is a nonzero constant \(c\) such that \(y=cx\).  Note that if \(y=cx\), then \(x = \frac1{c}y\) so that \(x\) is proportional to \(y\).  That is, \(x\) is proportional to \(y\) if and only if \(y\) is proportional to \(x\). (The proportionality relationship is \emph{symmetric}.) So we simply say \(x\) and \(y\) are proportional.%
\par
This means that the graph of \(y\) versus \(x\) should form a straight line through the origin.%
\par
One famous proportionality relationship is \emph{Hooke's law}, which relates the force applied to a spring to the distance it is stretched or compressed.  Hooke's law simply states that \(d=kF\) where \(F\) is the force applied to a spring, \(d\) is the distance stretched or compressed, and \(k\) is a constant related to the stiffness of the spring.%
\par
Here is an example.  Suppose that we hang a bucket from a spring, fill the bucket with varying amounts of sand, and measure the distance the spring is stretched.  The results are recorded in \hyperref[x:table:newtontable]{Table~{\xreffont\ref{x:table:newtontable}}}.%
\par
\begin{tableptx}{\textbf{}}{x:table:newtontable}{}%
\centering%
{\tabularfont%
\begin{tabular}{ll}
\multicolumn{1}{c}{\textbf{Weight (newtons)}}&\multicolumn{1}{c}{\textbf{Distance (cm)}}\tabularnewline\hrulethick
\multicolumn{1}{c}{5}&\multicolumn{1}{c}{1.02}\tabularnewline[0pt]
\multicolumn{1}{c}{10}&\multicolumn{1}{c}{1.86}\tabularnewline[0pt]
\multicolumn{1}{c}{15}&\multicolumn{1}{c}{3.00}\tabularnewline[0pt]
\multicolumn{1}{c}{20}&\multicolumn{1}{c}{3.94}\tabularnewline[0pt]
\multicolumn{1}{c}{25}&\multicolumn{1}{c}{4.95}\tabularnewline[0pt]
\multicolumn{1}{c}{30}&\multicolumn{1}{c}{5.82}\tabularnewline[0pt]
\multicolumn{1}{c}{35}&\multicolumn{1}{c}{6.95}\tabularnewline[0pt]
\multicolumn{1}{c}{40}&\multicolumn{1}{c}{7.80}
\end{tabular}
}%
\end{tableptx}%
%
\par
We plot this data to (1) verify that Hooke's law holds for this spring and (2) find the constant of proportionality (the \emph{spring constant}).  This data comes from the real world, so it is subject to errors and uncertainty.  Therefore, we cannot expect the data to lie perfectly on a straight line as predicted by the idealized Hooke's law.  However, the data should lie \emph{very near} a straight line.  The slope of this line will be the spring constant.%
\par
First, we need to tell Sage about the data, using the following command which is an example of how to write lists in Sage and Python:%
\begin{sageinput}
datapoints = [(5, 1.02), (10, 1.86), (15, 3.00), (20, 3.94), (25, 4.95), (30, 5.82), (35, 6.95), (40, 7.80)]
\end{sageinput}
We note that we ordinarily would not enter points by hand like this because we'd likely have hundreds or thousands of them.  We would ordinarily read the points into Sage from a file.  We will learn how to do this down the road.  For a small list like this, it's fine to enter the points by hand as we did here.%
\par
Notice how the data, namely those eight points, are separated by commas and enclosed by brackets. This is an example of a list in Sage.  You can enclose any data with \mono{[} and \mono{]}, and separate the entries by commas to make a list.%
\par
Now we can easily make a scatter plot by just typing%
\begin{sageinput}
sp = scatter_plot(datapoints)
show(sp)
\end{sageinput}
We can certainly use trial and error and our eyeball to find the slope of the best fit line for this data.  But there is a mathematical criterion for best fit called \emph{least squares}. This principle gets a line of best fit by using calculus to minimize the sums of the squares of the distances between the real \(y\)-coordinates of our data, and the \(y\)-coordinates of the points on our proposed line. SageMath can do this to fit a linear model via its built-in \mono{find\_fit} command.%
\begin{sageinput}
var('k')
model(x) = k*x
find_fit(datapoints, model)
\end{sageinput}
\begin{sageoutput}
[k == 0.19629411764530547]
\end{sageoutput}
This says that the line of best fit is \(y = 0.19629411764530547x\).  We can plot this line with our scatter plot.%
\begin{sageinput}
sp + plot(0.19629411764530547*x, (x, 5, 40))
\end{sageinput}
We can use this relationship to approximate \(y\)-values for \(x\)-values within the range of our data. For example, when \(x = 13\), we have that \(y\) is approximately%
\begin{sageinput}
0.19629411764530547*13
\end{sageinput}
\begin{sageoutput}
2.551823529388971
\end{sageoutput}
Thus, when we have a weight of 13 newtons attached to the spring, the spring will be stretched approximately 2.55 cm.%
%
%
\typeout{************************************************}
\typeout{Subsection 6.1.1 Inverse Proportionality}
\typeout{************************************************}
%
\begin{subsectionptx}{Inverse Proportionality}{}{Inverse Proportionality}{}{}{g:subsection:id43}
Not all pairs of variables are proportional.  But some that don't initially appear to have that sort of relationship can be recast to become proportional.%
\par
Another well-known proportionality relationship is \emph{Boyle's Law}, which relates the volume of a gas to its pressure at a constant temperature,%
%
\begin{equation*}
V = \frac{k}{P}
\end{equation*}
where \(V\) denotes the volume of the gas, \(P\) denotes the pressure, and \(k\) is a constant.  To test Boyle's law, a student measures the pressure of a gas at different volumes while keeping the temperature of the gas constant.  The resulting data is below.%
\par
\begin{tableptx}{\textbf{}}{x:table:boylestable}{}%
\centering%
{\tabularfont%
\begin{tabular}{llllllllll}
\multicolumn{1}{cA}{\emph{Volume} (\(V\))}&\multicolumn{1}{c}{50}&\multicolumn{1}{c}{45}&\multicolumn{1}{c}{40}&\multicolumn{1}{c}{35}&\multicolumn{1}{c}{30}&\multicolumn{1}{c}{25}&\multicolumn{1}{c}{20}&\multicolumn{1}{c}{15}&\multicolumn{1}{c}{10}\tabularnewline\hrulethin
\multicolumn{1}{cA}{\emph{Pressure} (\(P\))}&\multicolumn{1}{c}{27.24}&\multicolumn{1}{c}{30.36}&\multicolumn{1}{c}{34.01}&\multicolumn{1}{c}{38.73}&\multicolumn{1}{c}{45.5}&\multicolumn{1}{c}{54.35}&\multicolumn{1}{c}{68.03}&\multicolumn{1}{c}{90.53}&\multicolumn{1}{c}{135.73}
\end{tabular}
}%
\end{tableptx}%
%
\par
We will use this data to verify Boyle's law and find the constant of proportionality for this gas.  Note that the law does not say that \(V\) is proportional to \(P\). It says that \(V\) is proportional to \(1/P\).  Therefore, we will plot \(V\) versus \(1/P\) and fit a straight line through the origin to this \emph{transformed} data.%
\begin{sageinput}
pvpoints = [(27.24, 50), (30.36, 45), (34.01, 40), (38.73, 35), (45.5, 30), (54.35, 25), (68.03, 20), (90.53, 15), (135.73, 10)]
sp = scatter_plot(pvpoints, axes_labels = ['$P$', '$V$'])
show(sp)
\end{sageinput}
This is clearly not linear.  We can transform the points as follows:%
\begin{sageinput}
ourpoints = [(1/P, V) for (P, V) in pvpoints]
sp = scatter_plot(ourpoints, axes_labels = ['$1/P$', '$V$'])
show(sp)
\end{sageinput}
We can now use a linear model as we did earlier to find the best fit constant \(k\).%
\begin{sageinput}
var('k')
model(x) = k*x
find_fit(ourpoints, model)
\end{sageinput}
\begin{sageoutput}
[k == 1361.6466604482955]
\end{sageoutput}
\begin{sageinput}
sp + plot(1361.6466604552695*x, (x, 0, 0.04))
\end{sageinput}
This shows that \(V\) is clearly proportional to \(1/P\) and the constant of proportionality is about 1362.  (Note that the constant of proportionality may be different for a different gas.)  In this case, we say that \(V\) and \(P\) are \emph{inversely proportional}.%
\par
Another way to do this particular model would be to change the model equation and use the original points.%
\begin{sageinput}
var('k')
model(x) = k/x
soln = find_fit(pvpoints, model, solution_dict=True)
\end{sageinput}
We've put an extra option on the \mono{find\_fit} command this time called \mono{solution\_dict}. This records the variables in the model in an internal table so that we don't have to copy and paste long numbers like we did earlier. So if we want to know the value of \(k\) that SageMath computed we ask for%
\begin{sageinput}
soln[k]
\end{sageinput}
\begin{sageoutput}
1361.6466604652283
\end{sageoutput}
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Exercises 6.1.2 Exercises}
\typeout{************************************************}
%
\begin{exercises-subsection}{Exercises}{}{Exercises}{}{}{g:exercises:id44}
\begin{divisionexercise}{1}{}{}{g:exercise:id45}%
For each of the data sets below, determine if it is reasonable to assume that \(y\) is proportional to \(x\). If it is, approximate the constant of proportionality. If it is not, describe why this assumption is not reasonable.%
\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}\begin{center}%
{\tabularfont%
\begin{tabular}{ccccccccc}\hrulethick
\multicolumn{1}{cA}{\(x\)}&1&1.1&1.2&1.3&1.4&1.5&1.6&1.7\tabularnewline\hrulethin
\multicolumn{1}{cA}{\(y\)}&1&1.22&1.44&1.69&1.96&2.25&2.56&2.89\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
\item{}\begin{center}%
{\tabularfont%
\begin{tabular}{ccccccccc}\hrulethick
\multicolumn{1}{cA}{\(x\)}&1&5&7&2&10&12&3&6\tabularnewline\hrulethin
\multicolumn{1}{cA}{\(y\)}&0.79&10.89&14.37&5.75&23.36&26.29&3.76&16.12\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
\item{}\begin{center}%
{\tabularfont%
\begin{tabular}{ccccccccc}\hrulethick
\multicolumn{1}{cA}{\(x\)}&2&6&9&15&7&25&39&4\tabularnewline\hrulethin
\multicolumn{1}{cA}{\(y\)}&26&20&18&26&6&19&20&13\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
\end{enumerate}
\end{divisionexercise}%
\begin{divisionexercise}{2}{}{}{g:exercise:id46}%
Determine which model best fits the data below.  Find the constant of proportionality for each model.%
%
\begin{equation*}
y = kx, \quad y = k\cdot \frac1{x}, \quad y = k x^2, \quad y = k\sqrt{x}, \quad y = k\cdot\frac1{x^3}
\end{equation*}
\begin{center}%
{\tabularfont%
\begin{tabular}{cccccc}
\multicolumn{1}{cA}{\(x\)}&0.5&0.7&0.9&1.2&1.5\tabularnewline\hrulethin
\multicolumn{1}{cA}{\(y\)}&7.8&3.5&2.2&0.85&0.36
\end{tabular}
}%
\end{center}%
\end{divisionexercise}%
\end{exercises-subsection}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 6.2 Modeling with Proportionality}
\typeout{************************************************}
%
\begin{sectionptx}{Modeling with Proportionality}{}{Modeling with Proportionality}{}{}{x:section:modeling-with-proportionality}
One important observation about a proportionality relationship is that if one of the variables increases, so does the other, and if one variable decreases, so does the other. (We saw this previously in the examples on spring force.) Whenever we encounter a situation where two variables increase or decrease at the same time, we should consider a proportionality relationship.%
\begin{example}{Population Growth.}{g:example:id47}%
In many situations involving populations, the larger the population, the faster it grows. This suggests a proportionality relationship between the population and the rate of growth. The table below shows the population (in thousands) of bacteria in a Petri dish at different points in time. The third column contains the change in population between time periods.%
\par
\begin{tableptx}{\textbf{}}{x:table:petri-pop-growth}{}%
\centering%
{\tabularfont%
\begin{tabular}{ccc}\hrulethick
\textbf{}&\textbf{Actual}&\textbf{Change in}\tabularnewline[0pt]
\textbf{Day}&\textbf{Population}&\textbf{Population}\tabularnewline[0pt]
\textbf{\(n\)}&\textbf{\(p_n\)}&\textbf{\(\Delta p_n = p_{n+1}-p_n\)}\tabularnewline\hrulethin
0&10.3&6.9\tabularnewline[0pt]
1&17.2&9.8\tabularnewline[0pt]
2&27&18.3\tabularnewline[0pt]
3&45.3&34.9\tabularnewline[0pt]
4&80.2&45.1\tabularnewline[0pt]
5&125.3&6.9\tabularnewline[0pt]
6&176.2&79.4\tabularnewline[0pt]
7&255.6&\tabularnewline\hrulethick
\end{tabular}
}%
\end{tableptx}%
%
\par
Observe that as \(n\) increases, \(p_n\) increases, and so does \(\Delta p_n\). This suggests that \(p_n\) is proportional to \(\Delta p_n\). A graph of \(\Delta p_n\) vs. \(p_n\) is produced with the following commands.%
\begin{sageinput}
poppoints = [(10.3, 6.9), (17.2, 9.8), (27, 18.3), (45.3, 34.9), (80.2, 45.1), (125.3, 50.9), (176.2, 79.4)]
sp = scatter_plot(poppoints, xmin = 0, xmax = 200, ymin = 0, ymax = 100, frame = True, axes_labels = ["Population", "Change in Population"])
sp
\end{sageinput}
(Note we can get nice looking axes labels by including the \mono{frame = True} option. Take it out and notice the difference.)%
\begin{sageinput}
var('k')
model(x) = k*x
soln = find_fit(poppoints, model,solution_dict=True)
sp + plot(soln[k]*x, 0, 200)
\end{sageinput}
\begin{sageinput}
soln[k]
\end{sageinput}
\begin{sageoutput}
0.4666257644974303
\end{sageoutput}
We see that the points do fall near a straight line through the origin, suggesting that proportionality is a reasonable assumption. The slope of this line is approximately 0.5. This gives a model that relates the population on one day, \(p_n\), to the population on the next, \(p_{n+1}\):%
%
\begin{equation*}
\Delta p_{n} = p_{n+1} - p_{n} = 0.5p_n \quad \Longrightarrow \quad p_{n+1} = 1.5p_n
\end{equation*}
This model predicts that the population grows by about 50\% each time period, which means the population will grow without bound. This seems unreasonable, so the model needs to be refined. We will do just this later in the course.%
\end{example}
\begin{example}{Radioactive Decay.}{g:example:id48}%
One-half of the amount of a radioactive substance decays after each half-life. Radioactive Carbon-14 (\({}^{14}\)C) has a half-life of 5715 years. If we start with 10 g of \({}^{14}\)C, the table below shows the amount of material remaining after each half-life along with the rate of change between time periods.%
\begin{center}%
{\tabularfont%
\begin{tabular}{ccc}\hrulethick
\textbf{Time (years)}&\textbf{Amount}&\textbf{Change}\tabularnewline\hrulethin
0&10&5\tabularnewline[0pt]
5,715&5&2.5\tabularnewline[0pt]
11,430&2.5&1.25\tabularnewline[0pt]
17,415&1.25&0.625\tabularnewline[0pt]
22,860&0.625&\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
Note that as the amount of \({}^{14}\)C decreases, the rate at which it decreases also changes. This suggests a proportionality relationship between the amount of \({}^{14}\)C and the rate at which it decreases.%
\par
If we let \(y(t)\) represent the amount of \({}^{14}\)C at time \(t\), this proportionality relationship gives the differential equation%
\par
%
\begin{equation*}
\frac{dy}{dt} = k\,y.
\end{equation*}
%
\par
That is, the derivative of \(y\) is a multiple of \(y\). The exponential function \(y(t) = Ce^{kt}\) solves the differential equation, where \(C\) is the initial amount of material.%
\end{example}
\begin{example}{Free-falling Object.}{g:example:id49}%
An object in free–fall encounters two basic forces. The first is its weight due to gravity. The second is air resistance which slows the rate of fall. Air resistance is typically negligible at low speeds so it is often not modeled. If we ignore air resistance, then the only force acting on the object comes from acceleration due to gravity. This leads to the simple differential equation%
\par
%
\begin{equation*}
\frac{dv}{dt} = g 
\end{equation*}
%
\par
where \(v(t)\) = the velocity of the object at time \(t\) and \(g = 9.8\,\text{m}/\text{sec}^2\) (the acceleration due to gravity). Solving this differential equation yields the model \(v(t) = gt + v_0\) where \(v_0\) is the initial velocity. This model predicts that the velocity grows without bound, which is inaccurate. Physics tells us that a free-falling object reaches a ``terminal velocity'' where the deceleration due to air resistance equals the acceleration due to gravity. At this point the object remains at a fairly constant velocity.%
\par
To refine this model for velocity, we can incorporate a simple model for air resistance. It seems reasonable to assume that as velocity increases, the force due to air resistance increases. This implies a proportionality relationship between velocity and the force due to air resistance:%
\par
%
\begin{equation*}
\text{Force due to air resistance} = kv
\end{equation*}
%
\par
This force acts upward on the object. There is also a force acting downward on the object due to its mass \(m\):%
\par
%
\begin{equation*}
\text{Downward force} = mg
\end{equation*}
%
\par
Now, by Newton's second law,%
\par
%
\begin{equation*}
F = ma = m\,\frac{dv}{dt}
\end{equation*}
%
\par
Also,%
\par
%
\begin{equation*}
F = \text{Downward force} - \text{Upward force}
\end{equation*}
%
\par
Putting all this together we get,%
\par
%
\begin{equation*}
m\,\frac{dv}{dt} = mg - kv \Longrightarrow \frac{dv}{dt} + \frac{k}{m}\,v = g
\end{equation*}
%
\par
Solving this last differential equation gives the model%
\par
%
\begin{equation*}
v(t) = \frac{mg}{k}\left(1-e^{-kt/m}\right)
\end{equation*}
%
\par
Note that in this model,%
\par
%
\begin{equation*}
\lim_{t\to\infty} v(t) = \frac{mg}{k}
\end{equation*}
%
\par
This suggests a terminal velocity, so this model is more realistic.%
\end{example}
Proportionality relationships satisfy the following transitive property:%
\begin{theorem}{}{}{g:theorem:id50}%
If \(a\propto b\) and \(b\propto c\), then \(a\propto c\).\end{theorem}
\begin{proof}{}{g:proof:id51}
By definition, \(a\propto b\) and \(b\propto c\) mean that \(a=k_1 b\) and \(b=k_2 c\) for some nonzero constants \(k_1\) and \(k_2\). So, substituting we get%
%
\begin{equation*}
a=k_1k_2c
\end{equation*}
but \(k_1k_2\) is a nonzero constant, so \(a\propto c\) by definition.%
\end{proof}
The next example illustrates an application of this property.%
\begin{example}{Work Done by a Train.}{g:example:id52}%
If a constant force is applied to an object moving it some distance, the work done is defined to be%
%
\begin{equation*}
\text{Work} = \text{Force}\times\text{Distance} 
\end{equation*}
Suppose a train engine pulls a car along a flat stretch of track until it runs out of fuel, and assume that the force needed is constant. We want to model the total work done by the engine in terms of the amount of fuel it carries.%
\par
Since the force is constant, work is proportional to the distance pulled. Let \(W\) denote work and \(D\) denote distance. In standard notation,%
%
\begin{equation*}
W\propto D
\end{equation*}
Now, the total distance the train can pull the car is related to the amount of fuel. The more fuel, the farther it can pull the car. So distance pulled is proportional to the amount of fuel. If \(A\) denotes the amount of fuel, we have%
%
\begin{equation*}
D\propto A
\end{equation*}
Combining these two proportionality relationships, we arrive at the model:%
%
\begin{equation*}
W\propto A
\end{equation*}
Although we do not know the constant of proportionality, we can use this relationship to find relative values. For instance, if the constant of proportionality were 10 and the tank holds 1000 gallons, with a full tank the train could perform%
%
\begin{equation*}
W = 10 (1000) = 10,000 
\end{equation*}
units of work. If the fuel tank were one–quarter full, it could perform%
%
\begin{equation*}
W = 10(250) = 2500
\end{equation*}
units of work, which is exactly one–quarter as much work as if the tank were full.%
\end{example}
%
%
\typeout{************************************************}
\typeout{Exercises 6.2 Exercises}
\typeout{************************************************}
%
\begin{exercises-subsection-numberless}{Exercises}{}{Exercises}{}{}{g:exercises:id53}
\begin{divisionexercise}{1}{}{}{g:exercise:id54}%
A very simple assumption about the population of rabbits in a forest is that it grows at a rate proportional to the size of the population and the rabbits die at a rate proportional to the number of foxes in the forest. If \(p_n\) denotes the population of rabbits at time \(n\), and \(F\) denotes the (constant) number of foxes, this assumption yields a model for the change in the rabbit population:%
%
\begin{equation*}
\Delta p_n = p_{n+1}-p_{n} = k_1p_n - k_2 F
\end{equation*}
where \(k_1, k_2\ge 0\).%
\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}Solve this model for \(p_{n+1}\).%
\item{}If \(p_0 = 500\), \(k_1 = 0.15\), and \(k_2 = 0.25\), algebraically find the values of \(F\) for which the population of rabbits is decreasing, for which it is increasing, and for which it is constant for all \(n \ge 0\). (\emph{Hint:} If the population is constant, \(p_1 = p_0\).)%
\item{}Use SageMath to numerically and graphically support your answer above.%
\end{enumerate}
\end{divisionexercise}%
\begin{divisionexercise}{2}{}{}{g:exercise:id55}%
Refer back to the Population Growth example at the start of this section. We will analyze a refined model. Assume that \(\Delta p_n\) is proportional to the product of the population and its difference from 621, that is%
%
\begin{equation*}
\Delta p_n = p_{n+1}-p_n = kp_n(621-p_n)
\end{equation*}
\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}Use the data in the Population Growth example table to test this assumption by plotting \(\Delta p_n\) vs. \(p_n(621 - p_n)\). Use the graph to estimate the constant of proportionality.%
\item{}Starting with \(p_0 = 10.3\), use this refined model to predict the population for days 1 through 20.%
\item{}Does this model seem more or less reasonable than the original one? Why or why not?%
\end{enumerate}
\end{divisionexercise}%
\begin{divisionexercise}{3}{}{}{g:exercise:id56}%
Refer again back to the Population Growth example at the start of this section, and consider the assumption that \(\Delta p_n\) is proportional to \(p_n^2\). Use the data in the table to test this assumption. Does this assumption appear to be reasonable? Why or why not?%
\end{divisionexercise}%
\end{exercises-subsection-numberless}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 6.3 Fitting Straight Lines Analytically}
\typeout{************************************************}
%
\begin{sectionptx}{Fitting Straight Lines Analytically}{}{Fitting Straight Lines Analytically}{}{}{x:section:fitting-lines-analytically}
As we have seen, modeling with proportionality often requires us to fit a straight line to a set of data. In earlier sections we used a graphical approach, which can be rather subjective. Today we will look at different definitions of a ``best fit'' line and find formulas for the slope and \(y\)-intercept of a best-fit line in terms of the \(x\)- and \(y\)-coordinates of the data points. This will give an objective approach to fitting a straight line.%
\par
The first step is to define criteria for a good-fitting line. The line in the left graph in \hyperref[x:figure:two-lines]{Figure~{\xreffont\ref{x:figure:two-lines}}} fits the data ``better'' than the line in the right graph.%
\begin{figureptx}{}{x:figure:two-lines}{}%
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{./images/Fig2.14.png}
\end{image}%
\tcblower
\end{figureptx}%
What’s the difference between these two lines? There are probably many ways to answer this question.%
\par
We see that in the right graph, the line is very close to the right-most point, but further from the other two points than the line in the left graph. We might say that the line in the left graph is ``closer'' to the data points in general than the line in the right graph. The idea of minimizing the distance between the line and the points will form the basis of the definition of a best-fit line.%
\par
These distances (also called \emph{errors}) are illustrated in the figure below with the dashed lines.%
\begin{figureptx}{}{g:figure:id57}{}%
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{./images/Fig2.15.png}
\end{image}%
\tcblower
\end{figureptx}%
If the coordinates of the points are given by%
%
\begin{equation*}
(x_i,y_i) \text{ for } i = 1, 2, \dots, n
\end{equation*}
and the line is described by the function \(f(x) = mx + b\), then the values of the distances are%
%
\begin{equation*}
|y_i-f(x_i)| \text{ for } i=1, 2, \dots, n
\end{equation*}
There are many ways to define how the best-fit line minimizes these distances. One way, called \emph{Chebyshev’s criterion}, is based on the idea that the best-fit line should make the largest of these distances as small as possible. In more technical terms, this criterion says that the function \(f(x) = mx+b\) giving the best-fit line is the one that minimizes the number%
%
\begin{equation*}
C = \text{Maximum of } \{|y_i - f(x_i)|: i = 1, 2, \cdots n\}.
\end{equation*}
Our goal is to find formulas for the slope \(m\) and \(y\)-intercept \(b\). Since we want to minimize something, we might think about using derivatives. Chebyshev’s criterion makes logical sense, but it’s not obvious how to take the derivative or use it to find simple formulas for \(m\) and \(b\).%
\par
Another criterion is based on the idea that the best–fit line should minimize the sum of the distances. In mathematical notation, \(f(x) = mx + b\) should minimize the number%
%
\begin{equation*}
A = \sum_{i=1}^n |y_i - f(x_i)|.
\end{equation*}
This criterion is also very logical, but the absolute values make the derivative difficult to calculate. To make the derivative simpler, we might consider getting rid of the absolute values in the above summation altogether and add the criterion that the sum must be non–negative. This, however, would make some of the terms in the summation positive and some negative. So, there might be some large positive values that cancel out some large negative values resulting in a small sum, but a poor-fitting line.%
\par
The most widely used criterion, called the \emph{least–squares} criterion, uses squares rather than absolute values to make all the terms positive. In mathematical notation, this criterion says that the function \(f(x) = mx + b\) should minimize the number%
%
\begin{equation*}
S = \sum_{n=1}^\infty (y_i-f(x_i))^2.
\end{equation*}
To see how this might work, consider the example below.%
\begin{example}{Illustrating the Least-Squares Criterion.}{g:example:id58}%
We start with a data set and then ask SageMath to produce a scatterplot of the data.%
\begin{sageinput}
datapoints = [(0.8, 2), (2.5, 4.2), (3.5, 3.5), (4.2, 5.3), (5.8, 4.5), (7.5, 7)]
sp = scatter_plot(datapoints)
show(sp)
\end{sageinput}
We could certainly try to ``guess and check'' a slope and intercept, but it's likely there's a better candidate than our eyeball might give us.%
\par
The least-squares approach to finding a ``best-fit'' line for a set of data involves finding the slope \(m\) and the \(y\)-intercept \(b\) that minimizes the sum of the squares of the errors.  If we let \(f(x) = mx + b\) be our approximating line, we are trying to find \(m\) and \(b\) values so that%
%
\begin{equation*}
S = \sum_{i=1}^n \left(y_i - f(x_i)\right)^2 = \sum_{i=1}^n (y_i - mx_i -b)^2 
\end{equation*}
is a minimum.  To search for these values, we think of \(S\) as a function of \(m\) and \(b\), and set the partial derivatives of \(S\) with respect to \(m\) and \(b\) to 0.%
%
\begin{equation*}
\begin{aligned}
\frac{\partial S}{\partial m} &= \sum_{i=1}^n 2(y_i - mx_i -b)\cdot (-x_i)  = -2\sum_{i=1}^n (y_i - mx_i-b)x_i= 0 \\
\frac{\partial S}{\partial b} &= \sum_{i=1}^n 2(y_i - mx_i -b)\cdot (-1)  = -2\sum_{i=1}^n (y_i - mx_i - b)= 0
\end{aligned}
\end{equation*}
These equations can be rewritten as%
%
\begin{equation*}
\begin{gathered}
\sum_{i=1}^n x_i y_i - m\sum_{i=1}^n x_i^2 - b\sum_{i=1}^n x_i = 0 \\
\sum_{i=1}^n y_i - m\sum_{i=1}^n x_i - n\cdot b = 0
\end{gathered}
\end{equation*}
Despite the look of these equations, they are a system of two linear equations in two unknowns. Using the usual methods to solve for \(m\) and \(b\), we get%
%
\begin{equation*}
\begin{aligned}
b &= \frac{\sum x_i^2 \sum y_i - \sum x_i y_i \sum x_i}{n\sum x_i^2 - \left(\sum x_i\right)^2} \\
m &= \frac{n\sum x_i y_i - \sum x_i \sum y_i}{n\sum x_i^2 - \left(\sum x_i\right)^2}
\end{aligned}
\end{equation*}
These formulas are implemented below.%
\begin{sageinput}
n = len(datapoints)
n
\end{sageinput}
\begin{sageoutput}
6
\end{sageoutput}
\begin{sageinput}
b = (sum(x[0]^2 for x in datapoints)*sum(x[1] for x in 
	datapoints)-sum(x[0]*x[1] for x in datapoints)*
	sum(x[0] for x in datapoints))/(n*sum(x[0]^2 for x in 
	datapoints) - sum(x[0] for x in datapoints)^2)

m = (n*sum(x[0]*x[1] for x in datapoints)-
     sum(x[0] for x in datapoints)*sum(x[1] for x in 
     datapoints))/(n*sum(x[0]^2 for x in datapoints) - 
     sum(x[0] for x in datapoints)^2)

m, b
\end{sageinput}
\begin{sageoutput}
(0.632985312334100, 1.85307615171356)
\end{sageoutput}
The good news is that we don't have to do this all the time. The least-squares approach is already built into SageMath, using the \mono{find\_fit} function.%
\begin{sageinput}
var('m1 b1')
model(x) = m1*x + b1
\end{sageinput}
\begin{sageinput}
sol = find_fit(datapoints, model, solution_dict = True)
sol[m1], sol[b1]
\end{sageinput}
\begin{sageoutput}
(0.6329853123708113, 1.8530761494230292)
\end{sageoutput}
\begin{sageinput}
sp + plot(sol[m1]*x + sol[b1], (x, 0, 8))
\end{sageinput}
\end{example}
%
%
\typeout{************************************************}
\typeout{Exercises 6.3 Exercises}
\typeout{************************************************}
%
\begin{exercises-subsection-numberless}{Exercises}{}{Exercises}{}{}{g:exercises:id59}
\begin{divisionexercise}{1}{}{}{g:exercise:id60}%
Suppose a biologist records the number of pulses per second of the chirps of a cricket at different temperatures (in \({}^\circ\)F). The data collected is shown below.%
\begin{center}%
{\tabularfont%
\begin{tabular}{ccccccccccc}\hrulethick
\multicolumn{1}{rA}{\emph{Temperature}}&72&73&89&75&93&85&79&97&86&91\tabularnewline\hrulethin
\multicolumn{1}{rA}{\emph{Pulses\slash{}sec}}&16&16.2&21.2&16.5&20&18&16.75&19.25&18.25&18.5\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}Fit a straight line to this data (where temperature is on the \(x\)-axis). How well does the model fit the data?%
\item{}What is the slope of this line? What does the sign of the slope tell you about the relationship between pulses\slash{}sec and temperature?%
\end{enumerate}
\end{divisionexercise}%
\begin{divisionexercise}{2}{}{}{g:exercise:id61}%
The table below gives the win\slash{}loss percentage and other key statistics of 15 NCAA Division 1 women’s basketball teams (data collected by Quinn Wragge, 2019).%
%
\begin{equation*}
\begin{array}{c|ccccc}\hline\hline
\textbf{Win/Loss} & \textbf{Rebounds} & \textbf{Turnovers} & \textbf{Steals} & \textbf{3 pt Shots} & \textbf{Field Goal} \\
\textbf{Percent} & \textbf{Per Game} & \textbf{Per Game} & \textbf{Per Game} & \textbf{Made/Game} & \textbf{Percent} \\\hline\hline
93.8 & 48.8 & 13.1 & 7.4 & 3.3 & 51.5 \\
52.6 & 32.89 & 13.4 & 4.6 & 10.3 & 42.9 \\
89.5 & 39.89 & 14.2 & 10.2 & 4.8 & 45.3 \\
77.8 & 42.67 & 14.6 & 8.1 & 8.9 & 45.2 \\
68.8 & 36.19 & 13.8 & 8.8 & 7.7 & 41.2 \\
100 & 45.53 & 14.3 & 5.6 & 8 & 46.3 \\
50 & 40.82 & 15.7 & 7.8 & 7.2 & 42.9 \\
94.7 & 44.17 & 14.5 & 8.7 & 4.1 & 51.7 \\
68.4 & 38.26 & 13.7 & 7.4 & 7.5 & 46.6 \\
70.6 & 46 & 16.8 & 9.7 & 6.2 & 42.9 \\
83.3 & 43.28 & 16.4 & 7.6 & 5.6 & 45.5 \\
70.6 & 38.41 & 15.9 & 9.6 & 6.2 & 43.3 \\
94.1 & 42.13 & 11.8 & 7.3 & 7.9 & 49.1 \\
33.3 & 38.29 & 16.7 & 7.4 & 5.4 & 39 \\
85 & 38.84 & 13.4 & 9.5 & 8.2 & 44.4 \\\hline\hline
\end{array}
\end{equation*}
\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}Create graphs of win\slash{}loss percentage vs. each of the other statistics (one graph per statistic) and fit a straight line to the data.%
\item{}Comment on how well each line fits the data. Which line appears to fit the data the best?%
\item{}Comment on the sign of the slope of each line. Does the sign make sense? Briefly explain.%
\end{enumerate}
\end{divisionexercise}%
\end{exercises-subsection-numberless}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 6.4 Geometric Similarity}
\typeout{************************************************}
%
\begin{sectionptx}{Geometric Similarity}{}{Geometric Similarity}{}{}{x:section:geometric-similarity}
Shapes such as circles and rectangles are easy to work with. We can calculate the area and volume of objects with these shapes using very simple formulas. Real world objects rarely come in these simple forms. This necessitates some simplifying assumptions. Geometric similarity is one such assumption.%
\begin{definition}{}{g:definition:id62}%
Two objects are \emph{geometrically similar} if the following two conditions are met:%
%
\begin{enumerate}
\item{}There is a one-to-one correspondence between points of the objects (i.e. the two objects have the same ``shape''\textgreater{}).%
\item{}The ratio of distances between corresponding points is the same for all pairs of points.%
\end{enumerate}
\end{definition}
In simpler terms, two objects are geometrically similar if one is a scaled up or down version of the other.%
\par
What does geometric similarity allow us to do? Let’s start with a very simple example. Consider a rectangle of length 3 cm and height 2 cm. Its area is \(6 \text{ cm}^2\). Note that this area is proportional to the square of the length of the rectangle since%
%
\begin{equation*}
6 = \frac6{3^2} (3^2) = \frac23(3^2)
\end{equation*}
Now consider another rectangle of length 5 cm and height 4 cm. Its area is \(20 \text{ cm}^2\) which is again proportional to the square of the length since%
%
\begin{equation*}
20 = \frac{20}{5^2} (5^2) = \frac45(5^2)
\end{equation*}
Consider a third rectangle of length 6 cm and height 4 cm. This rectangle is a scaled up version of the first rectangle (its dimensions are simply 2 times the dimensions of the first one). In other words, these two rectangles are geometrically similar. Its area is \(24 \text{ cm}^2\) which is again proportional to the square of the length since%
%
\begin{equation*}
24 = \frac{24}{6^2} (6^2) = \frac23(6^2)
\end{equation*}
Notice that the constants of proportionality are the same for these two geometrically similar rectangles. The second rectangle is not geometrically similar to the other two rectangles, and its constant of proportionality is not the same as the others.%
\par
Let’s generalize this example. Suppose we have a rectangle of length \(3k\) cm and width \(2k\) cm where \(k\) is some positive number. This rectangle is geometrically similar to the first rectangle. Its area is \(6k^2 \text{ cm}^2\), which is proportional to the square of the length since%
%
\begin{equation*}
6k^2 = \frac{6k^2}{(3k)^2}(3k)^2 = \frac23(3k)^2
\end{equation*}
Again note that the constant of proportionality is the same as the other geometrically similar rectangles. What does this mean? Suppose we have a bag of rectangles each of length \(3k\) cm and width \(2k\) cm where \(k > 0\) is different for each rectangle. If we reached into the bag and pulled out one rectangle and wanted to know its area, we wouldn’t need to measure both the length and the height. We could simply measure the length, square it, and take it times 2\slash{}3. This simplifies the process of finding the area.%
\par
The length is an example of a \emph{characteristic dimension}. A characteristic dimension is simply a dimension of the object that is easy to measure. We could have chosen height as the characteristic dimension and done the same analysis as above, but the constant of proportionality would have been different.%
\par
This generalization illustrates the first important property of geometrically similar objects.%
\begin{theorem}{}{}{g:theorem:id63}%
Suppose \(H\) is a set of geometrically similar objects. Let \(A\) denote the surface area of an object and \(\ell\) denote a characteristic dimension. Then%
%
\begin{equation*}
A\propto \ell^2,
\end{equation*}
and the constant of proportionality is the same for every object in \(H\).%
\end{theorem}
\begin{example}{Wool from a Sheep.}{g:example:id64}%
A shepherd wants to predict the volume of wool he will get from a sheep, \(V\), in terms of the girth of the sheep (the distance around the fattest part of the belly). The volume is the thickness of the wool times the area from which it is shaved. This area is not a simple shape, so we will use geometric similarity to simplify the model. Consider the following assumptions:%
%
\begin{enumerate}
\item{}The thickness of the wool is the same for every sheep.%
\item{}The area on each sheep from which the wool is shaved is geometrically similar.%
\end{enumerate}
The first assumption allows us to model%
%
\begin{equation*}
V\propto A
\end{equation*}
where \(A\) is the area from which the wool is shaved. The second assumption allows us to model%
%
\begin{equation*}
A\propto \ell^2
\end{equation*}
where \(\ell\) is some characteristic dimension. We will choose the girth (the distance around the belly of the sheep) to be this dimension. Combining the two proportionalities using transitivity, we get%
%
\begin{equation*}
V\propto \ell^2
\end{equation*}
To find the constant of proportionality, and test the assumptions, we would need to collect data of volume and girth.%
\end{example}
Now let’s consider a three-dimensional object. Specifically consider a rectangular box with width 4 cm, height 3 cm, and depth 2 cm. Its volume is \(24 \text{ cm}^3\), which is proportional to the height cubed since%
%
\begin{equation*}
24 = \frac{24}{3^3}(3^3) = \frac89(3^3)
\end{equation*}
Consider a geometrically similar box with width \(4k\) cm, height \(3k\) cm, and depth \(2k\) cm where \(k > 0\). Its volume is \(24k^3 \text{ cm}^3\), which again is proportional to the height cubed since%
%
\begin{equation*}
24k^3 = \frac{24k^3}{(3k)^3}(3k)^3 = \frac89(3k)^3.
\end{equation*}
Note that the constant of proportionality is the same. This generalization illustrates the second important property of geometrically similar objects.%
\begin{theorem}{}{}{g:theorem:id65}%
Suppose \(H\) is a set of geometrically similar objects. Let \(V\) denote the volume of an object and \(\ell\) denote a characteristic dimension. Then%
%
\begin{equation*}
V\propto \ell^3,
\end{equation*}
and the constant of proportionality is the same for every object in \(H\).%
\end{theorem}
As in the first property, no special shape of the objects is assumed. This property allows us to relate the volume of an object to some characteristic dimension, and combining this with the first property we can relate volume to surface area.%
\begin{example}{Surface Area of a Potato.}{g:example:id66}%
Suppose we want to fix a large batch of the recipe ``Crispy Potato Skins'' for an appetizer at our Super Bowl party. This recipe requires only the skin from a potato, so when we buy the potatoes, we want to get the maximum surface area for our money.%
\par
At the supermarket we have the choice of several different sizes of potatoes. We have to decide if we want to buy several small potatoes or a few large ones (we are assuming that we can choose individual potatoes). Let’s restrict ourselves to the following problem:%
\begin{quote}%
Should we buy 8 small baking potatoes weighing 0.25 lbs each, or 4 large baking potatoes weighing 0.5 lbs each?%
\end{quote}
To answer this question, we want to relate the surface area of a potato, \(A\), to its weight, \(W\). Consider the following assumptions:%
%
\begin{enumerate}
\item{}Potatoes have a constant density.%
\item{}Potatoes are geometrically similar.%
\end{enumerate}
The first assumption seems very reasonable. The veracity of the second is arguable. However, potatoes have a very irregular shape, so we need some sort of simplifying assumption to model their surface. Similarity is a \emph{reasonable} assumption.%
\par
Now, Weight = density \(\times\) volume, so the first assumption allows us to model%
%
\begin{equation*}
W\propto V
\end{equation*}
where \(W\) is the weight and \(V\) is the volume. The second assumption allows us to model%
%
\begin{equation*}
V\propto \ell^3
\end{equation*}
where \(\ell\) is any characteristic dimension (such as length). Combining the two we get%
%
\begin{equation}
W\propto\ell^3.\label{x:men:weight-eqn}
\end{equation}
The second assumption also allows us to model%
%
\begin{equation*}
A\propto \ell^2,
\end{equation*}
where \(A\) is the surface area of a potato and \(\ell\) is the same characteristic dimension used in \hyperref[x:men:weight-eqn]{({\xreffont\ref{x:men:weight-eqn}})}. Rewriting and combining the last two proportionalities, we get%
%
\begin{equation*}
\ell \propto W^{1/3} \longrightarrow A \propto\left(W^{1/3}\right)^2 = W^{2/3}
\end{equation*}
Since potatoes are sold by the pound, each choice in the original problem will cost the same amount, so we want the choice with the largest surface area. If \(A_S\) and \(A_L\) represent the total surface area of the small and large potatoes, respectively, then the last equation gives%
%
\begin{equation*}
A_S = 8k(0.25)^{2/3} \qquad\text{and}\qquad A_L = 4k(0.5)^{2/3}
\end{equation*}
where \(k\) is some constant (note \(k\) is the same for both \(A_S\) and \(A_L\)). Thus%
%
\begin{equation*}
\frac{A_S}{A_L} = \frac{8k(0.25)^{2/3}}{4k(0.5)^{2/3}}\approx 1.26 \quad\Longrightarrow \quad A_S\approx 1.26 A_L
\end{equation*}
Therefore, the surface area of the small potatoes is approximately 26\% greater than the surface area of the larger potatoes. So we should buy the smaller potatoes.%
\end{example}
%
%
\typeout{************************************************}
\typeout{Exercises 6.4 Exercises}
\typeout{************************************************}
%
\begin{exercises-subsection-numberless}{Exercises}{}{Exercises}{}{}{g:exercises:id67}
\begin{divisionexercise}{1}{}{}{g:exercise:id68}%
In our earlier example, we assumed potatoes are geometrically similar and of constant density. This yielded the model \(W\propto \ell^3\) where \(W\) is weight and \(\ell\) is some characteristic dimension. To test these assumptions, a student measured the length (inches) and weight (pounds) of several yellow and Idaho russet potatoes as shown in the table below (data collected by Brennan DeForest, 2019).%
%
\begin{equation*}
\begin{array}{c|c}\hline\hline
\textbf{Yellow} & \textbf{Idaho Russet} \\
\begin{array}{cc}
\textbf{Length} & \textbf{Weight} \\\hline
2.5 & 0.2 \\
3.5 & 0.4 \\
3 & 0.3 \\
2.75 & 0.2 \\
3.5 & 0.4 \\
3.25 & 0.35 \\
2.5 & 0.25 \\
3 & 0.3 \\
3.25 & 0.4 \\
3.25 & 0.4 \\
3.25 & 0.35 \\
2 & 0.25
\end{array} & 
\begin{array}{cc}
\textbf{Length} & \textbf{Weight} \\\hline
4.75 & 0.55 \\
5.5 & 0.55 \\
5 & 0.7 \\
5.25 & 0.7 \\
4.75 & 0.4 \\
5.5 & 0.7 \\
5.75 & 0.75 \\
5 & 0.55 \\
& \\
& \\
& \\
& 
\end{array} \\\hline\hline
\end{array}
\end{equation*}
\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}Use the data to determine if the model \(W\propto \ell^3\) is reasonable for the yellow potatoes.%
\item{}Repeat the previous part for the Idaho russet potatoes.%
\item{}Combine the two types of potatoes into one large sample and repeat part (a).%
\item{}What do these results suggest about the validity of the assumptions?%
\end{enumerate}
\end{divisionexercise}%
\begin{divisionexercise}{2}{}{}{g:exercise:id69}%
The table below gives the overall length (inches) and weight (pounds) of several male black bears (data collected by Brent Troyer, 2011).  If we assume male black bears are geometrically similar, then we would expect that Weight \(\propto\) Length\({}^3\). Use this data in the table to determine if geometric similarity is a reasonable assumption.%
%
\begin{equation*}
\begin{array}{l|cccccccccc}\hline\hline
\textbf{Length}& 138 & 166 & 180 & 129.5 & 150 & 132 & 148 & 140 & 137 & 149 \\
\textbf{Weight}& 60 & 155 & 220 & 105 & 110 & 75 & 105 & 90 & 75 & 115 \\\hline
\textbf{Length}& 102 & 173 & 104.5 & 138 & 144.5 & 164 & 129 & 158 & 150 & 142 \\
\textbf{Weight}& 35 & 220 & 33 & 90 & 80 & 180 & 77 & 120 & 100 & 100 \\\hline\hline
\end{array}
\end{equation*}
\end{divisionexercise}%
\end{exercises-subsection-numberless}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 6.5 Linearizable Models}
\typeout{************************************************}
%
\begin{sectionptx}{Linearizable Models}{}{Linearizable Models}{}{}{x:section:linearizable-models}
In previous sections we used theory of one form or another to construct models and then used data to determine the values of parameters within the model. This process is called \terminology{model fitting} and the resulting models are called \terminology{analytical models}. The model never fit the data perfectly, but we were willing to accept some error because the model helps \emph{explain} the behavior of the system.%
\par
In this section, and the next chapter, we build models guided solely by data. We will not even attempt to use theory to explain behavior. Rather, we will find a model that captures the trend of the data and use it to \emph{predict} values rather than explain the behavior. These models are called \terminology{empirical models}. Many of the topics related to empirical modeling are closely related to the field of statistics, and particularly the topic of regression.%
\par
Linearizable models are those which can be fit to a set of data by making an appropriate transformation and then fitting a linear model to the transformed data. Listed below are the three common types of linearizable models:%
%
\begin{equation*}
\begin{array}{ccc}
\textbf{Logarithmic} & \textbf{Power} & \textbf{Exponential} \\\hline\hline
y = a + b\ln (x) & y = ax^b & y = ae^{bx}
\end{array}
\end{equation*}
The variable \(x\) is called the \terminology{predictor} variable while the variable \(y\) is called the \terminology{response} variable. Graphs of these different types of models are shown in \hyperref[x:figure:curveshapes]{Figure~{\xreffont\ref{x:figure:curveshapes}}}.%
\begin{figureptx}{}{x:figure:curveshapes}{}%
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{./images/MA241Notes0215-1.png}
\end{image}%
\tcblower
\end{figureptx}%
Note the ``shape'' of the different graphs. Each one of these different functions increases as \(x\) increases, but they increase at different rates. The logarithmic function and the power functions with exponents less than 1 increase much slower than the other types of functions. They almost appear to ``level off'' whereas the other types grow very quickly. Being able to recognize the shapes of the different graphs will help us to select an appropriate type of model.%
\par
To illustrate how to use these models, consider the data in the table below which gives the number of people per physician and male life expectancy (in years) for various countries around the world (data from \emph{World Almanac Book of Facts}, 1992, Pharos Books). Our goal is to predict life expectancy in terms of the number of people per physician.%
%
\begin{equation*}
\begin{array}{lcc}\hline\hline
& \textbf{People/Physician} & \textbf{Life Expectancy} \\
\textbf{Country} & \boldsymbol{P} & \boldsymbol{L} \\\hline
\text{Spain} & 275 & 74 \\
\text{United States} & 410 & 72 \\
\text{Canada} & 467 & 73 \\
\text{Romania} & 559 & 67 \\
\text{China} & 643 & 68 \\
\text{Taiwan} & 1010 & 70 \\
\text{Mexico} & 1037 & 67 \\
\text{South Korea} & 1216 & 66 \\
\text{India} & 2471 & 57 \\
\text{Morocco} & 4873 & 62 \\
\text{Bangladesh} & 6166 & 54 \\
\text{Kenya} & 7174 & 59\\\hline\hline
\end{array}
\end{equation*}
Obviously there are many factors involved with life expectancy; the number of persons per physician is only one of them. It seems reasonable to believe that as the number of persons per physician increases (meaning fewer doctors per person), life expectancy decreases because people would not have as easy access to health care.  We do not claim that the number of people per physician \emph{causes} life expectancy, but there is a relationship between the two variables. It is not at all clear how the variables of people per physician and life expectancy are related theoretically, so we will not even attempt to construct an analytical model. We will construct an empirical model by fitting various linearizable models to this data and analyzing how well each one fits.%
\par
We first enter the data points:%
\begin{sageinput}
datapoints = [(275, 74), (410, 72), (467, 73), (559, 67), 
	(643, 68), (1010, 70), (1037, 67), (1216, 66), 
	(2471, 57),(4873, 62), (6166, 54), (7174, 59)]
\end{sageinput}
\begin{sageinput}
sp = scatter_plot(datapoints)
show(sp, axes_labels = ['People/Physician', 'Life Expectancy'],figsize = [8,4], frame = True)
\end{sageinput}
Notice that as the number of people per physician increases, the life expectancy decreases, agreeing with our intuition. Also note that the points seems to form a curve that initially decreases rapidly, but then levels off. This suggests that a logarithmic or power model might be appropriate.%
%
%
\typeout{************************************************}
\typeout{Subsection 6.5.1 Logarithmic model}
\typeout{************************************************}
%
\begin{subsectionptx}{Logarithmic model}{}{Logarithmic model}{}{}{g:subsection:id70}
We will fit a curve of the form \(L = a + b\ln(P)\) by graphing \(L\) versus \(\ln(P)\) and fitting a straight line.  The value of \(b\) is the slope of the line and the value of \(a\) is the \(y\)-intercept.%
\begin{sageinput}
logpoints = [(ln(P), L) for (P,L) in datapoints]
sp2 = scatter_plot(logpoints, title = "Transformed Data", 
	axes_labels = ["$\\ln(P)$", "$L$"], frame = True)
show(sp2)
\end{sageinput}
This data looks to be more along a straight line than our original data set, so we can then ask Sage to fit a straight line to it.%
\begin{sageinput}
var('b a')
model(x) = b*x + a
sol = find_fit(logpoints,model, solution_dict = True)
sol
\end{sageinput}
\begin{sageoutput}
{a: 103.40031193527923, b: -5.287622670252565}
\end{sageoutput}
So the model is \(L = 103.4 - 5.2876\ln P\).%
\begin{sageinput}
sp2 + plot(sol[b]*x + sol[a], (x, 5, 9) )
\end{sageinput}
Now we want to create a graph to compare the observed values of \(L\) to the predicted ones from our model.%
\begin{sageinput}
predpoints = [(P,sol[b]*ln(P) + sol[a]) for (P,L) in datapoints]
show(sp + list_plot(predpoints, size=75, marker='v'), 
     axes_labels = ["People/Physician", "Life Expectancy"], 
     frame = True, xmin = 0, xmax = 8000, ymin = 50, ymax = 80)
\end{sageinput}
To further analyze how well the model fits the data, for each data point define%
%
\begin{equation*}
\text{Residual} = \text{(Observed value)} - \text{(Predicted value)}.
\end{equation*}
Note that a positive residual means that the predicted value is less than the observed value.  A negative residual means that the predicted value is greater than the observed value.%
\begin{sageinput}
respoints = [(x, y-(sol[b]*ln(x) + sol[a])) 
	for (x,y) in datapoints]
list_plot(respoints, size=75, title = "Residuals", 
	axes_labels = [None, "Residuals"], frame = True)
\end{sageinput}
Note that roughly half the residuals are positive and half are negative.  This indicates that the model does not tend to overpredict or underpredict the values of \(L\).  Also note that the magnitudes of the residuals (the absolute values) are all relatively small, less than 6, and that there is no ``pattern'' to the residuals.  These three observations indicate that this model fits relatively well.%
\par
We note that we can find the logarithmic model directly by using that logarithmic format in our definition of \mono{model(x)} and applying it directly to the data points themselves (not the logarithm version).%
\begin{sageinput}
var('b a')
model(x) = b*ln(x) + a
find_fit(datapoints, model)
\end{sageinput}
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 6.5.2 Power model}
\typeout{************************************************}
%
\begin{subsectionptx}{Power model}{}{Power model}{}{}{g:subsection:id71}
We will fit a curve of the form \(L=aP^b\) to the data.  To find the values of this, we linearize the model by taking the natural logarithm of both sides of its equation to get%
%
\begin{equation*}
\ln L = \ln(aP^b) = \ln a + \ln P^b = \ln a + b\ln P.
\end{equation*}
Thus a straight line fit to the graph of \(\ln L\) versus \(\ln P\) will have a slope of \(b\) and a \(y\)-intercept of \(\ln a\).%
\begin{sageinput}
loglogpoints = [(ln(P), ln(L)) for (P,L) in datapoints]
sp3 = scatter_plot(loglogpoints, title = "Transformed Data", 
	axes_labels = ["$\\ln(P)$", "$\\ln(L)$"], frame = True)
show(sp3)
\end{sageinput}
\begin{sageinput}
var('b a')
model(x) = b*x + a
sol = find_fit(loglogpoints, model, solution_dict = True)
sol
\end{sageinput}
\begin{sageoutput}
{a: 4.767541100938781, b: -0.08233961622369507}
\end{sageoutput}
The equation of the line through the log-log data is \(y = -0.0823x + 4.7675\).%
\begin{sageinput}
sp3 + plot(sol[b]*x + sol[a], (x, 5, 9))
\end{sageinput}
Therefore, we have%
%
\begin{equation*}
\ln a = 4.7675 \quad\Longrightarrow\quad a = e^{4.7675} = 117.62.
\end{equation*}
Therefore our model is \(L = 117.62P^{-0.0823}\). Again, we could have computed this directly from the original data points.%
\begin{sageinput}
var('a b')
model(x) = a*x^b
sol = find_fit(datapoints, model, solution_dict = True)
sol
\end{sageinput}
\begin{sageoutput}
{a: 117.64062968551121, b: -0.08223680619371171}
\end{sageoutput}
\begin{sageinput}
predpoints = [(P, sol[a]*P^sol[b] ) for (P,L) in datapoints]
sp + list_plot(predpoints, size=75, marker='v')
\end{sageinput}
Now plot the residuals and determine whether we have a good model.%
\begin{sageinput}
respoints = [(P,L-sol[a]*P^sol[b] ) for (P,L) in datapoints]
list_plot(respoints, size=75, 
	title = "Power Model Residuals", 
	axes_labels = [None, "Residuals"], frame = True)
\end{sageinput}
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 6.5.3 Exponential model}
\typeout{************************************************}
%
\begin{subsectionptx}{Exponential model}{}{Exponential model}{}{}{g:subsection:id72}
Now try and fit a model of the form \(L = ae^{bP}\) to the data, plot the residuals and tell whether the model is a good fit.%
\par
Note that%
%
\begin{equation*}
\ln(L) = \ln(ae^{bP}) = \ln a + \ln(e^{bP}) = \ln a + bP.
\end{equation*}
\begin{sageinput}
exppoints = [(P,ln(L)) for (P,L) in datapoints]
sp4 = scatter_plot(exppoints, 
	axes_labels=["$P$", "$\\ln L$"],
    frame=True)
sp4
\end{sageinput}
\begin{sageinput}
var('a b')
model(x) = b*x+a
sol = find_fit(exppoints, model, solution_dict=True)
sol
\end{sageinput}
\begin{sageoutput}
{a: 4.256131024464953, b: -3.416720158289088e-05}
\end{sageoutput}
The equation of the line through the transformed data is \(y = -0.00003x + 4.2561\), so \(b = -0.00003\) and%
%
\begin{equation*}
\ln a = 4.2561 \Longrightarrow a = e^{4.2561} \approx 70.53 
\end{equation*}
Therefore the model is \(L = 70.53e^{-0.00003P}\).%
\begin{sageinput}
sp4 + plot(sol[b]*x+sol[a],(x,0,8000))
\end{sageinput}
As before, we will graph our predicted values with the actual data points, and compute the residuals to check fit.%
\begin{sageinput}
predpoints = [(P, e^sol[a]*e^(sol[b]*P) ) for (P,L) in datapoints]
sp + list_plot(predpoints, size=75, marker='v')
\end{sageinput}
\begin{sageinput}
respoints = [(P,L-e^sol[a]*e^(sol[b]*P) ) for (P,L) in datapoints]
list_plot(respoints, size=75, 
	title = "Exponential Model Residuals", 
	axes_labels = [None, "Residuals"], frame = True)
\end{sageinput}
Notice that all the residuals are at least 1 in magnitude and that one is almost \(-8\). This indicates that the model doesn’t predict any of the values of \(L\) very accurately. Therefore, this is not the best fitting model, as previously suspected.%
\par
We note that in this case, we could \emph{not} have computed the exponential model directly.%
\begin{sageinput}
var('a b')
model(x) = a*e^(b*x)
find_fit(datapoints, model)
\end{sageinput}
\begin{sageoutput}
[a == 1.0, b == 1.0]
\end{sageoutput}
The \mono{find\_fit} has some issues when working on exponential models. So when computing an exponential model in SageMath, \emph{we will most likely have to linearize the model before using} \mono{find\_fit}.%
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsection 6.5.4 Using the models to predict}
\typeout{************************************************}
%
\begin{subsectionptx}{Using the models to predict}{}{Using the models to predict}{}{}{g:subsection:id73}
Out of the three models, the logarithmic and power models are the ``best'' based on an analysis of the graph of the models and of the residuals. In the next section we will look at more analytical techniques for measuring how well a model fits a set of data.%
\par
Now that we have two good–fitting models for the data, what can we do with them? There are at least two uses. First of all, the graphs of the models help us to see the trend of the data. The graphs decrease from left to right, helping us to illustrate the point that as the number of people per physician increases, life expectancy decreases. The plot of the data also shows this, but a curve helps exemplify the relationship.%
\par
Second of all, we can use the models to \emph{predict} life expectancy if we know the number of people per physician. For instance, suppose a country has 3,500 people per physician. The logarithmic model predicts that life expectancy is%
\begin{sageinput}
103.40031225765938 -5.287622715527743*ln(3500.)
\end{sageinput}
\begin{sageoutput}
60.2505706018187
\end{sageoutput}
while the power model gives%
\begin{sageinput}
117.64063035437424*(3500.)^(-0.0822368070118513)
\end{sageinput}
\begin{sageoutput}
60.1318413722959
\end{sageoutput}
We certainly could plug \(P = 3,500\) into the exponential model and get%
\begin{sageinput}
70.5365506541459*e^(-3.416720158289088e-05*3500)
\end{sageinput}
\begin{sageoutput}
62.5862633626265
\end{sageoutput}
However, we saw that the exponential model did not fit the data very well, so it would not be appropriate to use it for making predictions. This illustrates the first caution when using empirical models: \emph{If a model does not fit a set of data, do not use it for making predictions.}%
\par
Now suppose a country has 100 persons per physician.  We could plug \(P=100\) into the logarithmic model to get%
\begin{sageinput}
103.40031225765938 -5.287622715527743*ln(100.)
\end{sageinput}
\begin{sageoutput}
79.0499097733576
\end{sageoutput}
However, note that \(P = 100\) is outside the range of the original data. We do not know the trend of the data for values of \(P\) less than 275. It could change or stay the same; we simply do not know. Therefore, it would be inappropriate to use any of these models to predict values of \(L\) for \(P\) less than 275. This value of 79.04 years may or may not be accurate, so we should not report this ``prediction.'' This illustrates the second caution when using empirical models: \emph{Only use values of the predictor variable that are within the range of the original set of data.}%
\end{subsectionptx}
%
%
\typeout{************************************************}
\typeout{Exercises 6.5.5 Exercises}
\typeout{************************************************}
%
\begin{exercises-subsection}{Exercises}{}{Exercises}{}{}{g:exercises:id74}
\begin{divisionexercise}{1}{}{}{g:exercise:id75}%
The table below contains the total length and weight of 20 black bears (data collected by Brent Troyer, 2011). Graph weight vs. length, fit different linearizable models to the data, and select the one that best fits the data. Briefly explain your reasoning.%
%
\begin{equation*}
\begin{array}{l|cccccccccc}\hline\hline
\textbf{Length}& 139 & 138 & 139 & 120.5 & 149 & 141 & 150 & 166 & 180 & 129.5 \\
\textbf{Weight}& 110 & 60 & 90 & 60 & 85 & 95 & 85 & 155 & 220 & 105 \\\hline
\textbf{Length}& 150 & 142 & 162 & 148 & 140 & 134 & 137 & 149 & 102 & 151.5 \\
\textbf{Weight}& 110 & 115 & 255 & 105 & 90 & 75 & 75 & 115 & 35 & 140 \\\hline\hline
\end{array}
\end{equation*}
\end{divisionexercise}%
\begin{divisionexercise}{2}{}{}{g:exercise:id76}%
Consider the data below:%
\begin{center}%
{\tabularfont%
\begin{tabular}{ccccccc}\hrulethick
\multicolumn{1}{cA}{\(x\)}&0&2&4&6&8&10\tabularnewline\hrulethin
\multicolumn{1}{cA}{\(y\)}&3.000&3.061&3.122&3.186&3.250&3.316\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
\begin{enumerate}[font=\bfseries,label=(\alph*),ref=\alph*]
\item{}Fit a linear model to the data. How well does the model appear to fit the data? Create a graph of the residuals. What do you notice about the pattern of the residuals?%
\item{}Fit an exponential model to the data. How well does the model appear to fit the data? Calculate and graph the residuals. What does this tell you about how well this model fits the data?%
\end{enumerate}
\end{divisionexercise}%
\end{exercises-subsection}
\end{sectionptx}
%
%
\typeout{************************************************}
\typeout{Section 6.6 Coefficient of Determination}
\typeout{************************************************}
%
\begin{sectionptx}{Coefficient of Determination}{}{Coefficient of Determination}{}{}{x:section:coefficient-of-determination}
The coefficient of determination, denoted \(R^2\), is a numerical measure of how well a line fits a set of data.  To illustrate the fundamental concepts, we will generate some hypothetical data according to the relationship \(y=3+2x\).%
\begin{sageinput}
data = [(x,2*x+3) for x in range(10)]
data
\end{sageinput}
\begin{sageoutput}
[(0, 3),
 (1, 5),
 (2, 7),
 (3, 9),
 (4, 11),
 (5, 13),
 (6, 15),
 (7, 17),
 (8, 19),
 (9, 21)]
\end{sageoutput}
\begin{sageinput}
var('x') # x had a value of 9 because of our data definition.  This resets x and is necessary.
sp = scatter_plot(data)
sp + plot(2*x+3,(x,0,10))
\end{sageinput}
Note that the line goes through each data point and the equation of this line (also called the \emph{regression equation} is exactly what is used to generate the data.%
\par
One purpose of fitting a line to data is to use it for predicting the value of \(y\) when \(x\) is known.  If we did not have a graph of the data or the regression equation and we were given a value of \(x\), the best guess as to the corresponding value of \(y\) would be the mean of the data.%
\begin{sageinput}
yvalues = [y for (x,y) in data]
yvalues
\end{sageinput}
\begin{sageoutput}
[3, 5, 7, 9, 11, 13, 15, 17, 19, 21]
\end{sageoutput}
\begin{sageinput}
import numpy # This imports a numerical package

numpy.mean(yvalues)
\end{sageinput}
\begin{sageoutput}
12
\end{sageoutput}
This mean is denoted by \(\overline{y}\) and equals 12 in this case.  We test this simple prediction strategy by examining the ``error'' it would cause for the given data points.%
\begin{sageinput}
var('x')
sp + plot(2*x+3,(x,0,10)) + plot(12,(x,0,10),color='red') \
+ text('$\\}\\leftarrow y -\\overline{y}$', (7.2,13.5),fontsize='24') \
+ text('$\\overline{y}=12$', (2,13.5), fontsize = '24', color = 'black')
\end{sageinput}
\begin{image}{0.05}{0.9}{0.05}%
\includegraphics[width=\linewidth]{./images/meanerror.png}
\end{image}%
If a \(y\)-value predicted by the regression equation is denoted \(\hat{y}\), we measure how well a regression equation fits the data by comparing the deviation to the difference between \(\hat{y}\) and \(\overline{y}\), \(\hat{y} - \overline{y}\).  In this case, the regression line goes through each data point, so \(\hat{y} = y\).  Therefore,%
%
\begin{equation*}
\hat{y} - \overline{y} = y - \overline{y} \quad\Longrightarrow \quad \frac{\hat{y} - \overline{y}}{y - \overline{y}} = 1.
\end{equation*}
Thus we give this regression equation an \(R^2\) value of 1.  This value is often interpreted by saying that the regression equation ``explains'' 100\% of the deviation. The definition of the coefficient of determination is based on this idea of comparing the deviation to the difference between \(\hat{y}\) and \(\overline{y}\) to measure the percentage of deviation ``explained'' by the regression equation.%
\par
This set of data is highly idealized because it was generated exactly according to the linear relationship \(y=3+2x\).  In reality, data never conforms to an exact relationship like this.  Real data with a linear relationship satisfies an equation of the form%
%
\begin{equation*}
y = \beta_0 + \beta_1 x + \varepsilon
\end{equation*}
where \(\varepsilon\) is some ``noise.'' This noise may be due to measurement error, sampling variation, or some other random event outside of our control.%
\par
The relation \(y = \beta_0 + \beta_1x\) is called the ``true'' linear trend of the population while the regression equation has the generic form \(\hat{y} = \hat{\beta}_0 + 
\hat{\beta}_1 x\).  The ``hats'' indicate that the parameters \(\hat{\beta}_0\) and \(\hat{\beta}_1\), and the values of \(y\), are estimates of the population values based on sample data.%
\par
Let's redo the data set by adding in some psuedorandom noise.%
\begin{sageinput}
data = [(x, 2*x+3+numpy.random.normal(0,2)) for x in range(10)]

sp2 = scatter_plot(data)
show(sp2)
\end{sageinput}
(If you execute these commands several times in a row, you will get a slightly different graph each time.)%
\begin{sageinput}
var('b0 b1 x')
model(x) = b0 + b1*x
ans = find_fit(data,model, solution_dict = True)
ans
\end{sageinput}
\begin{sageinput}
sp2 + plot(ans[b0] + ans[b1]*x,(x,0,10))
\end{sageinput}
How do we define the \(R^2\) value for a line fit to noisy data?  We introduce three different types of deviation:%
%
\begin{itemize}[label=\textbullet]
\item{}\emph{Explained deviation} \({}=\hat{y} - \overline{y}\)%
\item{}\emph{Unexplained deviation} \({}=y - \hat{y}\)%
\item{}\emph{Total deviation} = Explained deviation + unexplained deviation \({}= y - \overline{y}\)%
\end{itemize}
We wish to total up the deviation over all the data points, but we need to avoid cancellation. So similar to the least-squares approach, we will square these quantities to get amounts of \terminology{variation}.  The total variation is called the \terminology{total sum of squares} and is given by%
%
\begin{equation*}
SS_{Tot} = \sum (y_i - \overline{y})^2.
\end{equation*}
The explained variation is called the \terminology{regression sum of squares} and is given by%
%
\begin{equation*}
SS_{Reg} = \sum (\hat{y}_i - \overline{y})^2.
\end{equation*}
The unexplained variation is called the \terminology{residual sum of squares} and is given by%
%
\begin{equation*}
SS_{Res} = \sum (y_i - \hat{y}_i)^2.
\end{equation*}
Similar to the relationship between the deviations, we get that%
%
\begin{equation*}
SS_{Tot} = SS_{Reg} + SS_{Res}.
\end{equation*}
(Proving that is not trivial.). If we rewrite the previous equation as \(SS_{Reg} = SS_{Tot} - SS_{Res}\), we can write that the ``percentage'' of the total variation explained by the regression equation is%
%
\begin{equation*}
R^2 = \frac{SS_{Reg}}{SS_{Tot}} = \frac{SS_{Tot} - SS_{Res}}{SS_{Tot}}.
\end{equation*}
This is the definition of the coefficient of determination.  The closer \(R^2\) is to 1, the better the line fits the data.  An \(R^2\) value close to 0 indicates a very poor-fitting model.%
\par
Now let's calculate \(R^2\) for our noisy data and its regression line above.%
\begin{sageinput}
yvalues = [y for (x,y) in data]
avg = numpy.mean(yvalues)

yhatvalues = [(ans[b0] + ans[b1]*x) for (x,y) in data]

sstot = sum((yvalues[i]-avg)^2 for i in range(10))

ssres = sum((yvalues[i] - yhatvalues[i])^2 for i in range(10))

rsquared = (sstot - ssres)/sstot
rsquared
\end{sageinput}
The \(R^2\) value is not 1 because our data has some noise, so the underlying linear relationship (\(y=3+2x\)) does not account for all of the variation from the mean.%
\par
If we re-execute the cells above to re-do the noise, we should get different points and a different \(R^2\) value. We can add more ``noise'' to the data by increasing the standard deviation from 2 to 4.  What happens to the \(R^2\) value if we do this?%
%
%
\typeout{************************************************}
\typeout{Subsection 6.6.1 Finding \(R^2\) for linearizable models}
\typeout{************************************************}
%
\begin{subsectionptx}{Finding \(R^2\) for linearizable models}{}{Finding \(R^2\) for linearizable models}{}{}{g:subsection:id77}
Consider the linearizable models fit to the life expectancy data in \hyperref[x:section:linearizable-models]{Section~{\xreffont\ref{x:section:linearizable-models}}}. We can compare how well the different models fit the data by calculating the \(R^2\) value for each model and then comparing the \(R^2\) values. To calculate the \(R^2\) value for a linearizable model, we calculate the \(R^2\) value for the straight line fit to the \emph{transformed} data.%
%
%
\typeout{************************************************}
\typeout{Subsubsection 6.6.1.1 Power model}
\typeout{************************************************}
%
\begin{subsubsectionptx}{Power model}{}{Power model}{}{}{g:subsubsection:id78}
\leavevmode%
\begin{sageinput}
datapoints = [(275, 74), (410, 72), (467, 73), (559, 67), (643, 68), (1010, 70), (1037, 67), (1216, 66), (2471, 57), (4873, 62), (6166, 54), (7174, 59)]

loglogpoints = [(ln(P), ln(L)) for (P, L) in datapoints]
sp = scatter_plot(loglogpoints, axes_labels=['$\\ln P$', '$\\ln L$'])
show(sp)
\end{sageinput}
\begin{sageinput}
var('b a')
model(x) = b*x + a
ans = find_fit(loglogpoints, model, solution_dict=True)
ans
\end{sageinput}
\begin{sageinput}
sp + plot(ans[b]*x + ans[a],(x,5,9))
\end{sageinput}
\begin{sageinput}
yvalues = [y for (x,y) in loglogpoints]

import numpy
avg = numpy.mean(yvalues).n()
avg
\end{sageinput}
\begin{sageinput}
yhatvalues = [(ans[b]*x + ans[a]) for (x,y) in loglogpoints]
sstot = N(sum((yvalues[i]-avg)^2 for i in range(10)))
ssres = N(sum((yvalues[i] - yhatvalues[i])^2 for i in range(10)))
rsquared = (sstot - ssres)/sstot
rsquared
\end{sageinput}
\begin{sageoutput}
0.761061535668576
\end{sageoutput}
\end{subsubsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsubsection 6.6.1.2 Logarithmic model}
\typeout{************************************************}
%
\begin{subsubsectionptx}{Logarithmic model}{}{Logarithmic model}{}{}{g:subsubsection:id79}
\leavevmode%
\begin{sageinput}
datapoints = [(275, 74), (410, 72), (467, 73), (559, 67), (643, 68), (1010, 70), (1037, 67), (1216, 66), (2471, 57), (4873, 62), (6166, 54), (7174, 59)]

logpoints = [(ln(P), L) for (P,L) in datapoints]
sp2 = scatter_plot(logpoints, axes_labels = ["$\\ln P$", "$L$"])
show(sp2)
\end{sageinput}
\begin{sageinput}
var('b a')
model(x) = b*x + a
ans = find_fit(logpoints,model, solution_dict = True)
ans
\end{sageinput}
\begin{sageinput}
sp2 + plot(ans[b]*x + ans[a],(x,5,9))
\end{sageinput}
\begin{sageinput}
yvalues = [y for (x,y) in logpoints]

import numpy
avg = numpy.mean(yvalues)
avg
\end{sageinput}
\begin{sageinput}
yhatvalues = [(ans[b]*x + ans[a]) for (x,y) in logpoints]
sstot = N(sum((yvalues[i]-avg)^2 for i in range(10)))
ssres = N(sum((yvalues[i] - yhatvalues[i])^2 for i in range(10)))
rsquared = (sstot - ssres)/sstot
rsquared
\end{sageinput}
\begin{sageoutput}
0.771445233869118
\end{sageoutput}
\end{subsubsectionptx}
%
%
\typeout{************************************************}
\typeout{Subsubsection 6.6.1.3 Exponential model}
\typeout{************************************************}
%
\begin{subsubsectionptx}{Exponential model}{}{Exponential model}{}{}{g:subsubsection:id80}
\leavevmode%
\begin{sageinput}
datapoints = [(275, 74), (410, 72), (467, 73), (559, 67), (643, 68), (1010, 70), (1037, 67), (1216, 66), (2471, 57), (4873, 62), (6166, 54), (7174, 59)]

exppoints = [(P,ln(L)) for (P,L) in datapoints]
sp3 = scatter_plot(exppoints,axes_labels=["$P$", "$\\ln L$"])
sp3
\end{sageinput}
\begin{sageinput}
var('b a')
model(x) = b*x + a
ans = find_fit(exppoints,model, solution_dict = True)
ans
\end{sageinput}
\begin{sageinput}
sp3 + plot(ans[b]*x + ans[a],(x,0,7000))
\end{sageinput}
\begin{sageinput}
yvalues = [y for (x,y) in exppoints]

import numpy
avg = numpy.mean(yvalues).n()
avg
\end{sageinput}
\begin{sageinput}
yhatvalues = [(ans[b]*x + ans[a]) for (x,y) in exppoints]
sstot = N(sum((yvalues[i]-avg)^2 for i in range(10)))
ssres = N(sum((yvalues[i] - yhatvalues[i])^2 for i in range(10)))
rsquared = (sstot - ssres)/sstot
rsquared
\end{sageinput}
\begin{sageoutput}
0.573865088823950
\end{sageoutput}
\end{subsubsectionptx}
We can now compare how well these models fit the data by comparing their \(R^2\) values:%
\begin{center}%
{\tabularfont%
\begin{tabular}{ccc}\hrulethick
\textbf{Logarithmic}&\textbf{Power}&\textbf{Exponential}\tabularnewline[0pt]
0.7714&0.7611&0.5739\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
\end{subsectionptx}
We see that the power and logarithmic models fit the data well with the logarithmic model being slightly better. The exponential model does not fit as well. Thus, based strictly on the \(R^2\) values, we would conclude that the logarithmic model fits the data the best. This agrees with our earlier conclusion.%
\par
We warn against blindly using \(R^2\) values to choose a best model. These values should be used as only one factor when choosing a best model. Other factors that should be considered are the nature of the behavior being analyzed and the simplicity of the model.%
\par
For instance, population growth is often exponential. So if we fit curves to some data of a population, we may want to favor an exponential model over other types even if it has a lower \(R^2\) value.%
\par
In ``Modeling the U.S. Population'' (AMATYC Review, Vol. 20, No. 2, Spring 1999, pages 17–29), Sheldon Gordon makes the point that, ``The best choice (of a model) depends on the set of data being analyzed and requires an exercise in judgement, not just computation.''%
%
%
\typeout{************************************************}
\typeout{Exercises 6.6.2 Exercises}
\typeout{************************************************}
%
\begin{exercises-subsection}{Exercises}{}{Exercises}{}{}{g:exercises:id81}
\begin{divisionexercise}{1}{}{}{g:exercise:id82}%
The data below contain the weights (in lbs) and highway miles per gallon (MPG) of several cars. Calculate \(SS_{Reg}\), \(SS_{Res}\), \(SS_{Tot}\), and \(R^2\) for the linear regression equation fit to this data.%
\begin{center}%
{\tabularfont%
\begin{tabular}{ccccc}\hrulethick
\multicolumn{1}{cA}{\emph{Weight} (\(x\))}&3250&3425&2400&2250\tabularnewline\hrulethin
\multicolumn{1}{cA}{\emph{MPG} (\(y\))}&26&28&37&38\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
\end{divisionexercise}%
\begin{divisionexercise}{2}{}{}{g:exercise:id83}%
The data below contain the diameter of the trunk at chest height and volume of wood in several pine trees. Model Volume in terms of Diameter with several different linearizable models and select the best one. Briefly explain how you decided which one is best.%
\begin{center}%
{\tabularfont%
\begin{tabular}{rcccccccccc}\hrulethick
\multicolumn{1}{rA}{\emph{Diameter}}&32&29&24&45&20&30&26&40&24&18\tabularnewline\hrulethin
\multicolumn{1}{rA}{\emph{Volume}}&185&109&95&300&30&125&55&246&60&15\tabularnewline\hrulethick
\end{tabular}
}%
\end{center}%
\end{divisionexercise}%
\end{exercises-subsection}
\end{sectionptx}
\end{chapterptx}
\end{partptx}
\end{document}